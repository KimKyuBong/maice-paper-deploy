# 논문 삽입용 - 교사 루브릭 평가 섹션

## 📍 Chapter 6: 연구방법 - 루브릭 검증 과정

### 6.X 루브릭 타당성 검증

본 연구에서 개발한 루브릭의 타당성을 확보하기 위해, 두 명의 현직 수학 교사에게 루브릭 검증을 의뢰하였다. 검증 과정은 다음과 같이 진행되었다.

#### 검증 참여자

| 구분 | 교사 1 | 교사 2 |
|------|--------|--------|
| 경력 | [X년] | [Y년] |
| 담당 | [학년/과목] | [학년/과목] |
| 검증 기간 | 2025.11.09 | 2025.11.09-10 |

두 교사는 실제 학생-AI 대화 세션 [N개]를 검토하고, 루브릭의 각 항목에 대해 다음 관점에서 평가하였다:

1. **항목의 적합성**: 해당 루브릭 요소가 AI 교육 시스템의 질을 평가하는 데 적합한가?
2. **평가 기준의 명확성**: 평가 기준이 명확하게 정의되어 있어 일관된 평가가 가능한가?
3. **평가 가능성**: 제공되는 정보(대화 로그)만으로 해당 항목을 평가하기에 충분한가?
4. **요소의 독립성**: 다른 루브릭 항목과 중복되지 않는가?

#### 검증 결과

두 교사의 평가를 분석한 결과, 8개 대항목 중 1개 항목에서 완전 일치, 4개 항목에서 부분 일치, 3개 항목에서 불일치를 보였다(표 X).

**[표 X] 교사 간 루브릭 평가 일치도**

| 루브릭 항목 | 교사 1 평가 | 교사 2 평가 | 일치도 |
|------------|-----------|-----------|--------|
| A1. 수학적 정확성 | 중립-비판 | 긍정-제안 | 부분 일치 |
| A2. 질문 구조화 | 중립-비판 | 긍정-제안 | 부분 일치 |
| A3. 학습 맥락 제시 | 중립-비판 | 중립-제안 | 일치 |
| B1. 수준 적합성 | 메타비판 | 긍정 | 불일치 |
| B2. 설명의 체계성 | 메타비판 | 긍정 | 불일치 |
| B3. 학습 확장 지원 | 중립-비판 | 중립-제안 | 부분 일치 |
| C1. 대화의 일관성 | 긍정-비판 | 긍정 | 일치 |
| C2. 학습 과정 지원 | 중립-비판 | 긍정 | 불일치 |

두 교사는 루브릭의 전반적인 구조와 평가 항목이 AI 교육 시스템의 질을 평가하는 데 적합하다고 인정하였으나, 다음과 같은 개선점을 지적하였다:

**1) 학습자의 맥락 정보 미제공 행동**

두 교사 모두 가장 일관되게 지적한 문제는 학습자들이 자신의 학년, 수준, 선행지식을 질문에 포함시키지 않아 일부 항목(특히 A1-교과과정 위계성, B1-수준 적합성)의 평가가 제한적이라는 점이었다.

> "질문자의 현재 수준, 학년을 밝히지 않은 경우가 대다수라 평가하기 모호함" (교사 1)

> "질문 내용만으로는 학습자의 현재 수준이나 교육과정 단계의 적합성을 명확히 파악하기 어려움" (교사 2)

실제로 분석 대상 대화 세션에서 학습자가 자신의 학년을 명시한 경우는 [X%]에 불과했다. 이는 온라인 학습 환경에서 학습자들이 자신의 학습 맥락을 제공하지 않고 즉각적인 문제 해결만 요청하는 전형적인 행동 패턴으로 분석된다. 이는 시스템이나 루브릭의 문제라기보다는, 학습자들의 질문 습관에서 기인한다.

**2) 추상적 평가 용어의 명확성 부족**

교사 1은 "체계적", "논리적", "적합" 등의 추상적 용어에 대한 조작적 정의가 부족하여 평가자마다 다르게 해석될 수 있다고 지적하였다.

> "설명이 체계적, 논리적이라는 말 자체가 모호하므로 좀 더 명확한 지표가 필요하다고 생각함" (교사 1)

반면 교사 2는 동일한 용어를 보다 구체적으로 해석하여 평가하였다.

> "개념의 정의와 배경에서 시작하여, 개념에 대한 구조화되고 위계적인 설명, 구체적 예시와 개념 활용 시 주의점 안내 등으로 체계적인 순서에 따라 설명이 구성되어 있음" (교사 2)

이러한 차이는 평가 용어에 대한 명확한 기준과 예시가 필요함을 시사한다.

**3) AI의 간접적 교수 행동 평가 기준 모호**

두 교사 모두 AI가 직접적으로 학습자에게 질문하거나 격려하기보다는 "질문식 전개", "추가 내용 제안" 등 간접적 방식을 사용한다고 관찰하였다. 그러나 이러한 간접적 행동을 어떻게 평가할지에 대해서는 견해가 달랐다.

교사 1은 직접적 확인이 드물다는 점을 부정적으로 평가한 반면:

> "AI가 질문자에게 이해되었는지 직접적으로 질문하는 경우는 드물었음" (교사 1)

교사 2는 질문식 전개 자체를 이해 확인 전략으로 긍정적으로 평가하였다:

> "각 단계마다 '이해되었나요?'와 같은 직접적 질문은 적게 나타나지만, '이제 어떤 단계를 확인해 보도록 합시다. 이를 위해 먼저 무엇을 해야 할까요?'와 같은 질문식 전개를 통해 학습자의 이해를 단계별로 점검하고 확인하도록 유도하고 있음" (교사 2)

**4) 실생활 연결 부족**

두 교사 모두 AI가 실생활 응용 사례를 먼저 제시하는 경우가 드물다고 지적하였다.

> "직접적으로 묻지 않는 경우 실생활 응용 사례를 먼저 제시한 경우는 없었음" (교사 1)

> "질문 내용에 따라 응용 사례 제시 여부가 달라지는 경향이 있어 다소 제한적으로 이루어지는 것으로 보임" (교사 2)

**5) 일부 요소 간 중복**

교사 1은 일부 루브릭 요소가 다른 항목과 개념적으로 중복된다고 지적하였다.

> "문제 해결 방향의 구체성 항목의 경우 질문 구조화 항목과 겹친다고 생각함" (A1-Element 4 관련)

> "적합하다고 생각하나 이는 문맥 일관성과 겹치는 부분이라고 생각함" (C1-Element 4 관련)

#### 루브릭 수정 및 보완

교사 검증 결과를 반영하여 루브릭을 다음과 같이 수정하였다:

1. **평가 불가 옵션 추가**: 학습자 정보가 없어 평가가 불가능한 경우를 위해 "N/A" 옵션을 추가하였다.
2. **평가 기준 구체화**: "체계적", "논리적" 등 추상적 용어에 대해 구체적인 행동 지표를 명시하였다(예: 체계적 = ①개념정의 → ②원리설명 → ③예시제시 → ④주의사항).
3. **간접적 행동 인정**: AI의 질문식 전개, 제안형 표현 등 간접적 교수 행동도 평가에 포함하도록 명시하였다.
4. **중복 요소 통합**: A1-Element 4를 A2로 통합하여 중복을 제거하였다.

이러한 수정을 통해 루브릭의 신뢰도와 타당성을 향상시켰다. 다만, 학습자 컨텍스트 정보 부족 문제는 루브릭 설계만으로는 해결할 수 없는 본질적인 한계로, 향후 시스템 개선이 필요한 부분으로 확인되었다.

---

## 📍 Chapter 7: 결과 - 평가자 간 신뢰도

### 7.X 평가자 간 신뢰도 분석

#### 평가 관점의 차이

두 교사의 평가를 비교 분석한 결과, 평가 관점에서 뚜렷한 차이가 발견되었다. 교사 1은 주로 루브릭 설계의 메타적 문제에 집중한 반면, 교사 2는 AI의 실제 교수 행동 관찰에 집중하였다(표 Y).

**[표 Y] 교사별 평가 특성**

| 특성 | 교사 1 | 교사 2 |
|------|--------|--------|
| 평가 관점 | 루브릭 설계 비판 | AI 성능 관찰 |
| 주요 키워드 | "모호함" (8회)<br>"명확한 지표 필요" (4회) | "대체로" (8회)<br>"효과적" (4회) |
| 부정 표현 빈도 | 높음 ("거의 없음" 7회) | 낮음 ("제한적" 위주) |
| 구체적 사례 제시 | 적음 | 많음 (15회 이상) |
| 평가 어조 | 비판적-개선 요구 | 균형잡힌-발전적 제안 |

#### 불일치 항목 상세 분석

B1(수준 적합성), B2(설명의 체계성), C2(학습 과정 지원) 항목에서 교사 간 평가가 크게 달랐다. 이는 다음과 같은 원인으로 분석된다:

**원인 1: 평가 대상의 차이**

교사 1은 "평가 자체가 가능한가"를 문제 삼은 반면, 교사 2는 "AI가 잘 수행했는가"를 평가하였다.

- B1에 대한 교사 1: "학습자의 수준이 드러나지 않은 경우 수준에 맞게 설명한 것인지 **평가하기 모호했음**"
- B1에 대한 교사 2: "학습자 수준과 질문 의도를 고려하여 구조적이고 논리적인 설명, 적절한 비유, 단계별 풀이 등으로 **적합한 답변 제공**"

**원인 2: 평가 기준 해석의 차이**

"직접적 격려"를 어디까지 인정할 것인가에 대한 해석이 달랐다.

- C2에 대한 교사 1: "AI가 **직접적으로** 학습자의 탐구를 격려하는 경우는 없었음"
- C2에 대한 교사 2: "**질문식 설명**으로 사고 촉진하고, 추가 문제 제시나 응용 학습 제안으로 자기주도 학습 장려"

이러한 차이는 평가 용어에 대한 명확한 정의와 예시가 필요함을 시사한다.

#### 일치 항목 분석

두 교사가 일치한 항목들을 분석한 결과, 다음과 같은 특징이 발견되었다:

**C1(대화의 일관성)**: 두 교사 모두 긍정적으로 평가
- 교사 1: "이 루브릭 항목은 대화의 일관성 항목을 평가하기 적합하다고 생각함"
- 교사 2: "질문자의 대화 흐름이 '문제 제시 → AI 답변 → 재질문' 형식으로 일관성 유지"

→ 평가 기준이 명확하고 관찰 가능한 항목일수록 교사 간 일치도가 높았다.

**A3(학습 맥락 제시)**: 두 교사 모두 학습자 행동의 문제점 지적
- 교사 1: "학생들은 문제 해결에만 집중하여 교육과정 맥락, 학습 상황, 이전 지식을 드러내지 않음"
- 교사 2: "단원, 개념, 교육과정상 위치, 선수 학습 내용을 함께 포함하여 질문하면 더 체계적일 것"

→ 부정적 측면에 대한 합의는 긍정적 측면보다 쉬웠다.

#### 시사점

평가자 간 신뢰도 분석을 통해 다음과 같은 시사점을 도출하였다:

1. **평가 기준의 명확화**: 추상적 용어("체계적", "논리적", "직접적")에 대한 조작적 정의와 구체적 예시가 필요하다.

2. **평가 대상의 명시**: 루브릭이 "AI 성능"을 평가하는 것인지, "평가 가능성"을 점검하는 것인지 목적을 명확히 해야 한다.

3. **평가자 훈련**: 평가자 간 일관성을 높이기 위해 평가 전 충분한 훈련과 사례 공유가 필요하다.

4. **다양한 관점의 가치**: 두 교사의 서로 다른 관점은 루브릭 개선에 모두 유용한 통찰을 제공하였다. 메타적 비판은 루브릭 설계 개선에, 구체적 관찰은 AI 시스템 개선에 기여한다.

---

## 📍 Chapter 8: 토론 - 루브릭 기반 평가의 도전과제

### 8.X 루브릭 기반 평가의 한계와 도전과제

본 연구는 AI 교육 시스템의 질을 평가하기 위해 루브릭을 개발하고 적용하였다. 그러나 두 명의 현직 교사에게 루브릭 검증을 받는 과정에서 루브릭 기반 평가가 직면한 여러 도전과제를 확인하였다.

#### 학습자의 질문 행동 패턴

가장 일관되게 관찰된 특징은 학습자들이 자신의 학년, 수준, 선행지식 등을 질문에 포함시키지 않는다는 점이었다. 이로 인해 "수준 적합성"이나 "교과과정 위계성" 항목을 평가하기 어려웠다. 이는 루브릭이나 시스템의 문제가 아니라, 온라인 학습 환경에서 학습자들이 보이는 전형적인 행동 패턴이다.

본 연구에서 분석한 [N개] 대화 세션 중 학습자가 자신의 학년을 명시한 경우는 [X%]에 불과했다. 학습자들은 주로 "이 문제를 풀어주세요"와 같이 즉각적인 문제 해결을 요청하는 경향이 있었다. 이는 Koedinger et al.(2015)이 지적한 바와 같이, 온라인 학습 환경에서 학습자가 메타인지적 정보를 제공하지 않는 일반적인 현상이다.

이 문제를 해결하기 위해서는 시스템 차원의 개입이 필요하다. 예를 들어, 대화 초기에 AI가 "어느 학년이고, 현재 어떤 단원을 공부하고 있나요?"와 같이 자연스럽게 학습자 정보를 수집하는 메커니즘을 도입할 수 있다. 또는 학습자가 처음 시스템에 가입할 때 기본적인 학년 정보를 입력받는 방식도 고려할 수 있다.

#### 평가 용어의 조작적 정의 필요

교사 1이 집중적으로 지적한 문제는 "체계적", "논리적", "적합" 등 추상적 평가 용어에 대한 명확한 정의가 부족하다는 점이었다. 동일한 AI 응답을 보고도 교사 2는 "체계적이고 논리적"이라고 긍정적으로 평가한 반면, 교사 1은 "체계적이라는 말 자체가 모호"하다고 비판하였다.

이는 교육 분야의 루브릭이 일반적으로 직면하는 문제이다. Jonsson & Svingby(2007)는 루브릭의 신뢰도를 높이기 위해서는 각 평가 기준에 대한 구체적 지표와 예시가 필수적이라고 강조하였다. 본 연구에서도 이를 반영하여 루브릭을 다음과 같이 수정하였다:

- "체계적" → "개념 정의 → 원리 설명 → 구체적 예시 → 주의사항 순서로 전개"
- "논리적" → "각 단계가 인과관계로 명확히 연결"
- "직접적 격려" → "잘했어요, 스스로 해보세요 등의 명시적 표현 + 질문식 전개도 포함"

향후 연구에서는 각 평가 수준(1~5점)에 대한 구체적 사례를 포함한 평가 사례집(exemplars)을 개발하여 평가자 간 신뢰도를 더욱 높일 필요가 있다.

#### AI의 간접적 교수 스타일

흥미로운 발견은 AI가 직접적으로 학습자에게 질문하거나 격려하기보다는 "질문식 전개", "추가 내용 제안" 등 간접적 방식을 주로 사용한다는 점이었다. 예를 들어:

- 직접적 확인: "이 부분이 이해되었나요?" (드물음)
- 간접적 확인: "이제 어떤 단계를 확인해야 할까요?" (빈번함)

교사 1은 직접적 확인이 드물다는 점을 부정적으로 평가한 반면, 교사 2는 간접적 방식도 효과적인 교수 전략으로 인정하였다. 교육학 관점에서 보면, 질문식 전개는 Socratic method의 일종으로 학습자의 사고를 촉진하는 효과적인 방법이다(Paul & Elder, 2007). 그러나 일부 학습자에게는 직접적 피드백이 더 명확하고 안심을 줄 수 있다.

이는 AI 교육 시스템이 학습자 특성에 따라 직접적/간접적 스타일을 조절할 필요가 있음을 시사한다. 예를 들어, 수준이 낮거나 자신감이 부족한 학습자에게는 "잘하고 있어요!"와 같은 직접적 격려를, 수준이 높은 학습자에게는 "이 부분을 어떻게 생각하나요?"와 같은 질문식 접근을 사용하는 적응적 전략이 필요하다.

#### 실생활 연결의 부족

두 교사 모두 지적한 또 다른 문제는 AI가 실생활 응용 사례를 먼저 제시하는 경우가 드물다는 점이었다. 학습자가 직접 "실생활에서 어떻게 쓰이나요?"라고 묻지 않는 한, AI는 주로 수학적 개념과 문제 풀이에만 집중하였다.

수학 교육 연구에 따르면, 실생활 맥락은 학습자의 학습 동기와 개념 이해를 높이는 중요한 요소이다(Boaler, 2008). 특히 수학적 귀납법과 같은 추상적 개념의 경우, 도미노 효과, 계단 오르기 등의 실생활 비유가 이해에 큰 도움이 된다(교사 2도 AI가 도미노 비유를 사용한 것을 긍정적으로 평가).

이를 개선하기 위해 AI 프롬프트에 "해당 수학 개념의 실생활 응용 사례를 최소 1개 제시하라"는 지시를 명시적으로 추가할 필요가 있다.

#### 평가자 훈련의 필요성

평가자 간 신뢰도 분석 결과, 동일한 루브릭을 사용해도 교사마다 평가 관점과 해석이 다를 수 있음이 확인되었다. 이는 단순히 루브릭을 제공하는 것만으로는 충분하지 않으며, 평가자 훈련이 필요함을 시사한다.

효과적인 평가자 훈련 프로그램은 다음을 포함해야 한다(Stemler, 2004):

1. **평가 기준 숙지**: 각 루브릭 요소의 정의와 의도 이해
2. **사례 기반 훈련**: 다양한 점수 수준의 실제 응답 사례 분석
3. **토론과 합의**: 모호한 경우를 함께 논의하고 합의 도출
4. **시범 평가**: 동일 샘플을 독립적으로 평가한 후 결과 비교

본 연구에서는 시간 제약으로 이러한 훈련을 충분히 제공하지 못했으나, 향후 연구에서는 체계적인 평가자 훈련을 포함하여 평가자 간 신뢰도를 더욱 높일 필요가 있다.

#### 루브릭 개선의 지속적 필요성

중요한 것은, 이러한 한계와 도전과제가 본 연구의 가치를 떨어뜨리는 것이 아니라 오히려 향후 개선 방향을 명확히 제시한다는 점이다. 교육 평가 도구로서 루브릭은 한 번 개발하고 끝나는 것이 아니라, 지속적으로 검증하고 개선해야 하는 '살아있는 문서'이다(Brookhart, 2013).

본 연구는 초기 버전의 루브릭을 개발하고, 현직 교사의 피드백을 받아 개선하였으며, 그 과정에서 발견한 한계를 투명하게 공개하였다. 이는 후속 연구자들이 더 나은 루브릭을 개발하는 데 기여할 것이다.

#### 학습자 행동 패턴에 대한 새로운 이해

본 연구의 중요한 발견 중 하나는 온라인 학습 환경에서 학습자들이 보이는 질문 행동 패턴을 파악한 것이다. 두 교사 모두 학습자들이 자신의 학년, 수준, 선행지식을 질문에 포함시키지 않는다고 지적했다. 이는 다음과 같은 함의를 갖는다:

**1) 루브릭이나 시스템의 문제가 아님**

초기에는 루브릭의 일부 항목(교과과정 위계성, 수준 적합성)을 평가하기 어렵다는 것이 루브릭 설계의 문제로 보였다. 그러나 교사 검증을 통해 이것이 학습자의 전형적인 행동 패턴임을 확인했다. 학습자들은 "수학적 귀납법으로 이 문제를 증명하시오"처럼 문제만 제시하고, 자신이 고등학교 1학년인지 3학년인지, 이 개념을 처음 배우는지 복습하는지 등의 맥락은 제공하지 않는다.

**2) 온라인 학습 환경의 특성**

이는 Koedinger et al.(2015)이 지적한 바와 같이, 온라인 학습 환경에서 학습자가 메타인지적 정보를 제공하지 않는 일반적인 현상이다. 오프라인 교실에서는 교사가 학습자의 학년, 진도, 수준을 이미 알고 있지만, 온라인 환경에서는 이러한 정보가 자동으로 제공되지 않는다. 그러나 많은 학습자들이 이를 인식하지 못하고 오프라인과 동일한 방식으로 질문한다.

**3) 시스템 설계에 대한 시사점**

이러한 발견은 향후 AI 교육 시스템 설계에 중요한 시사점을 제공한다. 시스템은 학습자가 자발적으로 정보를 제공하기를 기다리는 것이 아니라, 적극적으로 필요한 정보를 유도해야 한다. 예를 들어:

- "수학적 귀납법에 대해 질문하셨네요. 혹시 이 개념을 처음 배우는 건가요, 아니면 복습하는 건가요?"
- "이 문제는 고등학교 1학년 과정인데, 맞나요?"
- "이 단원의 기본 개념은 이해하셨나요, 아니면 처음부터 설명이 필요한가요?"

이러한 질문을 통해 AI는 학습자의 맥락을 파악하고, 그에 맞는 수준과 스타일로 답변을 조정할 수 있다.

**4) 연구 방법론에 대한 함의**

이는 또한 AI 교육 시스템 연구 방법론에도 시사점을 제공한다. 평가 도구(루브릭)를 개발할 때, 이상적인 학습 환경을 가정하는 것이 아니라 실제 학습자들의 행동 패턴을 고려해야 한다. 루브릭의 일부 항목은 평가하기 어려울 수 있지만, 그것이 루브릭의 문제가 아니라 실제 환경의 특성이라면, 이를 "한계"가 아닌 "발견사항"으로 다루고 개선 방향을 제시하는 것이 더 건설적이다.

---

## 📍 Chapter 8: 토론 - 연구의 한계

### 8.X 연구의 한계

본 연구는 다음과 같은 한계를 가진다:

#### 평가 환경의 특성

**1) 학습자의 맥락 정보 미제공 행동**

본 연구에서 사용된 루브릭의 일부 항목(A1-교과과정 위계성, B1-수준 적합성)은 학습자의 학년, 수준, 선행지식 정보를 필요로 한다. 그러나 분석 대상 대화 세션의 대부분에서 학습자가 이러한 정보를 질문에 포함시키지 않아 해당 항목의 평가가 제한적이었다. 이는 루브릭 설계의 문제가 아니라, 온라인 학습 환경에서 학습자들이 자신의 학습 맥락을 제공하지 않고 즉각적인 문제 해결만 요청하는 전형적인 행동 패턴에서 기인한다. 향후 연구에서는 AI가 대화 초기에 자연스럽게 학습자 정보를 유도하는 메커니즘을 도입할 필요가 있다.

**2) 추상적 평가 용어의 조작적 정의 부족**

"체계적", "논리적", "적합" 등의 추상적 용어에 대한 명확한 조작적 정의가 부족하여 평가자마다 다르게 해석할 가능성이 있다. 본 연구에서는 교사 피드백을 반영하여 이러한 용어에 대한 구체적 지표를 추가하였으나, 각 평가 수준(1~5점)에 대한 상세한 사례집(exemplars)은 개발하지 못하였다. 향후 연구에서는 다양한 수준의 실제 사례를 포함한 평가 매뉴얼을 개발하여 평가자 간 신뢰도를 높일 필요가 있다.

**3) 요소 간 부분적 개념 중복**

일부 루브릭 요소가 다른 항목과 개념적으로 중복되는 부분이 있다는 지적이 있었다(예: A1-문제해결방향과 A2-질문구조화). 본 연구에서는 중복을 최소화하기 위해 일부 요소를 통합하였으나, 루브릭의 포괄성과 요소 간 독립성 사이의 균형을 찾는 것은 여전히 과제로 남아있다.

**4) AI 간접적 행동에 대한 평가 기준 모호**

AI가 직접적으로 학습자에게 질문하거나 격려하기보다는 질문식 전개, 제안형 표현 등 간접적 방식을 주로 사용하는데, 이러한 간접적 행동을 어떻게 평가할지에 대한 명확한 기준이 부족하였다. 본 연구에서는 교사 피드백을 반영하여 간접적 행동도 인정하도록 수정하였으나, 직접적/간접적 접근 중 어느 것이 더 효과적인지는 추가 연구가 필요하다.

#### 평가자 간 신뢰도 관련 한계

**5) 제한적인 평가자 수**

본 연구에서는 두 명의 교사만 루브릭 검증에 참여하였다. 평가자 간 신뢰도를 보다 엄밀하게 측정하기 위해서는 더 많은 평가자와 Cohen's Kappa 등 신뢰도 계수 산출이 필요하나, 시간과 자원의 제약으로 이를 수행하지 못하였다. 두 교사의 피드백은 루브릭 개선에 유용한 통찰을 제공하였으나, 일반화에는 한계가 있다.

**6) 평가자 훈련 부족**

평가자들에게 체계적인 사전 훈련을 제공하지 못하였다. 이로 인해 교사마다 루브릭을 해석하는 관점이 달랐으며(교사 1: 루브릭 설계 비판, 교사 2: AI 성능 관찰), 일부 항목에서 평가 불일치가 발생하였다. 향후 연구에서는 평가 기준 숙지, 사례 분석, 모의 평가 등을 포함한 체계적인 평가자 훈련 프로그램이 필요하다.

#### 시스템 성능 관련 한계

**7) 실생활 연결 부족**

두 교사 모두 AI가 실생활 응용 사례를 먼저 제시하는 경우가 드물다고 지적하였다. 이는 AI 프롬프트 설계의 문제로, 향후 시스템 개선 시 "실생활 사례 제시"를 명시적으로 포함할 필요가 있다.

**8) 소극적 학습 동기 유발**

교사 1은 AI가 직접적으로 학습자에게 동기를 유발하거나 적극적으로 질문하는 경우가 드물다고 지적하였다. 이는 현재 시스템이 주로 질문에 답하는 반응적 역할에 머물고 있으며, 학습자를 능동적으로 참여시키는 proactive한 역할이 부족함을 시사한다.

---

## 📍 Chapter 8: 토론 - 향후 연구 방향

### 8.X 향후 연구 방향

본 연구의 결과와 한계를 바탕으로 다음과 같은 후속 연구를 제안한다:

#### 루브릭 정교화 연구

**1) 평가 사례집(Exemplars) 개발**

각 루브릭 항목의 평가 수준(1~5점)에 대한 구체적 사례를 포함한 평가 매뉴얼을 개발할 필요가 있다. 예를 들어, "설명의 체계성" 항목에 대해:

- 1점: 설명 순서가 무작위적이고 논리적 연결이 없음 [사례 A]
- 3점: 기본적인 순서는 있으나 일부 단계가 생략됨 [사례 B]
- 5점: 정의→원리→예시→주의사항 순서로 완벽하게 구조화 [사례 C]

이러한 사례집은 평가자 간 신뢰도를 크게 높일 것이다(Jonsson & Svingby, 2007).

**2) 평가자 간 신뢰도 체계적 측정**

더 많은 평가자(최소 5명 이상)를 대상으로 Cohen's Kappa, Intraclass Correlation Coefficient(ICC) 등 신뢰도 계수를 측정하여 루브릭의 신뢰도를 정량적으로 검증할 필요가 있다.

**3) 루브릭 요소 재구조화**

본 연구에서 지적된 요소 간 중복 문제를 해결하기 위해 요인분석(Factor Analysis) 등 통계적 방법을 활용하여 루브릭 구조를 재검토할 수 있다.

#### 시스템 개선 연구

**4) 학습자 맥락 정보 유도 메커니즘 개발**

학습자들이 자발적으로 자신의 학습 맥락을 제공하지 않는 경향이 있으므로, AI가 대화 초기에 자연스럽게 학습자의 학년, 수준, 학습 목표 등을 유도하는 대화 전략을 개발할 필요가 있다. 이는 다음과 같은 방식으로 구현 가능하다:

- 시스템 온보딩: 최초 가입 시 기본 정보 입력 (선택적)
- 자연스러운 대화형 유도: "어느 학년이고, 어떤 단원을 공부 중이에요?"
- 맥락 추론: 질문 내용과 용어 사용으로 수준 추정 후 확인

단, 개인정보보호를 고려하여 최소한의 정보만 수집하고, 학습자가 제공을 거부할 수 있는 옵션을 제공해야 한다. 중요한 것은 학습자의 행동 패턴을 이해하고 이에 적응하는 시스템을 설계하는 것이다.

**5) 적응적 교수 스타일 개발**

학습자 특성에 따라 직접적/간접적 교수 스타일을 조절하는 적응적 AI를 개발할 수 있다:

- 초보 학습자: 직접적 설명 + 명시적 격려
- 숙련 학습자: 질문식 전개 + 탐구 유도
- 자신감 부족 학습자: 빈번한 긍정적 피드백
- 자기주도적 학습자: 확장 자료 제시

이를 위해 학습자 모델링(Learner Modeling) 연구가 필요하다.

**6) 실생활 연결 사례 데이터베이스 구축**

각 수학 개념별로 실생활 응용 사례, 효과적인 비유, 역사적 배경 등을 포함한 데이터베이스를 구축하여 AI가 이를 적극적으로 활용하도록 할 수 있다. 예를 들어:

- 수학적 귀납법: 도미노 효과, 계단 오르기, 수학적 귀납법의 역사
- 로그: 지진 규모, 소리 데시벨, 지수적 성장의 실생활 사례

#### 효과성 검증 연구

**7) 루브릭 점수와 학습 성과 간 상관관계 연구**

본 연구에서는 루브릭을 개발하고 적용하였으나, 루브릭 점수가 실제 학습 성과(시험 점수, 개념 이해도, 학습 만족도 등)와 어떤 관계가 있는지는 검증하지 못하였다. 향후 연구에서는 루브릭 점수 vs 학습 성과 간 상관관계를 분석하여 루브릭의 예측 타당도(Predictive Validity)를 검증할 필요가 있다.

**8) 장기적 학습 효과 연구**

본 연구는 단일 대화 세션 수준의 평가에 집중하였다. 그러나 AI 교육 시스템의 진정한 효과는 장기간에 걸친 학습 성장에서 나타난다. 향후 연구에서는 학습자가 여러 주 또는 여러 달에 걸쳐 시스템을 사용하면서 어떻게 발전하는지, 루브릭 점수가 시간에 따라 어떻게 변화하는지 종단 연구(Longitudinal Study)를 수행할 수 있다.

#### 다른 영역으로 확장

**9) 타 과목 적용 연구**

본 연구에서 개발한 루브릭은 수학 교육에 초점을 맞추었으나, 기본 구조(정확성, 구조화, 맥락, 적합성, 체계성, 확장, 일관성, 지원)는 다른 과목에도 적용 가능하다. 향후 과학, 언어, 역사 등 다른 과목의 AI 교육 시스템 평가를 위한 루브릭 변형 연구가 가능하다.

**10) 다양한 AI 모델 간 비교**

본 연구에서는 특정 AI 모델을 사용하였으나, 향후 GPT-4, Claude, Gemini 등 다양한 AI 모델을 동일한 루브릭으로 평가하여 각 모델의 장단점을 비교하는 연구가 유용할 것이다.

---

**작성 일시**: 2025-11-10  
**기반 데이터**: 두 교사의 루브릭 평가 JSON 분석 결과

