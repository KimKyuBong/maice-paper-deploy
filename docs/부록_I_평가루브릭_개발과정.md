# 부록 I. 평가 루브릭 개발 과정

본 연구에서는 프리패스 방식 LLM의 교육적 문제점을 실증적으로 파악하고, MAICE 시스템의 효과성을 측정하기 위해 체계적인 평가 루브릭을 개발하였다. 루브릭 개발은 다음의 3단계 과정으로 진행되었다: (1) 이론적 기반 구축, (2) 예비 조사 데이터 기반 평가 영역 구성, (3) 세부 평가 요소 개발.

---

## I.1 이론적 기반

본 루브릭은 전통적 교육학 이론과 최신 AI 교육 평가 연구를 종합하여 개발되었다.

### I.1.1 전통적 교육학 이론

**Dewey(1910)의 반성적 사고 이론**

Dewey는 학습을 "문제 인식 → 문제 명료화 → 가설 형성 → 논리적 전개 → 검증 및 결론"의 5단계로 설명하였다. 이 이론은 본 루브릭의 다음 영역과 직접 연결된다:
- **질문 구조화 (A2)**: 학습자가 자신의 문제 상황을 얼마나 명료하게 표현하는가?
- **학습 내용 확장성 (B3)**: AI가 학습자의 가설 형성과 논리적 전개를 얼마나 지원하는가?

**Vygotsky(1978)의 근접발달영역(ZPD) 이론**

Vygotsky는 학습자의 현재 수준(실제적 발달 수준)과 잠재적 발달 수준 사이의 간극, 즉 근접발달영역(Zone of Proximal Development, ZPD)을 제시하였다. ZPD는 학습자가 혼자서는 수행할 수 없지만 더 유능한 타인의 도움을 받으면 수행할 수 있는 과제의 범위를 의미한다. 이후 Wood, Bruner, and Ross (1976)는 이러한 Vygotsky의 개념을 발전시켜 "비계설정(scaffolding)"이라는 용어를 도입하였으며, 이는 학습자의 ZPD 내에서 제공되는 일시적이고 조정 가능한 지원을 의미한다. 이는 본 루브릭의 다음 영역과 직접 연결된다:
- **학습 맥락 적용 (A3)**: 학습자가 자신의 현재 수준, 선수지식, 학습 목표를 얼마나 명시하는가?
- **학습자 맞춤도 (B1)**: AI가 학습자의 ZPD를 파악하고 적절한 비계를 제공하는가?

**Bloom의 교육 목표 분류학(1956, 2001 개정)**

Bloom의 분류학은 지식 차원과 인지 과정 차원으로 학습 목표를 체계화하였다. 본 연구는 Bloom의 지식 차원(사실적-개념적-절차적-메타인지적)을 채택하여 K1-K4 분류를 구성하였으며, 이는 다음 영역과 연결된다:
- **수학적 전문성 (A1)**: 질문이 어떤 지식 차원을 다루는지 명시되는가?
- **설명의 체계성 (B2)**: AI 답변이 학습 목표에 맞는 인지 과정을 지원하는가?

### I.1.2 최신 AI 교육 평가 연구

**MRBench (Mathematical Reasoning Benchmark)**

MRBench(Hendrycks et al., 2021)는 수학적 추론 능력을 평가하기 위한 벤치마크로, 다음 평가 차원을 제시한다:
- 수학적 정확성 (Mathematical Accuracy)
- 논리적 일관성 (Logical Consistency)
- 단계별 설명 (Step-by-Step Explanation)

본 루브릭의 **B2(설명의 체계성)** 영역은 MRBench의 "단계별 설명" 개념을 채택하였다.

**RUBICON (Rubric-based Evaluation Framework)**

RUBICON(Wilson & Scalise, 2015)은 AI 교육 도구의 교육적 효과성을 평가하기 위한 루브릭 기반 프레임워크로, 다음 원칙을 제시한다:
- 다층적 평가 구조 (Multi-dimensional Assessment)
- 명확한 성취 기준 (Clear Performance Criteria)
- 분석적 채점 (Analytic Scoring)

본 루브릭은 RUBICON의 분석적 채점 방식을 채택하여, 6개 독립 영역으로 평가하도록 설계하였다.

**Socratic Rubric (소크라테스 질문 평가)**

Graesser et al.(2005)의 소크라테스 질문 평가 연구는 교육적 질문의 품질을 다음 기준으로 평가한다:
- 질문의 명료성 (Question Clarity)
- 인지적 요구 수준 (Cognitive Demand Level)
- 후속 질문 유도 (Follow-up Question Potential)

본 루브릭의 **A2(질문 구조화)** 영역은 소크라테스 평가의 "질문의 명료성" 개념을 반영하였다.

---

## I.2 예비 조사 데이터 기반 평가 영역 구성

예비 조사(385건 질문-답변)에서 관찰된 **구체적 문제 패턴**에 대응하여 6개 평가 영역을 구성하였다:

### I.2.1 질문 평가 영역 (A1-A3)

**A1. 수학적 전문성** (관찰된 문제: 45.5% 최저점)
- **문제 패턴**: "수학과 무관한 질문", "용어 오용", "교과과정 외 질문"
- **설계 근거**: Bloom의 지식 분류 + MRBench의 수학적 정확성
- **평가 초점**: 수학 개념의 정확성, 교과과정 내 위치, 용어 사용의 적절성

**A2. 질문 구조화** (관찰된 문제: 45.8% 최저점)
- **문제 패턴**: "모호하고 불명확한 질문", "질문 대상 불분명", "초점 없는 질문"
- **설계 근거**: Dewey의 "문제 명료화" 단계 + 소크라테스 질문 평가
- **평가 초점**: 질문 대상·범위·초점의 명확성, 구체적 어려움 제시

**A3. 학습 맥락 적용** (관찰된 문제: 72.3% 최저점, 가장 심각)
- **문제 패턴**: "맥락 정보 부재", "수준 미표시", "학습 목적 불명"
- **설계 근거**: Vygotsky의 ZPD + Wood의 scaffolding 이론
- **평가 초점**: 학습자 수준, 선수지식, 학습 목적, 이해 상태 명시

### I.2.2 답변 평가 영역 (B1-B3)

**B1. 학습자 맞춤도** (관찰된 문제: 평균 2.474점, 27.6% 최저점)
- **문제 패턴**: "학습자 수준 파악 실패", "일방적 설명", "난이도 조절 부재"
- **설계 근거**: Vygotsky의 ZPD + 개인화 학습 이론
- **평가 초점**: 학습자 수준 파악, 선수지식 연계, 난이도 조절, 개인화된 피드백

**B2. 설명의 체계성** (관찰된 문제: 평균 2.765점, 23.9% 최저점)
- **문제 패턴**: "비체계적 설명", "논리 비약", "핵심 누락"
- **설계 근거**: MRBench의 단계별 설명 + Bloom의 인지 과정
- **평가 초점**: 개념의 위계적 설명, 단계별 논리 전개, 핵심 요소 강조, 예시 활용

**B3. 학습 내용 확장성** (관찰된 문제: 평균 1.832점, 48.9% 최저점, 가장 심각)
- **문제 패턴**: "심화학습 유도 실패", "단답형 종결", "확장 정보 부재"
- **설계 근거**: Dewey의 "가설 형성 및 논리적 전개" 단계
- **평가 초점**: 심화학습 방향 제시, 응용문제 연계, 오개념 교정, 자기주도 학습 유도

---

## I.3 세부 평가 요소 개발

각 영역은 **5점 리커트 척도(1=매우 부족 ~ 5=매우 우수)**로 평가되며, 교사가 6개 영역 각각에 대해 전체적인 판단을 바탕으로 1~5점을 직접 부여하였다. 평가를 돕기 위해 각 영역별로 4개의 세부 평가 요소(총 24개)를 참고 가이드로 제시하였으나, 최종 점수는 교사의 종합적 판단에 따랐다.

### I.3.1 A1. 수학적 전문성 세부 요소

| 세부 요소 | 평가 기준 | 이론적 근거 |
|----------|----------|----------|
| 1. 수학 개념의 정확성 | 개념, 기호, 용어의 수학적 정확성 | Bloom 사실적 지식 |
| 2. 교과과정 내 위치 | 고등학교 수학 교육과정 범위 내 | 교육과정 표준 |
| 3. 용어 사용의 적절성 | 교과서 표준 용어 사용 여부 | 수학 교육 표준 |
| 4. 학습 단계 적합성 | 해당 학년/단원 수준에 적합한 질문 | Bloom 지식 위계 |

### I.3.2 A2. 질문 구조화 세부 요소

| 세부 요소 | 평가 기준 | 이론적 근거 |
|----------|----------|----------|
| 1. 질문 대상의 명확성 | 무엇에 대한 질문인지 명확 | Dewey 문제 정의 |
| 2. 질문 범위의 구체성 | 질문 범위가 명확히 한정됨 | 소크라테스 질문 평가 |
| 3. 질문 초점의 명료성 | 핵심 질문이 분명함 | Dewey 문제 명료화 |
| 4. 구체적 어려움 제시 | 어디서 막혔는지 구체적 설명 | 메타인지 이론 |

### I.3.3 A3. 학습 맥락 적용 세부 요소

| 세부 요소 | 평가 기준 | 이론적 근거 |
|----------|----------|----------|
| 1. 학습자 수준 명시 | 현재 이해 수준 제시 | Vygotsky ZPD |
| 2. 선수지식 제시 | 알고 있는 개념 명시 | 구성주의 학습 이론 |
| 3. 학습 목적 명시 | 왜 알고 싶은지 설명 | 목표 지향 학습 |
| 4. 이해 상태 명시 | 어디까지 이해했는지 설명 | 메타인지 이론 |

### I.3.4 B1. 학습자 맞춤도 세부 요소

| 세부 요소 | 평가 기준 | 이론적 근거 |
|----------|----------|----------|
| 1. 학습자 수준 파악 | AI가 학습자 수준을 파악 | Vygotsky ZPD |
| 2. 선수지식 연계 | 학습자 배경지식과 연결 | 구성주의 |
| 3. 난이도 조절 | 적절한 난이도로 설명 | Wood scaffolding |
| 4. 개인화된 피드백 | 학습자 특성에 맞춘 설명 | 개인화 학습 |

### I.3.5 B2. 설명의 체계성 세부 요소

| 세부 요소 | 평가 기준 | 이론적 근거 |
|----------|----------|----------|
| 1. 개념의 위계적 설명 | 기초→심화 순서 준수 | Bloom 지식 위계 |
| 2. 단계별 논리 전개 | 논리적 비약 없이 전개 | MRBench 단계별 설명 |
| 3. 핵심 요소 강조 | 중요 개념 명확히 강조 | 인지 부하 이론 |
| 4. 예시 활용 | 구체적 예시로 이해 지원 | 구성주의 |

### I.3.6 B3. 학습 내용 확장성 세부 요소

| 세부 요소 | 평가 기준 | 이론적 근거 |
|----------|----------|----------|
| 1. 심화학습 방향 제시 | 다음 학습 방향 안내 | Dewey 논리적 전개 |
| 2. 응용문제 연계 | 다른 문제로 확장 | 전이 학습 이론 |
| 3. 오개념 교정 | 잘못된 이해 바로잡기 | 개념 변화 이론 |
| 4. 자기주도 학습 유도 | 스스로 탐구하도록 유도 | 구성주의 |

---

## I.4 루브릭의 특징

본 루브릭은 기존 AI 교육 평가 연구와 다음 4가지 점에서 차별화를 시도하였다. 단, 본 루브릭은 **개발 및 탐색 단계의 평가 도구**로서, 타당도와 신뢰도 검증은 본 연구와 후속 연구를 통해 수행될 예정이다:

### I.4.1 질문 품질의 독립적 평가

**기존 연구의 한계**: MRBench, RUBICON, 소크라테스 루브릭 모두 **AI 응답 품질**에만 초점

**본 연구의 기여**: 
- **질문 영역(A1-A3)**을 독립적으로 평가
- 질문-답변 상관관계(r=0.691) 발견
- **"질문의 질이 답변의 질을 결정한다"** 실증

### I.4.2 실제 교실 데이터 기반 설계

**기존 연구**: 이론적 프레임워크 중심

**본 연구**:
- 385건 실제 학생 질문-답변 분석
- 관찰된 구체적 문제 패턴에 직접 대응
- 72.3% 맥락 부재 → A3 영역 설계
- 48.9% 확장성 결여 → B3 영역 설계

### I.4.3 전통 이론 + 최신 AI 연구 통합

**본 루브릭의 통합 구조**:

| 평가 영역 | 전통 교육 이론 | AI 평가 연구 |
|----------|--------------|-------------|
| A1 수학적 전문성 | Bloom 지식 분류 | MRBench 수학적 정확성 |
| A2 질문 구조화 | Dewey 문제 명료화 | 소크라테스 질문 평가 |
| A3 학습 맥락 | Vygotsky ZPD | 개인화 학습 연구 |
| B1 학습자 맞춤 | Vygotsky ZPD | 적응형 학습 시스템 |
| B2 설명 체계성 | Bloom 인지 과정 | MRBench 단계별 설명 |
| B3 학습 확장성 | Dewey 논리 전개 | RUBICON 학습 지원 |

### I.4.4 질문-답변 상관관계 0.691 발견

예비 조사 데이터 분석 결과:
- **질문 점수(A1-A3 총점) ↔ 답변 점수(B1-B3 총점)**: r=0.691, p<0.001
- **해석**: 질문 품질이 답변 품질의 약 48% 설명 (r²=0.477)
- **교육적 함의**: 질문 명료화가 학습 효과 향상의 핵심 메커니즘

이는 MAICE의 **"명료화 중심 설계"**의 이론적 근거가 되었다.

---

## I.5 예비 조사 루브릭에서 QAC 체크리스트로 발전

예비 조사 루브릭의 한계와 개선 과정:

### I.5.1 예비 조사 루브릭의 한계

**교사 간 신뢰도**: 평균 r=0.28, ICC(2,k)=0.29로 낮음

**원인 분석**:
1. **종합적 판단 방식**: 5점 척도로 전체 영역 평가 → 주관성 높음
2. **세부 기준 부재**: 4개 요소가 "참고"일 뿐, 명확한 기준 부재
3. **배점 불명확**: "2점"과 "3점"의 차이 기준 모호

### I.5.2 QAC 체크리스트 설계

**핵심 개선**:
1. **이진 판단(0/1)**: "있다/없다"로 명확히 판단
2. **24개 체크리스트**: 각 영역 4개 → 세부 항목으로 분해
3. **45점 만점**: 영역별 배점 명확화
4. **대화 맥락 추가**: 명료화 프로세스 효과 측정 (C영역)

**개선 결과** (6장 6.4.2절):
- AI 평가자 간 신뢰도: ICC=0.595, Cronbach's α=0.840
- 예비 조사 대비 **2배 이상 향상**

---

## I.6 루브릭 적용 결과

### I.6.1 예비 조사 (2024년 5월)
- **대상**: 385건 질문-답변
- **평가자**: 중등 수학교사 4명
- **도구**: 6영역 루브릭 (5점 리커트)
- **주요 발견**: 질문-답변 상관 0.691

### I.6.2 본 실험 (2024년 10월)
- **대상**: Agent 118세션, Freepass 162세션
- **평가자**: AI 모델 3개 (Gemini, Claude, GPT-5)
- **도구**: QAC 체크리스트 (45점 만점)
- **주요 발견**: Agent 평균 +3.15점 우위 (p<0.001, d=0.457)

---

## I.7 향후 확장 가능성

### I.7.1 실시간 평가 통합

QAC 체크리스트를 **Observer Agent**에 통합하여:
- 대화 중 실시간으로 질문-답변 품질 평가
- 교사에게 즉시 피드백 제공
- 학생 개별 학습 진도 자동 추적

### I.7.2 단원별 맞춤 확장

현재 QAC는 범용 수학 평가 도구이나:
- 단원 특성 반영한 평가 항목 추가 가능
- 예: 수학적 귀납법 → "귀납 가정 이해도" 항목
- 예: 미적분 → "극한 개념 이해도" 항목

### I.7.3 타당도 검증 연구

본 연구 이후 다음 검증 필요:
- 요인 분석으로 구조 타당도 확인
- 학업 성취도와의 준거 타당도 검증
- 종단 연구로 예측 타당도 확인

---

**작성일**: 2025년 11월 6일  
**버전**: 1.0

