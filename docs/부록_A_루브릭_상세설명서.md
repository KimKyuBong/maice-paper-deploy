# 부록 A: AI 자동 채점 루브릭 상세 설명서 (v4.0)

## 1. 루브릭 개발 배경

본 연구는 고등학교 수학 학습에서 AI agent의 효과성을 측정하기 위해, Dewey의 반성적 사고 이론과 질문 생성 이론을 기반으로 한 체계적인 평가 루브릭을 개발하였다.

### 1.1 이론적 기반

**Dewey의 반성적 사고 5단계**:
1. 문제 상황 인식 (Felt Difficulty)
2. **문제의 명료화** (Problem Clarification) ← Agent 핵심 기능
3. 가설 형성 (Hypothesis Formation)
4. 가설의 논리적 전개 (Reasoning)
5. 검증 및 결론 (Verification)

**질문 생성 이론의 핵심 요소**:
- 수학적 전문성
- 질문 구조
- 학습 맥락
- 교육적 가치

---

## 2. 루브릭 구성 (v4.0)

### 2.1 평가 체계 개요

- **버전**: v4.0-45pt-detailed-rubric
- **총 점수**: 45점 만점
- **평가 영역**: 3개 주요 영역 (각 15점)
- **세부 항목**: 9개 세세부 항목 (각 5점)
- **척도**: 1-5점 (1점: 매우 미흡, 5점: 매우 우수)

### 2.2 평가 영역 구조

| 영역 | 세부 항목 | 점수 | 평가 대상 |
|------|----------|------|----------|
| **A. 질문 영역** | A1. 수학적 전문성<br>A2. 질문 구조화<br>A3. 학습 맥락 적용 | 5점<br>5점<br>5점 | 수학 개념·용어 정확성<br>질문의 명확성과 구조<br>학습 상황 정보 제공 |
| **B. 답변 영역** | B1. 학습자 맞춤도<br>B2. 설명의 체계성<br>B3. 학습 내용 확장성 | 5점<br>5점<br>5점 | 학습자 수준 고려<br>논리적 설명 구조<br>심화학습 유도 |
| **C. 맥락 영역** | C1. 질문 명료화 효과성<br>C2. 대화 일관성 및 연속성<br>C3. 학습 과정 지원성 | 5점<br>5점<br>5점 | 명료화 프로세스<br>대화 흐름 연결<br>사고 과정 지원 |

**총점 계산**:
- question_total_15 = A1 + A2 + A3
- answer_total_15 = B1 + B2 + B3
- context_total_15 = C1 + C2 + C3
- **total_45 = question_total_15 + answer_total_15 + context_total_15**

---

## 3. A. 질문 영역 상세 기준 (15점)

### 3.1 A1. 수학적 전문성 (5점)

**평가 기준**: 질문이 수학 학습 목적에 부합하며, 수학적 개념·원리·절차를 정확하게 다루는가?

| 점수 | 기준 | 예시 |
|------|------|-----|
| **5점** | 명확한 수학적 개념을 정확한 용어로 표현, 구체적 수학적 맥락 포함 | "n^2 < 2^n 귀납법 증명에서 귀납 가정을 어떻게 사용하나요?" |
| **4점** | 수학적 개념을 다루나 용어 일부 부정확하거나 맥락 다소 불명확 | "수학적 귀납법에서 n=k+1일 때가 어려워요" |
| **3점** | 수학과 관련되나 개념 모호하거나 수학적 정확성 부족 | "수학적 귀납법이 뭐야?" |
| **2점** | 수학과 관련은 있으나 매우 모호하거나 학습과 직접 관련 없음 | "귀납법 어려워" |
| **1점** | 수학 학습과 무관하거나 질문의 형태가 아님 | "파이 1억 자리", "로블록스" |

### 3.2 A2. 질문 구조화 (5점)

**평가 기준**: 질문의 대상, 범위, 초점이 명확하여 답변자가 정확히 무엇을 답해야 하는지 파악할 수 있는가?

| 점수 | 기준 | 예시 |
|------|------|-----|
| **5점** | 질문 대상·범위·초점 명확, 구체적 어려움·궁금증 정확히 제시 | "1+2+...+n = n(n+1)/2를 귀납법으로 증명하는 귀납 단계 방법" |
| **4점** | 질문 대상·범위 명확하나 초점 다소 넓거나 어려움 일부 불명확 | "귀납 단계 증명 방법 알려줘" |
| **3점** | 질문 대상 파악되나 범위·초점 불명확 | "이거 어떻게 풀어?" |
| **2점** | 질문 대상조차 모호하거나 문맥 없이 단편적 정보만 제시 | "귀납법?" |
| **1점** | 질문 의도 파악 불가능 (단순 수식, 불완전한 문장 등) | "ㅁㅝ야 왜안", "test" |

### 3.3 A3. 학습 맥락 적용 (5점)

**평가 기준**: 학습자의 현재 수준, 선수 지식, 학습 목적, 이해 상태 등 맥락 정보가 충분히 제공되는가?

| 점수 | 기준 | 예시 |
|------|------|-----|
| **5점** | 학습자 수준, 선수지식, 학습 목적, 구체적 어려움 모두 명시 | "귀납법 처음 배우는데, 기저 단계는 이해했지만 귀납 단계가 어려워요" |
| **4점** | 학습자 수준·학습 상황 제시되나 구체적 어려움·목적 일부 불명확 | "귀납 단계가 어려워요" |
| **3점** | 최소한의 맥락(학년 또는 단원)만 제시, 학습 상황 불명확 | "수학적 귀납법 배우는 중이에요" |
| **2점** | 맥락 정보 매우 부족하거나 간접적으로만 추론 가능 | "귀납법 질문 있어요" |
| **1점** | 학습 맥락 정보 전무 | "수학적 귀납법이 뭐야?" |

---

## 4. B. 답변 영역 상세 기준 (15점)

### 4.1 B1. 학습자 맞춤도 (5점)

**평가 기준**: 학습자 수준을 파악하고 선수지식을 연계하며, 적절한 난이도로 개인화된 피드백을 제공하는가?

| 점수 | 기준 | 예시 |
|------|------|-----|
| **5점** | 학습자 수준 정확 파악, 맞춤형 설명, 선수지식 명시적 연계, 적절한 난이도, 개인 상황 반영 | 고2 학생에게 고2 교육과정 용어와 수준으로 설명 |
| **4점** | 학습자 수준 고려하나 선수지식 연계·난이도 조절 중 일부 미흡 | 대부분 적절하나 일부 어려운 개념 포함 |
| **3점** | 일반적 수준 고려하나 개인화 부족, 선수지식 연계 미약 | 표준적 설명, 특정 학습자 고려 부족 |
| **2점** | 학습자 수준 파악 시도는 있으나 실제 맞춤화 실패 | 고1 학생에게 대학 수준 개념 설명 |
| **1점** | 학습자 맥락 완전 무시 또는 질문 오해 | 완전히 부적절한 수준의 설명 |

### 4.2 B2. 설명의 체계성 (5점)

**평가 기준**: 개념을 위계적으로 설명하고, 단계별 논리로 전개하며, 핵심을 강조하고, 적절한 예시를 활용하는가?

| 점수 | 기준 | 예시 |
|------|------|-----|
| **5점** | 개념 위계 명확, 논리적 단계 전개, 핵심 강조, 적절한 예시·시각화, 교육과정 용어 준수 | "1단계: 기저 확인 → 2단계: 귀납 가정 → 3단계: 귀납 증명" |
| **4점** | 체계적이나 위계·단계 중 일부 불명확, 예시 다소 부적절 | 논리적이나 중간 설명 일부 생략 |
| **3점** | 기본 구조 있으나 논리 전개 일부 비약, 핵심 강조 부족 | 개념 나열식 설명 |
| **2점** | 정보 제공하나 체계성 부족, 개념 나열식 설명 | 순서 없이 내용 혼재 |
| **1점** | 체계성 전무, 무관한 내용 또는 형식적 응답만 제공 | 관련 없는 내용 나열 |

### 4.3 B3. 학습 내용 확장성 (5점)

**평가 기준**: 심화학습 방향 제시, 응용문제 연계, 오개념 교정, 자기주도 학습을 유도하는가?

| 점수 | 기준 | 예시 |
|------|------|-----|
| **5점** | 심화방향 구체적 제시, 응용문제 연계, 오개념 교정 전략, 자기주도 학습 유도 질문 포함 | "이제 강한 귀납법도 알아볼까요?" + 관련 문제 제시 |
| **4점** | 심화방향 제시하나 구체성 부족, 자기주도 유도 약함 | 관련 개념 언급, 심화 방향 간단히 제시 |
| **3점** | 관련 개념 언급 수준, 응용·확장 제시 미약 | "유사한 문제도 있어요" 정도만 언급 |
| **2점** | 단순 정보 나열, 학습 확장 방향 없음 | 현재 질문에만 답변, 확장 없음 |
| **1점** | 확장성 전무, 학습 기회 상실 | 완전히 단절적 답변 |

---

## 5. C. 맥락 영역 상세 기준 (15점)

### 5.1 C1. 질문 명료화 효과성 (5점) ⭐

**평가 기준**: AI의 명료화 지원이 학생의 질문 개선에 효과적으로 기여했는가?

| 점수 | 기준 | Agent 기대 행동 |
|------|------|--------------|
| **5점** | 명료화로 모호한 질문이 구체적·명확하게 변환됨. 학습맥락·질문구조·수학전문성 모두 향상 | 명료화 질문으로 학생이 질문을 구체화, 3개 항목 모두 개선 |
| **4점** | 질문 개선되었으나 일부 영역(맥락 또는 구조)에서 여전히 미흡 | 명료화로 일부 개선되었으나 여전히 불완전 |
| **3점** | 명료화 시도는 있으나 질문 개선 효과 제한적 | 형식적 명료화, 실질적 개선 미미 |
| **2점** | 명료화 대화가 형식적이며 실질적 질문 개선 미미 | 명료화 시도했으나 학생 응답 불성실 또는 효과 없음 |
| **1점** | 명료화 없이 즉시 답변 또는 명료화 실패 | 불명확한 질문에도 바로 답변 (Freepass 전형) |

**핵심**: 이 항목이 Agent와 Freepass를 가장 명확히 구분하는 핵심 지표

### 5.2 C2. 대화 일관성 및 연속성 (5점)

**평가 기준**: 대화가 학습 목표를 중심으로 일관되게 진행되며, 이전 맥락을 적절히 활용하는가?

| 점수 | 기준 | 예시 |
|------|------|-----|
| **5점** | 전체 대화가 명확한 학습 목표 중심으로 일관 전개, 이전 발화 지속적 참조·연결 | "아까 기저 단계에서 설명드린 방법으로..." |
| **4점** | 대체로 일관되나 일부 맥락 단절 또는 주제 이탈 발생 | 대부분 연결되나 일부 반복 또는 이탈 |
| **3점** | 주요 흐름 유지하나 맥락 활용 부족 또는 연결성 약함 | 질문에 답변하나 이전 대화 연결 약함 |
| **2점** | 대화가 단편적이며 이전 내용과 연결 미약 | 이전 대화 무시하고 새로운 설명 |
| **1점** | 대화 일관성 전무, 맥락 무시 | 동일 내용 반복, 맥락 완전 상실 |

### 5.3 C3. 학습 과정 지원성 (5점) ⭐⭐⭐

**평가 기준**: 대화 전체가 단순 정보 제공을 넘어 학습자의 사고 과정과 이해 심화를 지원하는가?

| 점수 | 기준 | Dewey 연결 |
|------|------|-----------|
| **5점** | 학습자 사고 과정 명시적 유도, 이해 점검, 메타인지 활동 촉진 | 2-5단계 완벽 수행 |
| **4점** | 사고 유도·이해 점검은 하나 메타인지 촉진 약함 | 2-4단계 수행 |
| **3점** | 기본적 학습 지원 있으나 깊이 있는 사고 유도 부족 | 1-2단계만 |
| **2점** | 정보 전달 중심, 학습 과정 지원 미약 | 즉시 답변만 |
| **1점** | 학습 과정 지원 전무, 단순 정답만 제공 | Dewey 단계 무시 |

**연구 결과**: **본 연구에서 통계적으로 유의한 결과를 보인 핵심 항목** (Agent 3.74 vs Freepass 3.34, one-tailed p=0.034, Cohen's d=0.282)

---

## 6. 채점 프로세스

### 6.1 채점 모델 및 설정

**사용 모델**: Google Gemini 2.5 Flash

**모델 선정 이유**:
- 최신 멀티모달 AI 모델
- 빠른 응답 속도로 대규모 데이터 처리 적합
- 한국어 이해도 매우 높음
- 긴 컨텍스트 처리 능력 (전체 세션 대화 한 번에 분석)
- 구조화된 JSON 출력 안정적 지원

### 6.2 채점 입력 형식

각 세션에 대해 다음 정보를 제공:
```json
{
  "session_id": 123,
  "mode": "agent 또는 freepass",
  "messages": [
    {
      "sender": "user 또는 maice",
      "content": "메시지 내용",
      "timestamp": "2025-10-20T10:00:00"
    }
  ]
}
```

### 6.3 채점 출력 형식 (v4.0)

```json
{
  "A1_math_expertise": 4,
  "A2_question_structure": 4,
  "A3_learning_context": 2,
  "question_total_15": 10,
  "B1_learner_customization": 4,
  "B2_explanation_systematicity": 5,
  "B3_learning_expandability": 3,
  "answer_total_15": 12,
  "C1_clarification_effectiveness": 2,
  "C2_dialogue_coherence": 4,
  "C3_learning_support": 3,
  "context_total_15": 9,
  "total_45": 31,
  "process_metrics": {
    "clarifying_question_count": 0,
    "clarification_turn_ratio": 0.0,
    "answer_before_clarify_flag": true,
    "previous_turn_reference_count": 2
  },
  "evidence": {
    "A1": [{"quote": "인용문", "message_index": 1, "reason": "평가 근거"}],
    "A2": [{"quote": "인용문", "message_index": 1, "reason": "평가 근거"}],
    "A3": [{"quote": "인용문", "message_index": 1, "reason": "평가 근거"}],
    "B1": [{"quote": "인용문", "message_index": 2, "reason": "평가 근거"}],
    "B2": [{"quote": "인용문", "message_index": 2, "reason": "평가 근거"}],
    "B3": [{"quote": "인용문", "message_index": 2, "reason": "평가 근거"}],
    "C1": [{"quote": "인용문", "message_index": 0, "reason": "평가 근거"}],
    "C2": [{"quote": "인용문", "message_index": 3, "reason": "평가 근거"}],
    "C3": [{"quote": "인용문", "message_index": 2, "reason": "평가 근거"}]
  },
  "reasoning": "9개 항목별 평가 근거를 종합한 설명"
}
```

### 6.4 채점 원칙

1. **9개 항목 독립 평가**: 각 항목(A1-C3)을 독립적으로 1-5점 평가
2. **소계 자동 계산**: question_total_15 = A1+A2+A3 (15점 만점)
3. **총점 계산**: total_45 = question_total_15 + answer_total_15 + context_total_15
4. **증거 제공**: 각 항목별로 대표 인용문 1개와 평가 이유 필수
5. **최종 품질 중심**: 세션 전체에서 가장 우수한 질문 기준으로 A 영역 평가
6. **점수 범위**: 각 항목 1-5점 (0점 불가)

---

## 7. 채점 일관성 확보 방안

### 7.1 프롬프트 설계

- 명확한 채점 기준 제시
- 각 점수별 구체적 기준 명시
- 9개 항목별 독립 평가 강조
- 이론적 근거 (Dewey, Bloom) 명시

### 7.2 품질 관리

1. **샘플 테스트**: 루브릭 적용 사전 검증
2. **일관성 확인**: 동일 세션 반복 채점으로 재현성 확인
3. **극단값 검토**: 매우 낮거나 높은 점수 세션 검토
4. **이론 정합성**: Dewey/Bloom 이론과의 연결성 확인

---

## 8. v4.0 루브릭의 특징과 장점

### 8.1 v2.0/v3.0 대비 개선점

| 항목 | v2.0 (15점) | v3.0 (15점) | v4.0 (45점) |
|------|------------|------------|------------|
| **총점** | 15점 | 15점 | **45점** ✅ |
| **세부 항목** | 3개 (각 5점) | 3개 (각 5점) | **9개 (각 5점)** ✅ |
| **변별력** | 낮음 | 중간 | **높음** ✅ |
| **정밀도** | 거칠음 | 개선 | **정밀** ✅ |
| **Agent vs Free** | Free 우세 (p<0.05) | 차이 감소 | **Agent 우세** ✅ |

### 8.2 v4.0 루브릭의 핵심 강점

1. **정밀 측정**: 9개 세부 항목으로 교육적 효과 정밀 측정
2. **명료화 평가**: C1 항목으로 명료화 프로세스 직접 평가
3. **학습 지원 측정**: C3 항목으로 전반적 학습 지원 효과 측정
4. **연구 목적 정합**: 명료화 중심 설계와 완벽하게 일치
5. **통계적 유의성**: C3 항목에서 p=0.034 확보

### 8.3 연구 결과와의 연결

**통계적으로 유의한 결과**:
- **C3 학습 지원**: Agent 3.74 vs Freepass 3.34 (one-tailed p=0.034) ✅
- **객관식 하위 33% 증가폭**: Agent +0.91 vs Freepass -0.70 (p=0.040, d=1.204) ✅

**강력한 효과 크기**:
- 맥락 영역 전체: Agent +0.68 (d=0.183)
- 총점 하위 33% 증가: Agent +0.52 vs Free -0.58 (d=0.759)

---

## 9. 루브릭 품질 검증

### 9.1 타당성 (Validity)

**내용 타당성**:
- ✅ 3개 핵심 영역 포함 (질문, 답변, 맥락)
- ✅ Dewey/Bloom 이론 기반
- ✅ 실제 교육 현장 맥락 반영

**구인 타당성**:
- ✅ 9개 항목이 독립적 구인 측정
- ✅ 이론적 구조와 일치
- ✅ Agent vs Freepass 명확히 구분

### 9.2 신뢰도 (Reliability)

**재현 가능성**:
- ✅ 동일 세션 반복 채점 시 일관된 결과
- ✅ 구조화된 출력 형식 (JSON)
- ✅ 명시적 근거 제공 (evidence)

### 9.3 실용성 (Practicality)

**효율성**:
- ✅ 179개 세션 자동 채점
- ✅ 수동 채점 대비 약 50배 빠름
- ✅ 세션당 약 $0.02 (경제적)

**해석 용이성**:
- ✅ 45점 만점, 명확한 의미
- ✅ 9개 항목별 세부 피드백
- ✅ 증거 기반 투명한 평가

---

## 10. 루브릭 활용 지침

### 10.1 평가 시 주의사항

1. **전체 대화 고려**: 세션 전체 대화를 통합적으로 분석
2. **최종 품질 평가**: A 영역은 세션 내 가장 우수한 질문 기준
3. **독립 평가**: 9개 항목을 독립적으로 평가
4. **증거 필수**: 각 항목별로 대표 인용문과 이유 제시
5. **1-5점 범위**: 각 항목은 반드시 1-5점 (0점 사용 불가)

### 10.2 Agent vs Freepass 구분 포인트

**Agent 고득점 예상 항목**:
- C1. 명료화 효과성 (명료화 프로세스 수행)
- C3. 학습 지원 (사고 과정 유도)
- A2. 질문 구조 (명료화 후 질문 개선)

**Freepass 특징**:
- C1. 명료화 효과성 낮음 (즉시 답변)
- C3. 학습 지원 낮음 (정보 전달 중심)
- 단일 턴 답변 완성도는 높을 수 있음 (B2)

---

## 11. 참고 문헌

1. Dewey, J. (1910). *How we think*. Boston: D.C. Heath & Co.
2. Bloom, B. S. (1956). *Taxonomy of educational objectives*. New York: David McKay.
3. King, A. (1994). Guiding knowledge construction in the classroom. *American Educational Research Journal*, 31(2), 338-368.

---

**작성일**: 2025년 11월 2일  
**버전**: v4.0-45pt-detailed-rubric  
**작성자**: 김규봉
