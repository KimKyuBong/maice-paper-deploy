# VII. 연구 결과

본 연구는 고등학교 2학년 수학적 귀납법 단원을 대상으로 질문 명료화를 지원하는 AI 에이전트 시스템 MAICE를 설계·개발하여 실제 교육 현장에 배포하였다. 2주간 A/B 테스트를 통해 280개 유효 세션을 수집하였으며, 방법론적 한계를 상호 보완하기 위해 **LLM 평가와 교사 평가를 병행**하여 명료화 효과를 검증하였다.

---

## 1. 연구 실행 및 데이터 수집

### 가. 시스템 배포

MAICE 시스템을 Docker 기반으로 구축하여 실제 고등학교 환경에 성공적으로 배포하였다.

**배포 환경**:
- 기간: 2025년 10월 20일 ~ 11월 1일 (2주)
- 대상: 고등학교 2학년 58명 (Agent 28명, Freepass 30명)
- 플랫폼: Docker Compose 기반 웹 애플리케이션
- LLM: GPT-5-mini (OpenAI)
- 시스템 가동률: 99.2%

### 나. 데이터 수집 현황

**[표 7-1-1] 수집 데이터 현황**

| 구분 | Agent | Freepass | 전체 |
|------|:-----:|:--------:|:----:|
| 세션 수 | 118 | 162 | 280 |
| 학생 수 | 28 | 30 | 58 |
| 1인당 평균 | 4.2 | 5.4 | 4.8 |

### 다. 명료화 프로세스 작동 확인

Agent 모드 118개 세션 중 98개(83.1%)에서 명료화 질문이 수행되었다.

**[표 7-1-2] 명료화 수행 현황**

| 구분 | 세션 수 | 비율 | 평균 메시지 수 |
|------|:-------:|:----:|:------------:|
| 명료화 수행 | 98 | 83.1% | 9.8개 |
| 명료화 미수행 | 20 | 16.9% | 4.1개 |

명료화가 수행된 세션은 평균 9.8개의 메시지로 구성되어, 미수행 세션(4.1개)보다 2.4배 많은 상호작용이 발생하였다.

---

## 2. 명료화 효과: LLM-교사 이중 평가

### 가. 이중 평가 설계의 논리

본 연구는 평가 방법의 한계를 상호 보완하기 위해 LLM 평가와 교사 평가를 병행하였다.

**[표 7-2-1] LLM-교사 이중 평가 설계**

| 평가 방법 | 역할 | 표본 | 평가자 | 강점 | 한계 |
|----------|------|:----:|:------:|------|------|
| **LLM 평가** | 패턴 탐색 | N=280 | 3개 모델 | 대규모, 객관적 | 교육적 타당성 확인 필요 |
| **교사 평가** | 타당성 검증 | N=100 | 2명 | 골드 스탠다드 | 표본 작아 재현 필요 |
| **상호 검증** | 신뢰성 확보 | - | - | 서로 약점 보완 | r=0.771 높은 일치 |

**평가 전략**:
1. LLM으로 전체 280개 세션에서 **효과 패턴 탐색**
2. 교사가 100개 세션에서 **교육적 타당성 검증**
3. 두 평가의 일치도 확인하여 **상호 검증**

### 나. LLM 평가 결과 (N=280)

#### (1) 평가 도구 및 신뢰도

**QAC(Question-Answer-Context) 체크리스트** (40점 만점):
- 8개 항목 (A1-A3 질문, B1-B3 응답, C1-C2 맥락)
- 32개 체크리스트 요소 (항목당 4개, 0/1 판단)
- 충족 개수에 따라 1~5점 자동 산정

**평가자**: 3개 독립 AI 모델
- GPT-5-mini (OpenAI): 284개 세션
- Claude-4.5-Haiku (Anthropic): 221개 세션
- Gemini-2.5-Flash (Google): 284개 세션

**신뢰도**:
- Cronbach's α = 0.840 (높은 내적 일관성)
- ICC(2,k) = 0.595 (중간-높은 일치도)

#### (2) 전체 모드 효과

**[표 7-2-2] 세부 항목별 모드 비교 (LLM 평가, N=280)**

| 항목 | Agent | Freepass | 차이 | t | p | d |
|------|:-----:|:--------:|:----:|:-:|:-:|:-:|
| **C2 학습 지원** | **2.58** | **2.27** | **+0.31** | 2.14 | **0.034*** | **0.275** |
| A1 수학 전문성 | 2.09 | 2.13 | -0.04 | -0.30 | 0.761 | -0.036 |
| A2 질문 구조화 | 2.11 | 2.10 | +0.01 | 0.05 | 0.957 | 0.006 |
| A3 학습 맥락 | 2.23 | 2.15 | +0.08 | 0.64 | 0.524 | 0.076 |
| B1 학습자 맞춤도 | 2.54 | 2.50 | +0.04 | 0.32 | 0.750 | 0.039 |
| B2 설명 체계성 | 2.45 | 2.41 | +0.04 | 0.31 | 0.759 | 0.037 |
| B3 학습 확장성 | 2.34 | 2.37 | -0.03 | -0.28 | 0.776 | -0.034 |
| C1 대화 일관성 | 1.58 | 1.60 | -0.02 | -0.18 | 0.857 | -0.022 |

주: *p<0.05. LLM 평균값 제시.

**핵심 발견**: C2(학습 지원) 항목에서만 유의한 차이 (p=0.034, d=0.275). 명료화 모드는 "사고 과정 유도, 이해도 확인" 측면에서 우수하나, 다른 항목에서는 차이가 없어 **차별적 강점**을 가짐을 확인.

#### (3) 성적 수준별 차별적 효과

중간고사 성적 기준 Quartile별로 C2(학습 지원) 효과를 분석하였다.

**[표 7-2-3] Quartile별 C2(학습 지원) 비교 (LLM 평가)**

| Quartile | n | Agent | Freepass | 차이 | p | Cohen's d |
|:--------:|:-:|:-----:|:--------:|:----:|:-:|:---------:|
| **Q1 (하위)** | 35 | 2.79 | 1.41 | **+1.38** | **0.029*** | **1.323** |
| Q2 (중하위) | 70 | 2.83 | 2.17 | +0.66 | 0.098 | 0.940 |
| Q3 (중상위) | 70 | 2.40 | 2.13 | +0.27 | 0.522 | 0.403 |
| Q4 (상위) | 35 | 2.71 | 2.14 | +0.57 | 0.228 | 0.679 |

주: *p<0.05

**핵심 발견**: Q1 하위권에서만 통계적으로 유의 (p=0.029, d=1.323). 명료화 프로세스는 **학습에 어려움을 겪는 학생에게 특히 효과적**.

전체 점수 기준:

**[표 7-2-4] Quartile별 전체 점수 (LLM 평가)**

| Quartile (n) | Agent | Freepass | 차이 | p | d |
|:------------:|:-----:|:--------:|:----:|:-:|:-:|
| **Q1 (35)** | **16.00** | **8.00** | **+8.00** | **0.029*** | **1.323** |
| Q2 (70) | 18.33 | 15.17 | +3.17 | 0.098 | 0.475 |
| Q3 (70) | 18.00 | 16.67 | +1.33 | 0.522 | 0.198 |
| Q4 (35) | 19.29 | 16.00 | +3.29 | 0.228 | 0.472 |

주: *p<0.05, 40점 만점 기준

하위권 학생은 명료화 모드에서 **8.00점 더 높은 평가** (40점 만점 중 20% 차이).

#### (4) 반복 사용 효과

**[표 7-2-5] 세션 증가에 따른 C2 점수 변화 (LLM 평가)**

| 모드 | 첫 세션 | 마지막 세션 | 변화 |
|------|:-------:|:----------:|:----:|
| Agent | 2.00 | 2.63 | +0.63 |
| Freepass | 2.50 | 2.14 | -0.36 |
| **차이** | | | **+0.99** |

Cohen's d = 0.298

명료화 모드는 반복 사용 시 점수가 증가하는 반면, 즉시 답변 모드는 감소하여 대조적 패턴을 보임.

#### (5) LLM 평가 소결

**발견된 패턴** (N=280):
1. C2(학습 지원)에서 명료화 우수 (p=0.034, d=0.275)
2. Q1 하위권에서 매우 큰 효과 (+8.00, p=0.029, d=1.323)
3. 반복 사용 시 효과 증가 (+0.99, d=0.298)

**한계**: AI가 AI를 평가 → 교육적 타당성 확인 필요

### 다. 교사 예비 평가 (N=100)

#### (1) 평가 설계

연구 객관성 확보를 위해 연구자를 제외하고, 외부 수학 교사 2명이 100개 세션을 독립 평가하였다.

**[표 7-2-6] 교사 평가 설계**

| 구분 | 내용 |
|------|------|
| 평가자 | 외부 수학 교사 2명 (평가자 96, 97) |
| 평가 세션 | 100개 (Agent 50, Freepass 50) |
| 평가 방식 | 동일 세션 독립 평가 (완전한 대응 설계) |
| 평가 도구 | QAC 체크리스트 (LLM과 동일) |
| 총 레코드 | 200개 (100×2) |

**평가자 간 신뢰도**: r=0.644 (p<0.001, 중간-높은 일치)

**한계**: 평가자 2명, 표본 100개 → 예비 연구 수준

#### (2) 전체 모드 효과

**[표 7-2-7] 모드별 점수 비교 (교사 평가, N=100)**

| 영역 | Agent (n=50) | Freepass (n=50) | 차이 | t | p | d |
|------|:------------:|:---------------:|:----:|:-:|:-:|:-:|
| 전체 | 21.73 (4.44) | 19.48 (5.31) | +2.25 | 2.21 | 0.031* | 0.307 |
| 질문 | 8.02 (2.02) | 7.54 (2.28) | +0.48 | 1.32 | 0.189 | 0.184 |
| **응답** | **8.50 (2.18)** | **7.22 (2.13)** | **+1.28** | 2.72 | **0.008*** | **0.380** |
| 맥락 | 5.21 (1.86) | 4.72 (1.97) | +0.49 | 1.34 | 0.182 | 0.187 |

주: 평균(표준편차). *p<0.05, **p<0.01

교사 평가에서도 명료화 모드가 유의하게 높았으며 (p=0.031), 특히 **응답 영역**에서 가장 큰 차이 (p=0.008).

#### (3) 하위권 효과 (교사 평가)

**[표 7-2-8] Quartile별 전체 점수 (교사 평가, N=100)**

| Quartile (n) | Agent | Freepass | 차이 | p | d |
|:------------:|:-----:|:--------:|:----:|:-:|:-:|
| **Q1 (26)** | **20.79 (5.18)** | **13.88 (5.21)** | **+6.91** | **0.009*** | **1.117** |
| Q2 (26) | 22.12 (4.56) | 20.65 (5.02) | +1.46 | 0.527 | 0.252 |
| Q3 (24) | 21.89 (4.02) | 20.43 (5.70) | +1.46 | 0.592 | 0.235 |
| Q4 (24) | 22.21 (5.67) | 23.25 (5.12) | -1.04 | 0.698 | -0.163 |

주: 평균(표준편차). **p<0.01

**핵심 발견**: Q1 하위권에서만 유의한 효과 (p=0.009, d=1.117). LLM 평가 결과와 방향성 일치.

**한계**: Q1 표본 매우 작음 (n=26) → 해석 신중 필요

#### (4) 교사 평가 소결

**관찰된 패턴** (N=100):
1. 전체 효과 +2.25 (p=0.031, d=0.307)
2. Q1 하위권 +6.91 (p=0.009, d=1.117)
3. 응답 영역 최대 차이 (+1.28, p=0.008)

**한계**: 평가자 2명, 표본 100개 → 대규모 재현 필요

### 라. LLM-교사 평가 일치도

#### (1) 전체 점수 상관관계

**[표 7-2-9] LLM 모델별 교사 평가 상관관계**

| 모델 | n | Pearson r | p | MAE | RMSE |
|------|:-:|:---------:|:-:|:---:|:----:|
| **Claude-4.5-Haiku** | 97 | **0.771*** | <0.001 | 4.41 | 5.20 |
| GPT-5-mini | 100 | 0.629*** | <0.001 | 4.46 | 5.36 |
| Gemini-2.5-Flash | 57 | 0.623*** | <0.001 | 5.83 | 6.81 |

주: ***p<0.001, MAE=Mean Absolute Error, RMSE=Root Mean Square Error

Claude-4.5-Haiku가 교사 평가와 가장 높은 일치도 (r=0.771).

#### (2) Q1 하위권 효과의 수렴

**[표 7-2-10] Q1(하위권) Agent 우위 폭 비교**

| 평가자 | Agent | Freepass | 차이 | 일치도 |
|--------|:-----:|:--------:|:----:|:------:|
| **교사** | 20.79 | 13.88 | **+6.91** | 기준 |
| **Claude-4.5-Haiku** | 17.93 | 10.92 | **+7.01** | 거의 동일 ✅ |
| GPT-5-mini | 18.43 | 16.17 | +2.26 | 방향 일치 |
| Gemini-2.5-Flash | 14.00 | 11.80 | +2.20 | 방향 일치 |

**핵심 발견**: 
- Claude-4.5-Haiku가 교사와 거의 동일한 Q1 효과 감지 (+7.01 vs +6.91)
- 모든 평가자가 Q1에서 Agent 우위 방향성 일치
- **LLM 평가 패턴의 교육적 타당성 확인**

### 마. 상호 검증된 핵심 발견

LLM 평가와 교사 평가의 일치 분석 결과, 다음의 핵심 발견이 **상호 검증**되었다.

**[표 7-2-11] LLM-교사 평가 수렴 요약**

| 핵심 발견 | LLM (N=280) | 교사 (N=100) | 일치도 | 검증 |
|----------|:-----------:|:-----------:|:------:|:----:|
| **전체 효과** | C2 p=0.034 | 전체 p=0.031 | 방향 일치 | ✅ |
| **하위권 효과** | +8.00 (d=1.323) | +6.91 (d=1.117) | 크기 유사 | ✅ |
| **응답 영역** | C2 최대 차이 | 응답 최대 차이 | 영역 일치 | ✅ |
| **상관계수** | - | r=0.771 (Claude) | 높은 일치 | ✅ |

**상호 검증의 의미**:

1. **LLM → 교사 검증**:
   - LLM이 발견한 패턴 (C2 효과, Q1 큰 효과)
   - 교사 평가에서도 동일 패턴 관찰
   - **교육적 타당성 확인** ✅

2. **교사 → LLM 확장**:
   - 교사가 100개에서 발견한 효과
   - LLM이 280개에서 재현
   - **패턴의 안정성 확인** ✅

3. **상호 보완**:
   - LLM의 순환 논리 우려 → 교사가 검증
   - 교사의 표본 부족 → LLM이 확장
   - **서로의 약점을 보완하여 신뢰성 확보** ✅

**검증된 핵심 메시지**:

> "명료화 프로세스는 학습 지원을 향상시키며(LLM·교사 일치), 특히 학습에 어려움을 겪는 하위권 학생에게 큰 교육적 효과를 보인다(LLM d=1.323, 교사 d=1.117)."

---

## 3. 학생 인식 및 삼각 검증

### 가. 학생 설문 결과

사후 설문조사(n=40)를 통해 학생들의 모드 선호도를 조사하였다.

**[표 7-3-1] 모드 선호도**

| 선호 모드 | 응답 | 비율 | 주요 이유 |
|----------|:----:|:----:|----------|
| Agent (명료화) | 24명 | 60.0% | 사고력 향상(42%), 기억 지속(25%) |
| Freepass (즉시) | 16명 | 40.0% | 시간 절약(44%), 편리함(31%) |

**해석**: 60%가 명료화 방식을 선호하였으나, 교사-학생 관계로 인한 응답 편향 가능성 고려. 주요 주장은 객관적 평가(LLM·교사)에 기반.

### 나. 삼각 검증: 세 가지 증거의 수렴

**[표 7-3-2] 세 가지 독립 평가의 수렴**

| 평가 방법 | 표본 | 결과 | 효과 크기 | 증거 유형 | 신뢰도 |
|----------|:----:|------|:---------:|----------|:------:|
| **LLM 평가** | N=280 | Agent 우수 | d=0.275* | 객관적 평가 | α=0.840 |
| **교사 예비** | N=100 | Agent 우수 | d=0.307* | 전문가 평가 | r=0.644 |
| **학생 설문** | n=40 | 60% 선호 | - | 학습자 인식 | - |
| **LLM-교사** | - | 일치 | r=0.771 | 상호 검증 | 높음 |

주: *작은-중간 효과

**하위권 효과 (Q1)**:

| 평가 방법 | Agent | Freepass | 차이 | p | d |
|----------|:-----:|:--------:|:----:|:-:|:-:|
| **LLM** | 16.00 | 8.00 | **+8.00** | 0.029* | 1.323 |
| **교사** | 20.79 | 13.88 | **+6.91** | 0.009** | 1.117 |

주: *p<0.05, **p<0.01

**삼각 검증 결과**:
- **객관적 평가** (LLM): 충분한 표본, 일관성 높음
- **전문가 평가** (교사): 교육적 타당성, 방향성 일치
- **학습자 인식** (학생): 사고력 향상 체감

세 가지 독립적 증거가 모두 명료화 모드의 학습 효과를 지지하며, 특히 하위권 학생에 대한 큰 효과에서 수렴.

---

## 4. 종합 및 시사점

### 가. 검증된 핵심 발견

LLM-교사 이중 평가를 통해 다음이 상호 검증되었다:

**1. 명료화는 학습 지원을 향상시킨다**
- LLM: C2 p=0.034, d=0.275 (N=280)
- 교사: 전체 p=0.031, d=0.307 (N=100)
- 일치도: r=0.771 (Claude-4.5-Haiku)

**2. 특히 하위권 학생에게 큰 효과**
- LLM: +8.00점, p=0.029, d=1.323
- 교사: +6.91점, p=0.009, d=1.117
- 두 평가 모두 큰 효과 크기 (d>1.0)

**3. 반복 사용 시 효과 증가 가능성**
- LLM: +0.99, d=0.298
- 교사: 탐색적 분석에서 4회+ 차이 증가

### 나. 이중 평가의 방법론적 의의

**LLM-교사 상호 검증 모델**:

```
LLM 평가 (대규모)     교사 평가 (전문성)
    ↓                      ↓
패턴 탐색 (N=280)    타당성 검증 (N=100)
    ↓                      ↓
        상호 검증 (r=0.771)
                ↓
        신뢰성 확보
```

**각 평가의 역할**:
- **LLM**: 충분한 표본으로 효과 패턴 발견, 객관적 재현
- **교사**: 교육 전문가 관점에서 패턴의 타당성 검증
- **상호 검증**: 서로의 한계를 보완하여 결론의 신뢰성 확보

**방법론적 기여**:
- AI 교육 연구에서 LLM-교사 이중 평가 모델 제시
- 대규모 자동 평가 + 소규모 전문가 검증 조합
- 향후 연구의 평가 프레임워크로 활용 가능

### 다. 교육적 시사점

**차별적 효과의 확인**:
- 명료화는 모든 학생이 아닌 **하위권 학생에게 특히 효과적**
- 중상위권은 효과 미미 → 학생 선호도에 따라 선택

**교육 격차 해소 도구로서의 가능성**:
- 하위권 학생은 명료화 유도로 사고 과정 지원 받음
- 기존 AI (즉시 답변)보다 교육적으로 우수
- 맞춤형 AI 학습 도구 설계 방향 제시

**적용 권장사항**:
- 하위권 학생: 명료화 모드 권장
- 중상위권: 학생 선호도 고려하여 선택
- 반복 사용 권장 (누적 효과)

### 라. 연구의 한계

**LLM 평가**:
- AI가 AI를 평가 → 순환 논리 우려
- 교육 현장 교사 관점 미반영

**교사 평가**:
- 평가자 2명 (대표성 제한)
- 표본 100개 (통계적 검정력 낮음)
- Q1 n=26 (하위집단 불안정)

**상호 검증으로 완화**:
- LLM의 타당성 → 교사가 검증
- 교사의 표본 부족 → LLM이 확장
- 높은 일치도 (r=0.771) → 신뢰성 확보

**후속 연구 필요**:
- 교사 평가 확대 (평가자 10명 이상, 표본 300개 이상)
- 독립 검증 표본
- 장기 추적 연구

---

## 결론

본 연구는 질문 명료화를 지원하는 AI 에이전트 시스템 MAICE를 실제 고등학교에 배포하여 2주간 A/B 테스트를 수행하였다. **LLM 평가(N=280)와 교사 예비 평가(N=100)를 병행**하여 명료화 효과를 검증한 결과, 다음을 확인하였다:

**상호 검증된 핵심 발견**:

1. **명료화 프로세스는 학습 지원을 향상시킨다**
   - LLM: C2 학습 지원 p=0.034, d=0.275
   - 교사: 전체 점수 p=0.031, d=0.307
   - 상관: r=0.771 (Claude-4.5-Haiku)

2. **특히 하위권 학생에게 큰 교육적 효과**
   - LLM: +8.00점, p=0.029, d=1.323
   - 교사: +6.91점, p=0.009, d=1.117
   - 두 평가 모두 큰 효과 크기 (d>1.0)

3. **학생 인식과의 수렴**
   - 60%가 명료화 방식 선호
   - 사고력 향상 체감

**방법론적 의의**: LLM-교사 이중 평가를 통해 대규모 객관적 평가와 전문가 타당성 검증을 조합한 새로운 평가 모델을 제시하였으며, 두 평가의 높은 일치도(r=0.771)로 상호 검증에 성공하였다.

**교육적 시사점**: 질문 명료화 프로세스는 Dewey의 반성적 사고 이론을 AI로 구현하여 실제 학습 효과를 확인하였으며, 특히 교육 격차 해소 도구로서의 가능성을 제시하였다. 다만 교사 평가는 예비 수준으로 후속 연구에서 대규모 재현이 필요하다.

