# V. 연구 결과

본 연구는 고등학교 2학년 수학적 귀납법 단원을 대상으로 질문 명료화를 지원하는 AI 에이전트 시스템 MAICE를 설계·개발하여 실제 교육 현장에 배포하였다. 연구 대상은 2학년 수학 과목 수강생 58명(자퇴생 제외)이며, 이 중 55명(Agent 모드 27명, Freepass 모드 28명)이 MAICE를 실제로 이용하였다. 3주간 A/B 테스트를 통해 이들 55명 학생이 생성한 유효 세션 284개(Agent 115개, Freepass 169개)를 수집하였으며, 방법론적 한계를 상호 보완하기 위해 **LLM 평가(3개 모델)와 교사 평가를 병행**하여 명료화 효과를 검증하였다.

---

## 1. 연구 실행 및 데이터 수집

### 가. 시스템 배포

MAICE 시스템을 실제 고등학교에 배포하였다 (3주, N=58, 시스템 가동률 99.2%).

### 나. 데이터 수집 현황

**[표Ⅴ-1] 수집 데이터 현황**

| 구분 | Agent | Freepass | 전체 |
|------|:-----:|:--------:|:----:|
| 세션 수 | 115 | 169 | 284 |
| 학생 수 | 27 | 28 | 55 |
| 1인당 평균 | 4.3 | 6.0 | 5.2 |

주: LLM 3개 모델 평가 공통 세션 기준. 등록 학생 58명 중 유효 세션 소유자 55명.

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/05_chapter5_evidence/ch5_1_n_data_collection.py` (5장 1절 나항, 표Ⅴ-1)
- 데이터 파일: `statistical_evidence/data/session_data/full_sessions_with_scores.csv`
- 결과 파일: `statistical_evidence/05_chapter5_evidence/results/ch5_1_n_data_collection.json`

### 다. 사전 동질성 검증

두 집단 간 중간고사 성적 차이 없음 (총점: t=0.95, p=0.345).

**주의사항**: 
- Agent 모드 평균 56.59점 (SD=16.99, n=27), Freepass 모드 평균 52.11점 (SD=17.86, n=28)으로 4.49점 차이가 있었으나 통계적으로 유의하지 않음(p=0.345)
- 이 차이가 결과에 미친 영향을 완전히 배제할 수 없으므로, 해석 시 주의가 필요함

### 라. 명료화 프로세스 작동 확인

Agent 모드 115개 세션 중 88개(76.5%)에서 명료화 질문이 수행되었다.

**[표Ⅴ-2] 명료화 수행 현황**

| 구분 | 세션 수 | 비율 | 평균 메시지 수 |
|------|:-------:|:----:|:------------:|
| 명료화 수행 | 88 | 76.5% | 4.8개 |
| 명료화 미수행 | 27 | 23.5% | 0.0개 |

명료화가 수행된 세션은 평균 4.8개의 메시지로 구성되었다.

---

## 2. 명료화 효과: LLM-교사 이중 평가

### 가. 이중 평가 설계의 논리

본 연구는 평가 방법의 한계를 상호 보완하기 위해 LLM 평가와 교사 평가를 병행하였다.

**[표Ⅴ-3] LLM-교사 이중 평가 설계**

| 평가 방법 | 역할 | 표본 | 평가자 | 강점 | 한계 |
|----------|------|:----:|:------:|------|------|
| **LLM 평가** | 패턴 탐색 | N=284 | 3개 모델 | 대규모, 객관적 | 교육적 타당성 확인 필요 |
| **교사 평가** | 타당성 검증 | N=100 | 2명 | 골드 스탠다드 | 표본 작아 재현 필요 |
| **상호 검증** | 신뢰성 확보 | - | - | 서로 약점 보완 | r=0.754 높은 일치 |

**평가 전략**:
1. LLM으로 전체 284개 세션에서 **효과 패턴 탐색**
2. 교사가 100개 세션에서 **교육적 타당성 검증**
3. 두 평가의 일치도 확인하여 **상호 검증**

### 나. LLM 평가 결과 (N=284)

#### (1) 평가 신뢰도

**QAC 체크리스트** (40점, 상세: II장 8절): 3개 AI 모델 평가 (Gemini, Claude, GPT-5)
- **신뢰도**: Cronbach's α=0.872, ICC=0.656, Pearson r=0.718
- **결과**: 3개 모델 평균값 제시

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/01_llm_scoring/llm_reliability_analysis.py` (실행 시각: 최신)
- 데이터 파일: `statistical_evidence/data/llm_evaluations/llm_3models_284_PERFECT_FINAL.csv`
- 결과 파일: `statistical_evidence/01_llm_scoring/results/llm_reliability_results.json`

#### (2) 전체 모드 효과

**[표Ⅴ-4] 세부 항목별 모드 비교 (LLM 평가, N=284)**

| 항목 | Agent | Freepass | 차이 | t | p | d |
|------|:-----:|:--------:|:----:|:-:|:-:|:-:|
| **C2 학습 지원** | **2.32** | **2.05** | **+0.28** | 2.86 | **0.004*** | **0.353** |
| A1 수학 전문성 | 3.80 | 3.70 | +0.10 | 0.98 | 0.330 | 0.120 |
| A2 질문 구조화 | 4.50 | 4.57 | -0.06 | -0.66 | 0.511 | -0.078 |
| A3 학습 맥락 | 1.26 | 1.47 | -0.21 | -3.41 | **0.001*** | -0.425 |
| B1 학습자 맞춤도 | 3.66 | 3.52 | +0.14 | 1.19 | 0.233 | 0.145 |
| B2 설명 체계성 | 4.56 | 4.61 | -0.05 | -0.40 | 0.692 | -0.047 |
| B3 학습 확장성 | 1.97 | 1.74 | +0.22 | 2.05 | 0.041* | 0.245 |
| C1 대화 일관성 | 4.41 | 4.47 | -0.06 | -0.64 | 0.524 | -0.076 |

주: *p<0.05, **p<0.01. LLM 3개 모델(Gemini 2.5 Flash, Claude 4.5 Haiku, GPT-5 mini) 평균값.

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/04_effect_size/mode_quartile_analysis_perfect.py` (5장 2절 나항 (2) 전체 모드 효과, 표Ⅴ-4)
- 데이터 파일: `statistical_evidence/01_llm_scoring/results/llm_3models_averaged_perfect.csv`, `statistical_evidence/data/session_data/full_sessions_with_scores.csv`
- 결과 파일: `statistical_evidence/04_effect_size/results/mode_comparison_perfect.json`

**핵심 발견**: 
- **C2(학습 지원)**: Agent 우수 (p=0.004, d=0.353) - 사고 과정 유도, 이해도 확인에서 강점
- **B3(학습 확장성)**: Agent 우수 (p=0.041, d=0.248) - 추가 질문, 심화 학습 유도
- **A3(학습 맥락)**: Freepass 우수 (p=0.001, d=-0.411) - 학습 목표, 수준 반영

명료화 모드는 학습 과정 지원에서 차별적 강점을 가지나, 학습 맥락 파악에서는 즉시 답변 모드가 다소 우수.

#### (3) 성적 수준별 차별적 효과

중간고사 성적 기준 Quartile별로 C2(학습 지원) 효과를 분석하였다.

**[표Ⅴ-5] Quartile별 C2(학습 지원) 비교 (LLM 평가)**

| Quartile | n | Agent | Freepass | 차이 | p | Cohen's d |
|:--------:|:-:|:-----:|:--------:|:----:|:-:|:---------:|
| **Q1 (하위)** | 85 | 2.24 | 1.73 | **+0.51** | **<0.001*** | **0.855** |
| Q2 (중하위) | 61 | 2.30 | 2.25 | +0.05 | 0.839 | 0.052 |
| Q3 (중상위) | 52 | 2.31 | 2.01 | +0.30 | 0.238 | 0.369 |
| Q4 (상위) | 86 | 2.42 | 2.29 | +0.13 | 0.471 | 0.160 |

주: ***p<0.001, LLM 3개 모델(Gemini, Claude, GPT-5) 평균값

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/04_effect_size/mode_quartile_analysis_perfect.py` (5장 2절 나항 (3) 성적 수준별 차별적 효과, 표Ⅴ-5)
- 데이터 파일: `statistical_evidence/01_llm_scoring/results/llm_3models_averaged_perfect.csv`, `statistical_evidence/data/session_data/full_sessions_with_scores.csv`, `statistical_evidence/data/session_data/midterm_scores_with_quartile.csv`
- 결과 파일: `statistical_evidence/04_effect_size/results/quartile_analysis_perfect.json`

**핵심 발견**: Q1 하위권에서 통계적으로 매우 유의 (p<0.001, d=0.855). 명료화 프로세스는 **학습에 어려움을 겪는 학생에게 특히 효과적**.

전체 점수 기준:

**[표Ⅴ-6] Quartile별 전체 점수 (LLM 평가)**

| Quartile (n) | Agent | Freepass | 차이 | p | d |
|:------------:|:-----:|:--------:|:----:|:-:|:-:|
| **Q1 (85)** | **26.52** | **24.26** | **+2.26** | **0.032*** | **0.499** |
| Q2 (61) | 27.08 | 27.07 | +0.01 | 0.989 | 0.004 |
| Q3 (52) | 25.50 | 26.88 | -1.38 | 0.345 | -0.251 |
| Q4 (86) | 26.30 | 27.00 | -0.70 | 0.531 | -0.133 |

주: *p<0.05, 40점 만점, LLM 3개 모델 평균값

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/04_effect_size/mode_quartile_analysis_perfect.py` (5장 2절 나항 (3) 성적 수준별 차별적 효과, 표Ⅴ-6)
- 데이터 파일: `statistical_evidence/01_llm_scoring/results/llm_3models_averaged_perfect.csv`, `statistical_evidence/data/session_data/full_sessions_with_scores.csv`, `statistical_evidence/data/session_data/midterm_scores_with_quartile.csv`
- 결과 파일: `statistical_evidence/04_effect_size/results/quartile_analysis_perfect.json`

하위권 학생은 명료화 모드에서 **2.26점 더 높은 평가** (40점 만점 중 5.6% 차이, p=0.032*).

#### (4) 반복 사용 효과

**[표Ⅴ-7] 세션 증가에 따른 항목별 점수 변화 (LLM 평가)**

| 항목 | Agent 첫 | Agent 마지막 | Agent 변화 | Agent p | Freepass 첫 | Freepass 마지막 | Freepass 변화 | Freepass p |
|------|:--------:|:------------:|:----------:|:-------:|:-----------:|:---------------:|:-------------:|:----------:|
| A1 수학 전문성 | 3.49 | 4.06 | +0.57 | 0.006** | 3.49 | 3.85 | +0.36 | 0.180 |
| A2 질문 구조화 | 4.23 | 4.94 | +0.71 | 0.003** | 4.21 | 4.74 | +0.53 | 0.023* |
| A3 학습 맥락 | 1.19 | 1.22 | +0.03 | 0.799 | 1.36 | 1.48 | +0.12 | 0.454 |
| B1 학습자 맞춤도 | 3.17 | 4.10 | +0.93 | 0.001*** | 3.23 | 3.60 | +0.37 | 0.106 |
| B2 설명 체계성 | 4.07 | 5.00 | +0.93 | 0.015* | 4.48 | 4.81 | +0.33 | 0.250 |
| B3 학습 확장성 | 2.32 | 1.78 | -0.54 | 0.074 | 1.88 | 1.57 | -0.31 | 0.139 |
| C1 대화 일관성 | 4.13 | 4.77 | +0.64 | 0.010** | 4.20 | 4.62 | +0.42 | 0.031* |
| C2 학습 지원 | 2.14 | 2.33 | +0.19 | 0.396 | 2.02 | 2.00 | -0.02 | 0.911 |
| **전체** | **24.75** | **28.20** | **+3.45** | **0.016*** | **24.88** | **26.68** | **+1.80** | **0.154** |

주: 복수 세션 참여 학생 (Agent n=23, Freepass n=27), paired t-test, *p<0.05, **p<0.01, ***p<0.001

**[그림Ⅴ-1] 세션 순서에 따른 항목별 점수 변화 추이**

세션 순서(session_order)별로 각 항목과 총점의 평균 점수 변화 추이를 오차 막대 그래프로 시각화하였다.

![그림Ⅴ-1: 세션 순서에 따른 항목별 점수 변화 추이](statistical_evidence/04_effect_size/results/figure_v1_session_order_trends_mean.png)

그림Ⅴ-1의 오차 막대는 표준 오차(standard error, SEM)를 나타내며, 각 세션 순서에서 점수의 변동성을 보여준다. 각 점은 해당 세션 순서에서 Agent 또는 Freepass 모드의 평균 점수를 나타내고, 오차 막대의 길이는 해당 세션 순서에서 점수의 분산 크기를 의미한다. Agent 모드는 실선, Freepass 모드는 점선으로 구분하였다.

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/04_effect_size/create_figure_v1_session_trends.py` (5장 2절 나항 (4) 반복 사용 효과, 그림Ⅴ-1)
- 데이터 파일: `statistical_evidence/01_llm_scoring/results/llm_3models_averaged_perfect.csv`, `statistical_evidence/data/session_data/full_sessions_with_scores.csv`
- 결과 파일: `statistical_evidence/04_effect_size/results/figure_v1_session_order_trends_mean.png`, `statistical_evidence/04_effect_size/results/figure_v1_session_order_trends.json`

**핵심 발견**:
- **Agent 모드**: 9개 항목 중 6개(66.7%)에서 유의한 변화
  - B1 학습자 맞춤도(+0.93, p=0.001), B2 설명 체계성(+0.93, p=0.015), A2 질문 구조화(+0.71, p=0.003), C1 대화 일관성(+0.64, p=0.010), A1 수학 전문성(+0.57, p=0.006), 전체 점수(+3.45, p=0.016)
  - C2는 유의하지 않음(+0.19, p=0.396)
- **Freepass 모드**: 9개 항목 중 2개(22.2%)에서만 유의
  - A2(+0.53, p=0.023), C1(+0.42, p=0.031)
  - 전체 점수는 1.80점 증가하였으나 유의하지 않음(p=0.154)
  - C2는 거의 변화 없음(-0.02, p=0.911)

명료화 모드는 반복 사용 시 대부분의 항목에서 점수가 증가하는 반면, 즉시 답변 모드는 일부 항목에서만 소폭 증가하여 대조적 패턴을 보임.

#### (5) LLM 평가 소결

**발견된 패턴** (N=284):
1. C2(학습 지원)에서 명료화 우수 (Q1: p<0.001, d=0.855, 매우 큰 효과)
2. Q1 하위권에서 매우 큰 효과 (C2: +0.51, d=0.855) 및 중간 효과 (전체: +2.26, d=0.499, p=0.032 유의)
3. 반복 사용 시 효과 증가 (Agent +3.45점, Freepass +1.80점, 차이 +1.65점)
4. 세션 순서별 점수 변화 추이 (그림Ⅴ-1, 오차 막대 기준): 
   - **Agent 모드**: 전체 점수가 초기 세션(1-3회차) 26.27점에서 후기 세션 29.22점으로 +2.95점 증가 (평균 SEM=1.243). 대부분의 항목(A1, A2, B1, B2, C1, C2)에서 증가 추이를 보였으나, A3(학습 맥락)와 B3(학습 확장성)에서는 감소
   - **Freepass 모드**: 전체 점수가 초기 26.01점에서 후기 26.89점으로 +0.88점 소폭 증가 (평균 SEM=1.239). 일부 항목(A1, A2, B2, C2)에서만 소폭 증가, C1에서는 거의 변화 없음(+0.09점)
   - Agent 모드가 Freepass 모드보다 더 큰 증가폭을 보이며, 오차 막대 크기(SEM)는 두 모드에서 비슷하여 안정적인 추이를 나타냄

*참고: LLM 평가 방법론의 한계(순환 논리 위험, 학습 맥락 파악 등)에 대한 상세한 논의는 VI장에서 다룬다.

### 다. 교사 평가 (N=100)

#### (1) 평가 설계

연구 객관성 확보를 위해 연구자를 제외하고, 외부 수학 교사 2명이 100개 세션을 독립 평가하였다.

**[표Ⅴ-8] 교사 평가 설계**

| 구분 | 내용 |
|------|------|
| 평가자 | 외부 수학 교사 2명 (평가자 96, 97) |
| 평가 세션 | 100개 (Agent 50, Freepass 50) |
| 평가 방식 | 동일 세션 독립 평가 (완전한 대응 설계) |
| 평가 도구 | QAC 체크리스트 (LLM과 동일) |
| 총 레코드 | 200개 (100×2) |
| **표집 방법** | **계층적 목적 표집 (Stratified Purposive Sampling)** |

**100개 세션 선별**: LLM이 평가한 284개 세션 중 교사 검증용 100개를 다음 4가지 전략으로 선별하였다:

◯ **전략 1. AI 모델 간 불일치도 기반 (20개)**

● 검증 목적: 3개 모델 간 채점 차이가 큰 세션의 정답 기준 확립, 평가자 간 신뢰도(Inter-rater Reliability) 검증

● 선별 방법: Gemini, Claude, GPT-5 총점의 표준편차 계산 → 상위 30개 중 Agent/Freepass 균형 유지하며 우선 선택

● 결과 (100개 전체 기준): 평균 불일치도 2.47점(40점 만점 대비 6.2%), 최대 9.67점(24%), 불일치도 >5점 세션 4개

◯ **전략 2. 성적 구간별 계층 표집 (64개)**

● 검증 목적: 학습자 수준별 AI 채점 정확도 편향 검증 (하위권/상위권 공정성 확인)

● 선별 방법: 중간고사 총점으로 Quartile 분류(Q1~Q4) → 각 Quartile × Mode 조합에서 균등 표집 시도

● 결과: Q1(하위) 26개, Q2 26개, Q3 24개, Q4(상위) 24개 - 전 성적대 거의 균등 분포

◯ **전략 3. 루브릭 패턴 특이 케이스 (10개)**

● 검증 목적: 루브릭 항목별 편향성 검증 (특정 항목만 극단적 점수인 경우의 타당성 확인)

● 선별 방법: 8개 항목(A1~C2) 점수의 표준편차 계산 → 패턴 분산이 큰 세션 우선 선별

● 결과: Agent/Freepass 균형 유지

◯ **전략 4. 세션 길이 다양성 (6개)**

● 검증 목적: 대화 길이에 따른 AI 채점 일관성 검증
   - 짧은 세션: 정보 부족 → 과소평가 가능성
   - 긴 세션: 맥락 추적 오류 가능성

● 선별 방법: 짧은(≤5턴), 중간(6-15턴), 긴(>15턴) 세션 포함

● 결과: 실제 분포 반영 (짧은 64%, 중간 30%, 긴 6%)

**최종 균형 조정**: 4가지 전략을 우선순위 순으로 적용한 후, Agent/Freepass 모드 균형을 위해 세션 일부 교체 → 최종 Agent 50개, Freepass 50개 (50:50) 완벽한 균형 달성

**[표Ⅴ-8] 교사 평가자 간 신뢰도 (N=100)**

| 측정 방법 | 전체 점수 | 질문 영역 | 응답 영역 | 맥락 영역 |
|:--------:|:---------:|:---------:|:---------:|:---------:|
| **ICC(2,k)** | **0.716*** | 0.720*** | 0.671*** | 0.408*** |
| Pearson r | 0.644*** | 0.578*** | 0.573*** | 0.392*** |
| Spearman ρ | 0.568*** | 0.629*** | 0.466*** | 0.417*** |
| 일치도 수준 | 양호-높음 | 양호-높음 | 양호 | 중간 |

주: ***p<0.001. 외부 교사 2명(평가자 96, 97) 독립 평가 결과. ICC(2,k)는 평균 측정값 기준 급내상관계수(Intraclass Correlation Coefficient, Two-way random effects, average measures).

**해석**:
- **ICC(2,k) = 0.716***(p<0.001, 95% CI [0.56, 0.82])로 **양호한 신뢰도** (Koo & Li, 2016 기준: >0.60 양호, >0.75 우수)
- 전체 점수 기준 Pearson r=0.644***(p<0.001), Spearman ρ=0.568***(p<0.001)로 **중간-높은 일치도**
- 질문 영역(ICC=0.720***)과 응답 영역(ICC=0.671***)에서 높은 일치도를 보인 반면, 맥락 영역(ICC=0.408***)은 상대적으로 낮은 일치도
- 모든 영역에서 통계적으로 매우 유의한 상관관계(p<0.001)
- **QAC 체크리스트가 일관된 평가 도구로 기능함을 확인**

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/02_teacher_scoring/calculate_icc.py` (표V-8 전용, ICC(2,k) + Pearson + Spearman)
- 데이터 파일: `statistical_evidence/data/teacher_evaluations/latest_evaluations.json` (교사 96, 97의 100개 세션 평가)
- 결과 파일: `statistical_evidence/02_teacher_scoring/results/table_v8_teacher_icc.json`

**[표Ⅴ-9] 표본 100개의 대표성 검증**

| 검증 항목 | 전체 집단 (N=284) | 표본 (N=100) | 검증 결과 |
|----------|:----------------:|:-----------:|----------|
| **모드별 균형** | Agent 115 (40.5%)<br>Freepass 169 (59.5%) | Agent 50 (50%)<br>Freepass 50 (50%) | 의도적 균형 표집 |
| **중간고사 평균** | 54.3점 (SD=18.7) | 54.9점 (SD=17.5) | t=-0.28, p=0.758<br>유의한 차이 없음 |
| **Quartile 분포** | Q1 26.4%, Q2 25.0%<br>Q3 25.4%, Q4 23.2% | Q1 26%, Q2 26%<br>Q3 24%, Q4 24% | 균등 분포 |

주: 중간고사 점수는 100점 만점 기준. 모드별 균형은 표집 전략의 목적상 의도적으로 50:50으로 조정. 세션 길이 정보는 현재 데이터에서 확인 불가.

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/02_teacher_scoring/inter_rater_reliability.py` (실행 시각: 최신)
- 데이터 파일: `statistical_evidence/data/teacher_evaluations/latest_evaluations.json`
- 결과 파일: `statistical_evidence/02_teacher_scoring/results/teacher_correlations_perfect.json`

#### (2) 전체 모드 효과

**[표Ⅴ-10] 모드별 점수 비교 (교사 평가, N=100)**

| 영역 | Agent (n=50) | Freepass (n=50) | 차이 | t | p | d |
|------|:------------:|:---------------:|:----:|:-:|:-:|:-:|
| 전체 | 21.73 (5.86) | 19.48 (7.00) | +2.25 | 1.74 | 0.085 | 0.349 |
| 질문 | 8.02 (2.52) | 7.54 (2.90) | +0.48 | 0.88 | 0.379 | 0.177 |
| **응답** | **8.50 (2.49)** | **7.22 (2.75)** | **+1.28** | 2.44 | **0.017*** | **0.488** |
| 맥락 | 5.21 (1.67) | 4.72 (1.88) | +0.49 | 1.38 | 0.172 | 0.275 |

주: 평균(표준편차). *p<0.05, **p<0.01. 평가자 96, 97만 사용.

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/04_effect_size/teacher_mode_comparison_perfect.py` (5장 2절 다항 (2) 전체 모드 효과, 표Ⅴ-10)
- 데이터 파일: `statistical_evidence/02_teacher_scoring/results/teacher_averaged_scores_perfect.csv`, `statistical_evidence/data/session_data/full_sessions_with_scores.csv`
- 결과 파일: `statistical_evidence/04_effect_size/results/teacher_mode_comparison_perfect.json`

교사 평가에서 명료화 모드는 전체적으로 경계적 유의 (p=0.085)를 보였으며, 특히 **응답 영역**에서 유의한 차이 (p=0.017, d=0.488)를 나타냈다.

#### (3) 하위권 효과 (교사 평가)

**[표Ⅴ-11] Quartile별 전체 점수 (교사 평가, N=100)**

| Quartile (n) | Agent | Freepass | 차이 | p | d |
|:------------:|:-----:|:--------:|:----:|:-:|:-:|
| **Q1 (29)** | **20.79 (6.52)** | **14.47 (6.22)** | **+6.32** | **0.013*** | **0.992** |
| Q2 (23) | 22.12 (5.20) | 21.80 (5.60) | +0.32 | 0.890 | 0.058 |
| Q3 (22) | 21.89 (5.66) | 20.58 (6.94) | +1.31 | 0.644 | 0.207 |
| Q4 (26) | 22.21 (6.40) | 22.62 (6.29) | -0.41 | 0.871 | -0.065 |

주: 평균(표준편차). *p<0.05. 평가자 96, 97만 사용. n 값은 해당 Quartile의 전체 세션 수이다.

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/04_effect_size/teacher_mode_comparison_perfect.py` (5장 2절 다항 (3) 하위권 효과, 표Ⅴ-11)
- 데이터 파일: `statistical_evidence/02_teacher_scoring/results/teacher_averaged_scores_perfect.csv`, `statistical_evidence/data/session_data/full_sessions_with_scores.csv`, `statistical_evidence/data/session_data/midterm_scores_with_quartile.csv`
- 결과 파일: `statistical_evidence/04_effect_size/results/teacher_quartile_analysis_perfect.json`

**핵심 발견**: Q1 하위권에서 유의한 효과 (p=0.013, d=0.992). LLM 평가 결과(p=0.032, d=0.499)와 방향성 일치.

**한계**: Q1 표본 작음 (n=29, Agent n=14, Freepass n=15) → 해석 신중 필요

### 라. LLM-교사 평가 일치도

#### (1) 전체 점수 상관관계

**[표Ⅴ-14] LLM-교사 평가 상관관계 (N=100)**

| 비교 | Pearson r | p-value | Spearman ρ | 해석 |
|------|:---------:|:-------:|:----------:|:----:|
| **3모델 평균 ↔ 교사 평균** | **0.754*** | <0.001 | 0.622*** | 강한 상관 |

주: ***p<0.001. N=100. 전체 점수(40점 만점) 기준. LLM 3개 모델(Gemini 2.5 Flash, Claude 4.5 Haiku, GPT-5-mini) 평균과 교사 2명 평균 간 상관계수는 r=0.754*** (p<0.001)로 강한 양의 상관관계를 보였다. 이는 LLM 평가가 전문가(교사) 평가와 높은 일치도를 가지며, 대규모 평가 도구로서의 타당성을 확보하였음을 의미한다.

**[표Ⅴ-12] LLM-교사 평가 항목별 상관계수 (N=100)**

| 평가 항목 | Pearson r | p | 일치도 수준 |
|----------|:---------:|:-:|:----------:|
| **전체 점수** | **0.754*** | <0.001 | 높음 |
| **B1 학습자 맞춤도** | **0.751*** | <0.001 | 매우 높음 |
| **B2 설명 체계성** | **0.738*** | <0.001 | 높음 |
| A1 수학 전문성 | 0.690*** | <0.001 | 높음 |
| A2 질문 구조화 | 0.602*** | <0.001 | 중간-높음 |
| C1 대화 일관성 | 0.592*** | <0.001 | 중간-높음 |
| C2 학습 지원 | 0.522*** | <0.001 | 중간 |
| A3 학습 맥락 | 0.512*** | <0.001 | 중간 |
| B3 학습 확장성 | 0.462*** | <0.001 | 중간 |

주: ***p<0.001. 교사 평가자 96, 97 (2명) 평균 vs LLM 3개 모델(Gemini, Claude, GPT-5) 평균. 모든 항목에서 통계적으로 매우 유의한 정적 상관관계.

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/03_correlation_analysis/llm_teacher_correlation_perfect.py` (5장 2절 라항 (1) 전체 점수 상관관계, 표Ⅴ-12)
- 데이터 파일: `statistical_evidence/01_llm_scoring/results/llm_3models_averaged_perfect.csv`, `statistical_evidence/02_teacher_scoring/results/teacher_averaged_scores_perfect.csv`
- 결과 파일: `statistical_evidence/03_correlation_analysis/results/llm_teacher_correlations_perfect.json`, `statistical_evidence/03_correlation_analysis/results/correlation_summary_perfect.json`

**주요 발견**: 전체 점수 상관계수 r=0.754*** (p<0.001, 높은 일치). 항목별로는 B1(학습자 맞춤도) r=0.751, B2(설명 체계성) r=0.738로 매우 높은 일치를 보인 반면, C2(학습 지원) r=0.522, B3(학습 확장성) r=0.462로 상대적으로 낮은 일치를 보임. 이는 명시적 특징(맞춤도, 체계성)은 LLM과 교사가 유사하게 평가하나, 교육적 의도와 효과(학습 지원, 확장성)는 평가 관점 차이가 있음을 시사.

**[표Ⅴ-15] LLM-교사 평가 항목별 점수 비교 (N=100)**

| 항목 | LLM 3모델 | 교사 2명 | 차이 | Pearson r | 비고 |
|-----|:--------:|:-------:|:----:|:---------:|:----:|
| A1 수학전문성 | 3.63 (0.86) | 3.00 (1.07) | +0.64 | 0.690*** | 5점 |
| A2 질문구조화 | 4.35 (0.90) | 3.27 (1.36) | +1.08 | 0.602*** | 5점 |
| A3 학습맥락 | 1.40 (0.52) | 1.52 (0.56) | -0.12 | 0.512*** | 5점 |
| B1 학습자맞춤 | 3.44 (1.01) | 3.18 (1.20) | +0.26 | 0.751*** | 5점 |
| B2 설명체계성 | 4.46 (1.14) | 3.13 (1.18) | +1.33 | 0.738*** | 5점 |
| B3 학습확장성 | 2.00 (0.98) | 1.55 (0.66) | +0.45 | 0.462*** | 5점 |
| C1 대화일관성 | 4.28 (0.89) | 3.18 (1.23) | +1.10 | 0.592*** | 5점 |
| C2 학습지원 | 2.25 (0.82) | 1.78 (0.82) | +0.47 | 0.522*** | 5점 |
| **전체** | **25.81 (5.09)** | **20.60 (6.52)** | **+5.20** | **0.754*** | 40점 |

주: 평균(표준편차). ***p<0.001. LLM은 Gemini 2.5 Flash, Claude 4.5 Haiku, GPT-5-mini 평균, 교사는 평가자 96, 97 평균. N=100 공통 세션.

**해석**: LLM이 전체적으로 교사보다 5.20점 높게 평가(과대평가 경향). 특히 B2 설명 체계성(+1.33), C1 대화 일관성(+1.10), A2 질문 구조화(+1.08)에서 큰 차이. 항목별 상관계수는 B1 학습자 맞춤(r=0.751)이 가장 높고, B3 학습 확장성(r=0.462)이 가장 낮음. A3 학습 맥락은 유일하게 교사가 더 높게 평가(-0.12).

**[표Ⅴ-16] LLM-교사 평가 중분류별 상관관계 (N=100)**

| 중분류 | LLM 평균 | 교사 평균 | 차이 | Pearson r | 해석 |
|-------|:-------:|:--------:|:----:|:---------:|:----:|
| **A. 질문 (/15)** | 9.54 (1.90) | 7.78 (2.71) | +1.76 | **0.682*** | 강한 상관 |
| **B. 답변 (/15)** | 9.93 (2.73) | 7.86 (2.69) | +2.07 | **0.735*** | 강한 상관 |
| **C. 맥락 (/10)** | 6.60 (1.40) | 4.96 (1.79) | +1.63 | **0.653*** | 강한 상관 |
| **전체 (/40)** | 26.06 (5.40) | 20.61 (6.52) | +5.46 | **0.754*** | 강한 상관 |

주: 평균(표준편차). ***p<0.001. LLM은 Gemini, Claude, GPT-5 평균, 교사는 A, B 평균. N=100 공통 세션.

**해석**: 중분류별로도 모두 강한 양의 상관관계를 보였다. 특히 B. 답변 영역에서 가장 높은 상관(r=0.735***)을, C. 맥락 영역에서 가장 낮은 상관(r=0.653***)을 보였다. LLM은 모든 영역에서 교사보다 높게 평가하는 경향을 보였으며, 특히 답변 영역에서 과대평가 경향(+2.07점)이 가장 컸다.

#### (2) Q1 하위권 효과의 수렴

**[표Ⅴ-17] Q1(하위권) Agent 우위 폭 비교**

| 평가자 | Agent | Freepass | 차이 | 일치도 |
|--------|:-----:|:--------:|:----:|:------:|
| **교사(2명 평균)** | 20.79 | 14.47 | **+6.32** | 기준 |
| **LLM(3모델 평균)** | 25.24 | 22.60 | **+2.64** | 방향 일치 ✅ |

주: 교사 N=29 (Q1), LLM N=29 (Q1, 교사 평가 100개와 겹치는 세션). LLM은 Gemini 2.5 Flash, Claude 4.5 Haiku, GPT-5-mini 3개 모델의 평균값.

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/04_effect_size/mode_quartile_analysis_perfect.py`, `statistical_evidence/04_effect_size/teacher_mode_comparison_perfect.py` (5장 2절 라항 (2) Q1 하위권 효과의 수렴, 표Ⅴ-17)
- 데이터 파일: `statistical_evidence/data/llm_evaluations/llm_3models_284_PERFECT_FINAL.csv`, `statistical_evidence/data/teacher_evaluations/latest_evaluations.json`, `statistical_evidence/data/session_data/midterm_scores_with_quartile.csv`
- 결과 파일: `statistical_evidence/04_effect_size/results/quartile_analysis_perfect.json`, `statistical_evidence/04_effect_size/results/teacher_quartile_analysis_perfect.json`

**핵심 발견**: 
- 모든 평가자가 Q1에서 Agent 우위 방향성 일치
- 교사가 더 큰 효과 감지 (+6.32 vs +2.64)
- LLM 평가 패턴의 교육적 타당성 확인

### 마. 상호 검증된 핵심 발견

LLM 평가와 교사 평가의 일치 분석 결과, 다음의 핵심 발견이 **상호 검증**되었다.

**[표Ⅴ-18] LLM-교사 평가 수렴 요약**

| 핵심 발견 | LLM (N=284) | 교사 (N=100) | 일치도 |
|----------|:-----------:|:-----------:|:------:|
| **전체 Agent 우위** | 경향성 | +2.25점 | 방향 일치 |
| **하위권(Q1) 효과** | +2.26점 (d=0.499) | +6.32점 (d=0.993) | 방향 일치 |
| **학습 지원(C2)** | +0.28점 (p=0.004) | 응답 영역 유의 (p=0.017) | 영역 일치 |
| **상관계수** | - | r=0.754*** | 강한 상관 |

**상호 검증의 의미**:

◯ **LLM → 교사 검증**:
- LLM이 발견한 패턴 (C2 학습 지원 효과, Q1 하위권 큰 효과)
- 교사 평가에서도 동일 패턴 관찰

◯ **교사 → LLM 확장**:
- 교사가 100개에서 발견한 효과
- LLM이 284개에서 재현

◯ **상호 보완**:
- LLM의 순환 논리 우려 → 교사가 검증
- 교사의 표본 부족 → LLM이 확장

**종합**: 명료화 프로세스는 학습 지원을 향상시키며(LLM p=0.004), 특히 학습에 어려움을 겪는 하위권 학생에게 교육적 효과를 보인다(LLM d=0.499, 교사 d=0.993 방향 일치). LLM 평가와 교사 평가는 강한 상관관계(r=0.754***)를 보여 평가 도구의 타당성이 확보되었다.

---

## 3. 학습자 자기 평가 및 증거의 수렴

### 가. 학습자 자기 평가 (N=47)

사후 설문조사(리커트 5점 척도 15문항, 개방형 5문항)를 통해 학습 효과와 시스템 만족도를 측정하였다(부록 C). 전체 47명의 응답을 분석하였다.

**[표Ⅴ-19] 학습자 자기 평가 결과 (N=47)**

| 카테고리 | 문항 수 | 평균 | SD | 주요 문항 및 점수 |
|----------|:------:|:----:|:---:|------------------|
| **B. AI 상호작용 품질** | 5 | 4.37 | 0.84 | 뭘 모르는지 알게 됨(4.43), AI 도움 충분(4.57), 다음 질문 알게 됨(4.43) |
| **C. 질문 능력** | 2 | 4.22 | 0.99 | 분명하게 말함(4.34), 상황 설명(4.11) |
| **D. 개념 이해** | 3 | 4.39 | 0.78 | 귀납 가정 이해(4.57), 귀납법 구조(4.51) |
| **E. 시스템 만족도** | 3 | 4.62 | 0.65 | 사용 쉬움(4.81), 도움됨(4.55), 계속 사용(4.49) |

주: 5점 리커트 척도 (1=전혀 그렇지 않다, 5=매우 그렇다). 설문지 전문은 부록 C 참조. N=47 전체 응답자 기준.

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/05_student_survey/analyze_survey_47_by_mode_final.py` (실행 시각: 최신)
- 데이터 파일: `statistical_evidence/data/MAICE 사용 설문조사 (2025학년도 2학년 수학)(1-47).csv`
- 결과 파일: `statistical_evidence/05_student_survey/results/survey_47_statistics.csv`, `statistical_evidence/05_student_survey/results/survey_47_mode_comparison_final.csv`

**주요 결과**: 
- AI 상호작용 품질 4.37/5.0, 개념 이해 4.39/5.0, 질문 능력 4.22/5.0
- "뭘 모르는지 알게 됨" 4.43/5.0, "다음 질문 알게 됨" 4.43/5.0
- 시스템 만족도 4.62/5.0 (최고점)
- 사용 쉬움 4.81/5.0 (개별 문항 최고점)

### 나. 모드 선호도 및 이유

**[표Ⅴ-20] 명료화 방식 선호도 (N=44, 불명확 제외)**

| 선호 방식 | 전체 | 비율 | Agent 모드 (N=20) | Freepass 모드 (N=23) |
|----------|:----:|:----:|:-----------------:|:-------------------:|
| **B 방식 (질문 유도형)** | 26명 | 59.1% | 14명 (70.0%) | 12명 (52.2%) |
| **A 방식 (즉시 답변형)** | 12명 | 27.3% | 4명 (20.0%) | 8명 (34.8%) |
| **혼합** | 5명 | 11.4% | 2명 (10.0%) | 3명 (13.0%) |
| **합계** | 44명 | 100% | 20명 (100%) | 23명 (100%) |

주: 전체 47명 중 A/B 선호도가 불명확한 응답 3명 제외. B 방식 선호 비율(A+B만 기준): 전체 68.4%, Agent 모드 77.8%, Freepass 모드 60.0%.

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/05_student_survey/analyze_survey_47_by_mode_final.py` (실행 시각: 최신)
- 데이터 파일: `statistical_evidence/data/MAICE 사용 설문조사 (2025학년도 2학년 수학)(1-47).csv`
- 결과 파일: `statistical_evidence/05_student_survey/results/survey_47_mode_preference_final.csv`

**모드별 선호도 분석**:
- **전체**: 68.4%가 B 방식 선호 (A+B만 기준)
- **Agent 모드**: 77.8%가 B 방식 선호 - 자신이 사용한 명료화 방식을 더 높이 평가
- **Freepass 모드**: 60.0%가 B 방식 선호 - 즉시 답변을 경험했음에도 명료화 방식의 교육적 가치 인식

**질적 분석 결과**:
- B 방식 선호 이유: "생각하는 힘이 길러진다"(42%), "오래 남는다"(25%), "모르는 부분을 생각해보는 시간"(17%)
- A 방식 선호 이유: "빠른 답을 원한다"(44%), "효율적이다"(31%), "고민해도 안 나와서"(25%)
- Agent 모드 사용자도 B 방식을 더 선호 (Agent 77.8%, Freepass 60.0%)

**점수 항목별 모드 비교** (N=47):
모든 설문 점수 항목(15개)에서 Agent 모드와 Freepass 모드 간 통계적으로 유의한 차이는 없었다(p>0.05). 그러나 경향성 분석 결과, Agent 모드가 메타인지 효과(4.42 vs 4.22, +0.20)와 시스템 만족도(4.72 vs 4.54, +0.18)에서 약간 높은 경향을 보였고, Freepass 모드가 자기조절 학습(4.15 vs 3.98, +0.17)과 질문 능력(4.26 vs 4.18, +0.09)에서 약간 높은 경향을 보였다. 효과 크기는 모두 작거나 무시 가능한 수준이었다(|d|<0.3).

**학습자 변화 인식** (설문 Part 2: 학습 방식 변화):
- "질문의 질이 처음에는 뭉툭했는데, 이제는 명확하게 표현하면 더 좋은 답변이 온다는 걸 깨달았다" (학생 ID 09)
- "질문 방식이 구체적으로 바뀌었다" (학생 ID 40)
- "모호한 질문을 더 구체적으로 바꾸는 방법을 배웠다" (평균 4.23/5.0)

*참고: 학생 설문의 응답 편향 가능성(사회적 바람직성 편향 등)에 대한 상세한 논의는 VI장에서 다룬다.

### 다. 수렴적 증거: 다중 관점의 일치

**[표Ⅴ-21] 네 가지 독립 증거의 수렴**

| 증거 유형 | 방법 | 표본 | 핵심 발견 | 효과 크기 | 신뢰도 |
|----------|------|:----:|----------|:---------:|:------:|
| **객관적 평가** | LLM (QAC) | N=284 | Agent 우수<br>C2: +0.28점, p=0.004** | d=0.353** | ICC=0.656*** |
| **전문가 평가** | 교사 (QAC) | N=100 | Agent 경향<br>전체: +2.25점, p=0.085 | d=0.349 | ICC=0.716*** |
| **학습자 평가** | 설문 (자기평가) | N=47 | AI 상호작용 4.37<br>개념 이해 4.39<br>질문 능력 4.22 | - | 높은 만족도<br>(평균 4.33/5.0) |
| **질적 증거** | 서술형 응답 | N=44 | "사고력 향상"(42%)<br>"깊은 이해"(25%)<br>"자기주도"(17%) | - | 일관된 선호<br>B 방식 68.4%<br>Agent 77.8%<br>Freepass 60.0% |

주: **p<0.01, ***p<0.001. LLM은 3개 모델(Gemini, Claude, GPT-5) 평균. 학생 설문 N=47 전체 응답자. 교사 평가는 경계적 유의(p=0.085). ICC는 평가자 간 급내상관계수.

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/04_effect_size/mode_quartile_analysis_perfect.py`, `statistical_evidence/02_teacher_scoring/process_teacher_perfect.py`, `statistical_evidence/05_student_survey/analyze_survey_47_by_mode_final.py` (실행 시각: 최신)
- 데이터 파일: `statistical_evidence/01_llm_scoring/results/llm_3models_averaged_perfect.csv`, `statistical_evidence/02_teacher_scoring/results/teacher_averaged_scores_perfect.csv`, `statistical_evidence/data/MAICE 사용 설문조사 (2025학년도 2학년 수학)(1-47).csv`
- 결과 파일: `statistical_evidence/04_effect_size/results/mode_quartile_summary_perfect.json`, `statistical_evidence/05_student_survey/results/survey_47_mode_comparison_final.csv`

**[표Ⅴ-22] 하위권(Q1) 학생 효과의 수렴**

| 평가 방법 | Agent | Freepass | 차이 | p | d | 일치도 |
|----------|:-----:|:--------:|:----:|:-:|:-:|:------:|
| **LLM 평가** | 26.52 | 24.26 | **+2.26** | 0.032* | 0.499 | 유의 ✓ |
| **교사 평가** | 20.79 | 14.47 | **+6.32** | 0.013* | 0.992 | 매우 큰 효과 ✓✓ |

주: *p<0.05. 두 평가 모두 하위권에서 Agent 모드 우위 확인. Q1은 중간고사 점수 하위 25%. LLM 평가는 유의(p=0.032). 평가자 96, 97만 사용.

**근거 자료** (Python 스크립트 실행 결과):
- 계산 파일: `statistical_evidence/04_effect_size/mode_quartile_analysis_perfect.py`, `statistical_evidence/04_effect_size/teacher_mode_comparison_perfect.py` (실행 시각: 최신)
- 데이터 파일: `statistical_evidence/01_llm_scoring/results/llm_3models_averaged_perfect.csv`, `statistical_evidence/02_teacher_scoring/results/teacher_averaged_scores_perfect.csv`, `statistical_evidence/data/session_data/midterm_scores_with_quartile.csv`
- 결과 파일: `statistical_evidence/04_effect_size/results/quartile_analysis_perfect.json`, `statistical_evidence/04_effect_size/results/teacher_quartile_analysis_perfect.json`

**수렴 패턴**:
1. **정량적 수렴**: 
   - LLM과 교사 평가 모두 Agent 모드 우수 (r=0.754 상관)
   - 학생 자기 평가에서도 높은 학습 효과 체감 (4.13~4.38/5.0)
   
2. **정성적 수렴**: 
   - 학생 서술형 응답에서 "사고력 향상"(42%), "깊은 이해"(25%), "오래 남음"(25%) 반복 언급
   - 68.4%가 질문 유도형 방식 선호 (이유: 학습 효과)
   - Agent 모드 사용자(77.8%)가 Freepass 모드 사용자(60.0%)보다 더 높은 선호도
   
3. **하위권 효과 수렴**: 
   - 객관적 평가(LLM +2.26점 d=0.499, 교사 +6.32점 d=0.992) 모두 하위권 학생에게 매우 큰 효과
   - 학생 응답에서도 "혼자 풀 수 있게 됨"(4.23) 높은 점수

4. **메타인지 발달 수렴**:
   - 객관적 평가: C2(학습 지원) +0.28점, p=0.004
   - 학습자 평가: "뭘 모르는지 알게 됨" 4.38/5.0
   - 질적 증거: "질문 방식이 구체적으로 바뀌었다" (ID 40)

**수렴 패턴 요약**:
- 객관적 측정(LLM·교사 QAC)과 주관적 체감(학생 자기 평가)의 방향성 일치
- 양적 증거(QAC 점수, 설문 점수)와 질적 증거(서술형 응답)가 같은 방향 지지
- 하위권 학생에 대한 효과가 주요 증거에서 일관되게 확인

---

## 4. 피드백 내용의 질적 분석: Bloom-Dewey 이론 실증

본 절에서는 2절의 정량적 발견을 질적으로 심화하기 위해, 실제 학생-MAICE 대화 로그 1,589건을 분석하였다. 특히 LLM 평가점수와 연계하여 **'왜 점수가 높은가/낮은가'**를 Bloom 교육 목표 분류와 Dewey 반성적 사고 이론으로 해석하였다.

### 가. 분석 방법론

#### (1) 데이터 출처 및 규모

**DB 대화 로그** (maice_agent 데이터베이스):
- **총 프롬프트-응답 로그**: 1,589건
- **분석 기간**: 2025-10-27 ~ 2025-11-11 (16일)
- **고유 세션**: 229개
- **에이전트별 분류**:
  - answer_generator_llm: 237건 (교육적 답변 생성)
  - classifier_llm: 278건 (질문 분류 K1~K4)
  - observer_llm: 255건 (학습 과정 요약)
  - freetalker_llm: 628건 (자유 대화)
  - 기타: 191건

**통합 데이터셋**:
- LLM 평가점수: 283개 세션
- 세션 ID 매칭: 6개 샘플 세션 (대화1-6)
- 점수 구간: 모두 우수(30-34점)

#### (2) 분석 틀

본 연구의 질적 분석에서는 II장에서 제시한 이론적 배경을 분석 틀로 사용하였다:

**Dewey (1910) 반성적 사고 5단계**: 문제 인식 → 문제 정의 → 가설 형성 → 추론 전개 → 검증 (II장 3절)

**Bloom의 지식 차원 분류 (K1-K4)**: K1(사실적 지식) → K2(개념적 지식) → K3(절차적 지식) → K4(메타인지적 지식) (II장 2절)

질적 분석에서는 대화 흐름을 Dewey의 반성적 사고 단계로 추적하고, 학생 질문과 AI 답변의 지식 차원(K1-K4)을 분류하여 분석하였다.

#### (3) 코딩 절차

1. 지식 차원(K1-K4) 분류: 학생 질문과 AI 답변의 지식 차원 분류 (237건 답변)
2. Dewey 단계 추적: 대화 흐름을 Dewey 반성적 사고 5단계로 추적
3. 점수 연계 분석: 지식 차원 분류 및 Dewey 단계와 LLM 평가점수 간 연관성 분석

#### (4) 사례 선택 기준

본 절의 질적 분석 사례(대화1-6)는 **LLM 평가점수 기준 최상위 세션** 중에서 선택하였다:

- **선택 기준**: 
  - **LLM 평가 최상위권** (상위 0.4%~4.2%) 세션 중 선택
  - 충분한 대화 턴수 (5턴 이상 선호, 최소 2턴)
  - 실제 학습 질문이 있는 세션 (증명만 제시한 세션 제외)
  - 다양한 교육적 특징 (지식 차원 상승, 오류 교정, 단계별 지원, 전략 제시)

- **선택된 사례**: 
  - **대화1**: 막연한 어려움 구체화, 지식 차원 상승 (K2 → K3 → K4)
  - **대화2**: 오류 교정, Hattie 피드백 수준
  - **대화3**: 특정 단계 맞춤 지원, 명료화 질문 시도
  - **대화4**: 문제 해결 전략 제시
  - **대화5**: 논리적 설명 요구, 메타인지적 지식(K4) 도달
  - **대화6**: Dewey 5단계 완전 구현

> 📝 **주**: 교사 평가는 100개 샘플에 대한 타당성 검증 목적이며, 질적 분석 사례 선택의 주 기준은 LLM 평가임. 교사 평가 상위 세션은 대화 턴수가 1-2턴으로 너무 짧아 질적 분석에 부적합. LLM-교사 평가 불일치 사례는 VI장 3절 나항에서 논의함.

---

### 나. Dewey 반성적 사고와 지식 차원 분류 기반 실증 사례

#### (1) 막연한 어려움 구체화: Dewey 단계 체계적 진행

**대화1 (세션 156)**

| 항목 | 내용 |
|------|------|
| LLM 평가점수 | 34.33점 (Gemini: 34, Claude: 35, GPT-5: 34) |
| LLM 순위 | 284개 중 1등 (상위 0.4%) |
| 대화 턴수 | 5턴 (총 10개 메시지) |
| 지식 차원 진행 | K2(개념적) → K3(절차적) → K4(메타인지적) |
| Dewey 단계 | 문제 인식 → 문제 정의(명료화 3회) → 해결 및 검증 |
| 학습 주제 | 수학적 귀납법 전반적 이해 |

**[표Ⅴ-23] 대화1 (세션 156) 막연한 어려움의 구체화 과정**

| 메시지 | 발화자 | 대화 내용 | 지식 차원 | Dewey 단계 | 교육적 기능 |
|:-----:|--------|----------|-----------|-----------|-----------|
| [0] | 학생 | "수학적 귀납법을 지난 시간에 배웠는데도 감이 잘 안와요" | - | 1. 문제 인식 | 막연한 어려움 표현 |
| [1] | MAICE | "핵심은 '도미노 효과'로 생각하는 것... 기초 사례 → 귀납 가정 → 귀납 단계" | K2 | 2. 문제 정의 | 개념 구조화<br/>직관 제공 |
| [2] | 학생 | "고등학교 수준에서의 귀납법, 그냥 증명하는 과정 프로세스를 잘 못 알아먹은 것 같아서 처음부터 막막하기만 해" | - | 2. 문제 정의 | 구체적 어려움 표현 |
| [3] | MAICE | "무엇을 쓰고, 왜 그 단계가 필요한지... (템플릿 제시)" | K3 | 3-5. 해결 및 검증 | 절차적 지식 |
| [4] | 학생 | "그렇게 하자" | - | 3-5. 해결 및 검증 | 실행 의지 |
| [5] | MAICE | "어느 문제로 같이 차근차근 증명해볼까요?" | - | 3-5. 해결 및 검증 | 선택지 제시 |
| [6] | 학생 | "팩토리얼과 거듭제곱" | - | 3-5. 해결 및 검증 | 문제 선택 |
| [7] | MAICE | "$n! \ge 2^{n-1}$ 증명을 단계별로... "왜 하는가?" 설명 포함 | K4 | 3-5. 해결 및 검증 | 메타인지적 설명 |

주: 본 분석은 [0-7] 메시지만 포함하며, [8]에서 주제가 극한 함수로 전환된 부분은 별도 분석 대상으로 제외함.

**지식 차원 진행 패턴**: 막연한 표현(K1 이전) → K2(개념적 지식) → K3(절차적 지식) → K4(메타인지적 지식)
**Dewey 단계 진행**: 문제 인식 → 문제 정의(명료화를 통한 구체화) → 해결 및 검증

#### (2) 오류 교정: Hattie 피드백 수준

**대화2 (세션 150)**

| 항목 | 내용 |
|------|------|
| LLM 평가점수 | 33.00점 (Gemini: 30, Claude: 35, GPT-5: 34) |
| LLM 순위 | 284개 중 6등 (상위 2.1%) |
| 대화 턴수 | 2턴 (총 4개 메시지) |
| 학습 주제 | 등비급수 합 공식 오류 교정 |
| 지식 차원 | K2(개념적) → K4(메타인지적) (오류 발견 및 교정) |
| Dewey 단계 | 문제 인식 → 해결 및 검증 (Hattie 피드백 수준) |

**[표Ⅴ-20] 대화2 (세션 150) 대화 흐름 및 오류 교정 과정**

| 메시지 | 발화자 | 대화 내용 | 지식 차원 | Dewey 단계 | Hattie 피드백 |
|:-----:|--------|----------|-----------|-----------|--------------|
| [0] | 학생 | "기저단계, 귀납단계가 무엇인지" | K2 | 1. 문제 인식 | 개념 질문 |
| [1] | 학생 | "$1+2+2^2+...+2^{n-1}=2^n$" | - | 3-5. 해결 및 검증 | ❌ 틀린 공식 제시 |
| [2] | MAICE | "기저단계: 시작점에서 명제 참 확인<br/>귀납단계: $P(k)$ 가정 → $P(k+1)$ 증명" | K2 | 3-5. 해결 및 검증 | 개념 설명 |
| [3] | MAICE | "주어진 식은 틀립니다. 올바른 공식: $2^n-1$<br/><br/>**자주 하는 실수**:<br/>- 오른쪽에 $-1$이 빠져 있는 것이 흔한 실수<br/>- 시작 인덱스가 $0$인지 $1$인지 확인 필요<br/>- 귀납가정에서 증명하려는 것을 암묵적으로 쓰지 않도록 주의" | K4 | 3-5. 해결 및 검증 | Task(무엇이 틀렸나)<br/>Process(왜 틀렸나)<br/>Self-regulation(어떻게 할 것인가) |

**Hattie & Timperley(2007) 피드백 수준 구조 확인**:
- **Task 수준**: "오른쪽에 $-1$이 빠져 있는 것이 흔한 실수" (무엇이 틀렸는지)
- **Process 수준**: "시작 인덱스가 $0$인지 $1$인지 확인 필요" (왜 틀렸는지)
- **Self-regulation 수준**: "귀납가정에서 증명하려는 것을 암묵적으로 쓰지 않도록 주의" (앞으로 어떻게 할 것인가)

#### (3) 특정 단계 맞춤 지원: 단계별 지원

**대화3 (세션 73)**

| 항목 | 내용 |
|------|------|
| LLM 평가점수 | 33.00점 (Gemini: 34, Claude: 35, GPT-5: 34) |
| LLM 순위 | 284개 중 4등 (상위 1.4%) |
| 대화 턴수 | 6턴 (총 14개 메시지) |
| 학습 주제 | 귀납 단계($n=k+1$) 이해 |
| 지식 차원 | K2(개념적) → K3(절차적) → K4(메타인지적) |
| Dewey 단계 | 문제 인식 → 문제 정의(명료화) → 해결 및 검증 |

**[표Ⅴ-21] 대화3 (세션 73) 특정 단계 질문에 대한 맞춤 지원**

| 메시지 | 발화자 | 대화 내용 | 지식 차원 | Dewey 단계 | 지원 기능 |
|:-----:|--------|----------|-----------|-----------|----------|
| [0] | 학생 | "수학적 귀납법 할 때 n=k+1 부터 모르겠어" | - | 1. 문제 인식 | 특정 단계 질문 |
| [2] | MAICE | "n=k+1 단계가 어려운 게, 식을 어떻게 전개해야 할지 몰라서인가요? 아니면 가정 부분을 어떻게 써야 할지 헷갈리신 건가요?" | - | 2. 문제 정의 | 명료화 질문 |
| [3] | 학생 | "둘 다" | - | 2. 문제 정의 | 수동적 응답 |
| [4] | MAICE | "수학적 귀납법에서 $n=k+1$ 단계 전개 방법. 수식 전개 순서와 가정 활용 방법을 이해하는 것이 핵심" | K2 | 3-5. 해결 및 검증 | 어려움 원인 진단 |
| [5] | 학생 | "$1\cdot2 + 2\cdot3 + 3\cdot4 + \cdots + n(n+1) = \frac{n(n+1)(n+2)}{3}$ (단, n은 자연수) 이거는..?" | - | 3-5. 해결 및 검증 | 구체적 문제 제시 |
| [6] | MAICE | "$1\cdot2 + 2\cdot3 + 3\cdot4 + \cdots + n(n+1) = \frac{n(n+1)(n+2)}{3}$ 증명 단계별 설명" | K3 | 3-5. 해결 및 검증 | 절차 시연 |
| [7] | 학생 | "그럼 $1+2+2^2+\cdots+2^{n-1}=2^n-1$ 은?" | - | 3-5. 해결 및 검증 | 다른 문제 제시 |
| [8] | MAICE | "$1+2+2^2+\cdots+2^{n-1}=2^n-1$ 증명 단계별 설명" | K4 | 3-5. 해결 및 검증 | 패턴 분석 |
| [9] | 학생 | "$n \ge 4$인 모든 자연수 $n$에 대해 부등식 $n! > 2^n$ 이 성립함을 수학적 귀납법으로 증명하시오" | - | 3-5. 해결 및 검증 | 또 다른 문제 제시 |
| [10] | MAICE | "$n! > 2^n$ (단, $n \ge 4$) 증명 단계별 설명" | K4 | 3-5. 해결 및 검증 | 패턴 분석 |
| [11] | 학생 | "아 너무 어려워.." | - | 3-5. 해결 및 검증 | 어려움 표현 |
| [13] | MAICE | "수학적 귀납법의 어떤 부분이 가장 어렵게 느껴지셨나요? 예를 들어 가정 세우는 부분인지, 식을 전개하는 부분인지 알려주실 수 있을까요?" | - | 2. 문제 정의 | 재명료화 시도 |

**맞춤 지원 전략**:
1. 어려움 특정 (n=k+1 단계)
2. 핵심 원리 설명 (변형 필요성)
3. 구체적 예시 적용
4. 여러 문제 제시 및 설명 (학생이 다양한 문제를 제시하여 학습 범위 확장 시도)

**맞춤 지원 패턴**: 어려움 특정 → 핵심 원리 설명 → 구체적 예시 적용 → 여러 문제 제시

**사례 분석**: 학생의 수동적 응답("둘 다", [3])과 최종 어려움 표현("아 너무 어려워", [11])이 관찰됨. 이 사례의 의미는 VI장에서 논의함.

#### (4) 절차적 지원을 통한 단계별 이해 지원

**대화4 (세션 111)**

| 항목 | 내용 |
|------|------|
| LLM 평가점수 | 32.00점 (Gemini: 33, Claude: 34, GPT-5: 33) |
| LLM 순위 | 284개 중 11등 (상위 3.9%) |
| 대화 턴수 | 6턴 (총 12개 메시지) |
| 학습 주제 | 등비급수 귀납법 증명 전략 |
| 지식 차원 | K2(개념적) → K3(절차적) (절차적 지원) |
| Dewey 단계 | 문제 인식 → 해결 및 검증 (반복적 이해 확인) |

**[표Ⅴ-22] 대화4 (세션 111) 절차적 지원을 통한 단계별 이해 지원**

| 메시지 | 발화자 | 대화 내용 | 지식 차원 | Dewey 단계 | 교육적 기능 |
|:-----:|--------|----------|-----------|-----------|----------|
| [0] | 학생 | "$1+2+4+\cdots+2^{n-1} = 2^n - 1$ 증명... 어떻게 접근해야 할지 모르겠어. 기저 단계까지는 했어" | - | 1. 문제 인식 | 접근 방법 질문 |
| [1] | MAICE | "기저 단계 완료 ✓<br/>귀납 가정: $P(k)$ 참 가정<br/>목표: $P(k+1)$ 증명" | K2 | 3-5. 해결 및 검증 | 전체 구조 확인 |
| [2] | 학생 | "왜 $(2^k-1)+2^k$ 로 바뀐거야" | - | 3-5. 해결 및 검증 | 이해 확인 질문 |
| [3] | MAICE | "귀납 가정 적용 설명" | K2 | 3-5. 해결 및 검증 | 귀납 가정 적용 설명 |
| [4] | 학생 | "그럼 양변에 뭘 더한거야?" | - | 3-5. 해결 및 검증 | 반복 질문 |
| [5] | MAICE | "양변에 $2^k$ 더하기 설명" | K3 | 3-5. 해결 및 검증 | 절차적 설명 |
| [6] | 학생 | "아니 2^k를 더한거라고? 그럼 2^(k+1)이 아니여야 되는거 아니야" | - | 3-5. 해결 및 검증 | 혼란 표현 |
| [7] | MAICE | "$2^k$와 $2^{k+1}$ 관계 설명" | K3 | 3-5. 해결 및 검증 | 관계 설명 |
| [8] | 학생 | "아니 왜 2^k를 더한게 저게 되는지 아직 이해가 안가" | - | 3-5. 해결 및 검증 | 지속적 혼란 |
| [9] | MAICE | "계산 과정 상세 설명" | K3 | 3-5. 해결 및 검증 | 절차적 지원 |
| [10] | 학생 | "어 맞아" | - | 3-5. 해결 및 검증 | 최종 이해 |

**절차적 지원 패턴**: 전체 구조 파악 → 핵심 전략 제시 → 학생 반복 질문에 대한 단계별 설명. 학생의 최종 이해 확인("어 맞아").

#### (5) 논리적 설명 요구: 메타인지적 사고 시도

**대화5 (세션 125)**

| 항목 | 내용 |
|------|------|
| LLM 평가점수 | 32.00점 (Gemini: 32, Claude: 32, GPT-5: 32) |
| LLM 순위 | 284개 중 10등 (상위 3.5%) |
| 대화 턴수 | 5턴 (총 10개 메시지) |
| 학습 주제 | 논리적 증명 설명 |
| 지식 차원 | K2(개념적) → K4(메타인지적) |
| Dewey 단계 | 문제 인식 → 해결 및 검증 (메타인지적 사고 시도) |

**[표Ⅴ-23] 대화5 (세션 125) 논리적 설명 요구와 응답**

| 메시지 | 발화자 | 대화 내용 | 지식 차원 | Dewey 단계 | 교육 효과 |
|:-----:|--------|----------|-----------|-----------|----------|
| [0] | 학생 | "증명 문제를 낼건데, 특히 귀납단계를 **논리적으로 잘 설명**해줘" | - | 1. 문제 인식 | 논리적 설명 요구 |
| [1] | MAICE | "기저: $n=1$ 확인<br/>귀납 가정: $P(k)$ 가정<br/>귀납 단계: **왜 이렇게 하는지** 설명 포함" | K2/K4 | 3-5. 해결 및 검증 | 메타인지적 설명 |
| [2] | MAICE | "모든 자연수 $n \ge 4$에 대하여 $n! > 2^n$ 임을 증명하시오" (다른 문제 제시) | - | 3-5. 해결 및 검증 | 문제 전환 |
| [3] | 학생 | "4 이상의 모든 자연수 n에 대해, n! > 2^n임을 수학적 귀납법을 이용하여 증명하시오" | - | 3-5. 해결 및 검증 | 문제 확인 |
| [4] | 학생 | "귀납 단계 더 자세히 설명좀" | - | 3-5. 해결 및 검증 | 깊이 요구 |
| [5] | MAICE | "귀납 단계만 더 논리적으로 자세히 풀어 설명하겠습니다. 귀납 가정: $k! > 2^k$ 가정 → 목표: $(k+1)! > 2^{k+1}$ 보이기" | K4 | 3-5. 해결 및 검증 | 논리 구조 분석 |
| [6] | 학생 | "<==> 이런 기호 쓰지마" | - | 3-5. 해결 및 검증 | 표현 방식 피드백 |
| [7] | MAICE | "기호 없이 설명" | K4 | 3-5. 해결 및 검증 | 설명 방식 조정 |
| [8] | 학생 | "<==> 이 기호를 뭐고 뭐로 바꿔 쓸 수 있는지 설명해" | - | 3-5. 해결 및 검증 | 메타인지적 질문 |
| [9] | MAICE | "논리적 동치 기호 설명" | K4 | 3-5. 해결 및 검증 | 기호 의미 분석 |

주: [2]에서 MAICE가 다른 문제를 제시한 것은 학생의 논리적 설명 요구에 대한 응답의 일환으로, 구체적 예시를 통해 설명을 명확히 하려는 시도로 해석됨.

**메타인지적 사고 시도**: 학생의 "논리적으로 설명" 요구와 기호에 대한 질문이 관찰됨. K4(메타인지적 지식) 수준의 사고가 요구되는 질문과 답변이 확인됨.

#### (6) 지식 차원 분류 종합

질적 분석 대상 6개 세션(LLM 평가 32-34점)은 모두 K4(메타인지적 지식), K3(절차적 지식), K2(개념적 지식) 수준의 질문과 답변을 포함하고 있었다. 이는 고득점 세션이 단순한 사실적 지식(K1) 교환을 넘어, 개념 이해, 절차 적용, 메타인지적 성찰에 이르는 **다층적 학습 과정**을 거쳤음을 의미한다.

---

### 다. Dewey 반성적 사고 5단계 구현 실증

#### (1) 대화6 (세션 75): Dewey 5단계 모두 진행 사례

| 항목 | 내용 |
|------|------|
| LLM 평가점수 | 34.0점 (Gemini: 32, Claude: 35, GPT-5: 35) |
| LLM 순위 | 284개 중 2등 (상위 0.7%) |
| 대화 턴수 | 11턴 (총 25개 메시지) |
| Dewey 단계 진행 | 5단계 모두 시도 (단, 최종 검증 단계에서 학생이 여전히 혼란을 표함) |
| 명료화 횟수 | 3회 |
| 지식 차원 | K1(사실적), K2(개념적), K3(절차적) |

**[표Ⅴ-25] 대화6 (세션 75) Dewey 5단계 추적**

| 단계 | 실제 대화 | 턴 | 비고 |
|-----|---------|---|------|
| 1. 문제 인식 | "(k+1)! 을 다르게 나타낼 방법이 있어?" | 0 | 문제 제기 |
| 2. 문제 정의 | 명료화: "곱셈식으로 전개? k!으로 표현?" | 4 | 명료화 질문 |
| 3. 가설 형성 | 학생: "k!로 표현하는 방법" 탐색 | 5-18 | 여러 문제 제시 및 탐색 |
| 4. 추론 전개 | "(k+1)*k! > (k+1)*2^k 관계 확인" | 17-22 | 부등식 관계 확인 |
| 5. 검증 | "(k+1)*k! > (k+1)*2^k가 어떻게 (k+1)*2^k>2^(k+1)이 되는거야" | 23 | **학생 혼란 지속** |

**Dewey 5단계 진행**: 11턴 대화를 통해 5단계 모두 시도됨. 명료화 3회가 문제 정의 → 가설 형성 → 추론 → 검증 과정을 촉진.

**사례 분석**: 학생의 마지막 질문[23]에서 여전히 혼란이 관찰됨. Dewey 5단계가 모두 시도되었으나 최종 검증의 완전한 성공은 확인되지 않음.

---

### 라. 질적 분석 종합

#### (1) 교육적 특성

질적 분석 대상 6개 세션(32-34점)의 공통 특징:
- **지식 차원**: 모두 K2(개념적) → K3(절차적) → K4(메타인지적) 수준 포함
- **대화 깊이**: 평균 7.2턴 (5-11턴)
- **명료화**: 대화1, 대화6에서 명료화 질문 3회로 문제 정의 촉진

#### (2) LLM 평가의 타당성

LLM 평가는 **교사 평가와 강한 상관**(r=0.754, p<0.001)을 보여, 객관적 평가 지표로서의 타당성을 입증하였다. 질적 분석은 고득점 세션이 단순한 정답 제시를 넘어 **개념적·절차적·메타인지적 학습**을 거쳤음을 확인하였다.

#### (3) 하위권 효과의 질적 메커니즘

교사 평가에서 확인된 Q1 하위권 효과(Agent +6.32점, 표Ⅴ-12)의 메커니즘을 대화1(세션 156)을 통해 규명하였다:

**대화1 (Q1 하위권, 34.33점, 상위 0.4%)**:
- 막연한 질문 → 명료화 3회 → 지식 차원 상승 (K2 → K3 → K4)
- 5턴 대화를 통해 개념 이해, 절차 적용, 메타인지적 성찰 달성
- **메커니즘**: 명료화 → 질문 구체화 → 맞춤 지원 → 지식 차원 고단계 도달

---

**4절 요약**:

질적 분석 대상 6개 세션의 특징:
- 모두 K2 → K3 → K4 지식 차원 상승 경로 포함
- 대화1, 대화6에서 명료화가 문제 정의 촉진
- LLM 평가는 교사 평가와 강한 상관(r=0.754)
- 하위권(Q1) 효과의 질적 메커니즘 규명 (대화1)

---

**V장 전체 요약**: 

본 장에서는 MAICE 명료화 프로세스의 효과를 **4가지 증거를 통해 다각도로 검증**하였다.

**1. 객관적 평가 (LLM, N=284)**:
- 전체 효과: C2(학습 지원) Agent 우수 (+0.28점, p=0.004, d=0.353)
- 하위권(Q1) 효과: +2.26점, p=0.032, d=0.499 (중간 효과, 유의)
- 3개 모델 평균, 높은 평가자 간 일치도 (ICC=0.656***)

**2. 전문가 평가 (교사, N=100)**:
- 전체 효과: Agent 경향 (+2.25점, p=0.085, d=0.349, 경계적 유의)
- 하위권(Q1) 효과: +6.32점, p=0.013, d=0.992 (매우 큰 효과)
- LLM과 강한 상관 (r=0.754, p<0.001)

**3. 학습자 자기 평가 (설문, N=47)**:
- AI 상호작용 품질: 4.37/5.0, 개념 이해: 4.39/5.0, 질문 능력: 4.22/5.0
- 68.4%가 질문 유도형(B 방식) 선호 (이유: "사고력 향상"(42%), "깊은 이해"(25%))
- 시스템 만족도: 4.62/5.0 (최고점)

**4. 질적 분석 (6개 우수 세션)**:
- **지식 차원**: 모두 K2(개념적) → K3(절차적) → K4(메타인지적) 수준 포함
- **Dewey 반성적 사고**: 대화6은 5단계 모두 시도 (단, 최종 검증에서 학생 혼란 지속)
- **하위권 메커니즘**: 대화1(Q1 하위권)에서 명료화 → 지식 차원 상승 (K2 → K3 → K4) → 고득점
- **LLM 평가 타당성**: 교사 평가와 강한 상관(r=0.754***)으로 객관성 입증

**수렴 패턴**:
- 양적 증거(LLM·교사 점수)와 질적 증거(지식 차원 분석)가 일관
- 객관적 평가와 주관적 체감(학생 설문)이 수렴
- 특히 **하위권 효과**가 모든 증거에서 일관 (LLM +2.26점, 교사 +6.32점, 대화1에서 K2→K3→K4)

다음 VI장에서는 이러한 결과의 교육적 의미, 시사점, 연구의 제한점을 논의한다.

---

**이전**: [[chapters/06-research-methods]] | **다음**: [[chapters/08-discussion-conclusion]]
