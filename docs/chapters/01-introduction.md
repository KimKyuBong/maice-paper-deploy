---
tags: [논문/서론, 논문/1장]
alias: [서론, 1장]
parent: "수학 학습에서 질문 명료화를 지원하는 AI에이전트 설계 및 개발 고등학교 2학년 수학적 귀납법 단원 중심으로"
---

# 1. 서론

## 1.1 연구의 필요성

### 1.1.1 수학 교육에서 생성형 AI 활용의 확산과 한계

대규모 언어 모델(Large Language Model, LLM)의 비약적 발전에 따라 ChatGPT, Claude 등 생성형 AI 도구가 교육 현장에 빠르게 도입되고 있다. 특히 수학 교육 영역에서는 학생들이 개념 이해, 문제 풀이, 추가 학습 등의 목적으로 LLM을 활용하는 빈도가 급증하고 있으며, 일부 교사들은 이를 보조 학습 도구로 활용하려는 시도를 하고 있다.

그러나 실제 교실 현장에서 LLM을 보조교사로 활용하려는 시도 과정에서, 교육적 효과성에 대한 근본적인 문제들이 지속적으로 관찰되었다. 현재 대부분의 LLM 기반 AI 도구는 학생의 질문에 즉각적으로 답변을 제공하는 **프리패스(FreePass) 방식**으로 작동한다. 이러한 방식은 신속한 정보 제공이라는 장점이 있으나, 학습자가 스스로 질문을 구조화하고 사고를 확장하는 과정을 지원하지 못하여 깊이 있는 학습을 저해할 가능성이 제기되고 있다.

### 1.1.2 학생 질문의 질적 문제: 실증 분석

본 연구에서는 실제 고등학교 수학 수업 환경에서 학생들이 LLM에 입력한 질문 1,012건을 수집하고, 중등 수학교사 4명으로 구성된 전문가 패널을 통해 질문과 AI 답변의 질을 체계적으로 평가하였다. 평가는 질문의 수학적 전문성, 질문 구조화, 학습 맥락 적용을 포함한 3개 영역(각 5점 만점)과, AI 답변의 학습자 맞춤도, 설명의 체계성, 학습 내용 확장성을 포함한 3개 영역(각 5점 만점)으로 구성된 루브릭을 개발하여 실시하였다.

학생 질문을 유형별로 분석한 결과, 다음과 같은 문제 패턴이 확인되었다:

#### 1.1.2.1 맥락 없는 개념 설명 요청

학생들은 "지수의 확장을 알려줘", "미분이 뭐야?", "적분이 어려워"와 같이 학습자의 현재 수준, 선수 지식, 학습 목적 등의 맥락 정보가 결여된 질문을 빈번하게 제시하였다. 이러한 질문에서는 AI가 적절한 난이도와 설명 방식을 선택할 수 있는 근거가 부족하여, 학습자 맞춤형 답변 생성이 구조적으로 불가능하다.

**예시:** "삼각함수 설명해줘" (학습자가 어떤 수준에서, 어떤 관점으로, 어떤 목적으로 설명이 필요한지에 대한 정보 부재)

#### 1.1.2.2 모호하고 불명확한 질문

"루트를 증명해줘", "이게 왜 맞는 거야?", "어떻게 푸는 거지?"와 같이 질문의 대상, 범위, 초점이 불명확한 질문이 다수 관찰되었다. 이러한 질문 구조에서는 AI가 학습자의 실제 어려움이나 구체적인 궁금증을 파악하기 어려워 적절한 답변을 생성할 수 없다.

**예시:** "이 공식이 왜 이렇게 되는지 모르겠어" (어떤 공식을 지칭하는지, 공식의 어느 부분이 이해되지 않는지 불분명)

#### 1.1.2.3 AI 답변에 부적절한 질문

"파이의 1억 자리까지 알려달라", "세상에서 가장 큰 소수는?", "무한대 곱하기 무한대는?"와 같이 교육적 가치가 결여된 단순 정보 요구나 AI의 계산 능력을 시험하려는 의도의 질문이 확인되었다.

**예시:** "AI가 정말 똑똑한지 테스트해볼게", "계산기보다 빠르게 계산해줘"

#### 1.1.2.4 수학과 무관한 질문

"오늘 날씨 어때?", "점심 뭐 먹을까?", "A와 B가 싸우면 누가 이겨?"와 같이 수학 학습 목적에서 완전히 이탈한 질문이 관찰되었다. 이는 학습 집중도를 저하시키고 AI의 교육적 역할 수행을 방해하는 요인으로 작용한다.

**예시:** "수학 공부하기 싫어", "다른 과목은 어떻게 공부해?", "수학이 실생활에 왜 필요한가?"

### 1.1.3 AI 답변의 질적 문제: 교사 루브릭 평가 결과

학생 질문에 대한 LLM의 답변을 동일한 교사 패널이 개발한 루브릭으로 평가한 결과, 심각한 교육적 한계가 확인되었다. 평가는 학습자 맞춤도(학습자 수준별 접근, 선수지식 연계성, 학습 난이도 조절), 설명의 체계성(개념 설명 위계화, 단계별 논리 전개, 핵심 요소 강조), 학습 내용 확장성(심화학습 방향 제시, 응용문제 연계성, 오개념 교정 전략) 영역으로 구성되었다.

특히 학습 맥락 적용 측면에서 학생 질문의 72.3%가 최저점(1점)을 받았으며, AI 답변의 학습 내용 확장성 측면에서 48.9%가 최저점을 기록하였다. 이는 현재 프리패스 방식의 LLM이 학습자의 맥락을 반영하지 못하고, 학습 과정을 확장하거나 심화하는 교육적 역할을 수행하지 못함을 의미한다.

구체적인 AI 답변의 문제점은 다음과 같다:

#### 1.1.3.1 개념 오해 및 맥락 부재

**학생 질문:** "지수의 확장에 대해 설명해줘"

**AI 답변:** "지수의 확장에 대해 설명하자면, 이는 지수가 영역을 확장하고 더 많은 지역이나 새로운 시장으로 진출하는 과정을 의미합니다. 이러한 확장은 일반적으로 비즈니스의 성장 및 발전 전략의 일환으로 이루어지며..."

**문제점:** 수학의 '지수(exponent)'와 비즈니스 용어인 '지점 확장'을 혼동하여, 학생이 요청한 수학 개념과 전혀 무관한 영역으로 답변을 제공하였다. 이는 질문에 학습 맥락 정보가 부족할 때 AI가 적절한 의미 해석에 실패함을 보여준다.

#### 1.1.3.2 학습 수준 불일치

**학생 질문:** "로지스틱 회귀가 뭐야?" (고등학교 1학년)

**AI 답변:** "로지스틱 회귀(logistic regression)는 데이터 분석에서 많이 사용하는 기법 중 하나로, 주로 두 가지 범주 중 하나로 분류하는 데 사용됩니다... 고등학교 1학년 수준에서 이해할 수 있도록 조금 더 쉽게 설명하면..."

**문제점:** AI는 "고등학교 1학년 수준"이라고 언급하였으나, 실제 설명 내용은 대학 수준의 통계학 개념(odds ratio, 최대우도추정 등)을 포함하고 있어 학습자의 실제 수준과 답변 내용 간 심각한 괴리가 발생하였다.

#### 1.1.3.3 교육과정 용어 부적절성

**학생 질문:** "수열이 뭐야?"

**AI 답변:** "수열은 여러 수학적 개념 중 하나로... **명시적 공식(Explicit Formula)** \(a_n\)을 \(n\)에 대한 함수로 표현합니다..."

**문제점:** 대한민국 수학 교육과정에서 표준 용어로 명시된 '일반항' 대신 '명시적 공식(Explicit Formula)'이라는 비표준 용어를 사용하여, 학생의 개념 형성과 교사-학생 간 의사소통에 혼란을 초래할 가능성이 높다.

#### 1.1.3.4 과도한 정보 제시로 인한 인지 과부하

학생이 요청하지 않은 관련 개념까지 한꺼번에 제시하는 문제가 공통적으로 관찰되었다. 예를 들어, "수열이 뭐야?"라는 질문에 대해 유한수열, 무한수열, 등차수열, 등비수열, 일반항, 점화식 등을 한 번에 설명함으로써, 학생이 각 개념을 단계별로 이해하고 소화할 수 있는 기회를 제공하지 못하였다.

이는 학습자의 현재 이해 수준과 필요성을 고려하지 않은 일방적 정보 전달 방식으로, 학습자의 인지적 부담을 가중시키고 비효율적인 학습 구조를 형성한다. 학습자의 반응이나 이해도에 따른 답변 조정 없이 모든 관련 정보를 동시에 제공하는 것은, 학생들이 한 번에 많은 새로운 지식을 처리하기 어렵다는 인지 심리학적 원리를 간과한 것이다.

### 1.1.4 프리패스 방식의 구조적 한계

이러한 문제점들은 단순히 개별 사례의 오류가 아니라, 현재 LLM이 채택하고 있는 프리패스 방식의 구조적 한계에서 비롯된다. 프리패스 방식은 질문의 질이나 맥락과 무관하게 즉각적인 답변을 제공함으로써, 학습자가 스스로 질문을 명료화하고 구조화하는 과정을 경험할 기회를 제공하지 않는다. 이는 학생들의 LLM 활용 만족도를 저하시킬 뿐만 아니라, 실질적인 학습 효과를 얻지 못하는 결과를 초래한다.

특히 수학적 귀납법과 같이 논리적 사고의 구조화와 단계적 추론이 핵심인 단원에서는, 프리패스 방식의 즉시 답변이 학생의 사고 과정을 충분히 유도하지 못하고 피상적 이해에 머무르게 하는 한계가 있다. 수학적 귀납법은 "n=1일 때 성립함을 보이고, n=k일 때 성립한다고 가정하면 n=k+1일 때도 성립함을 보인다"는 명확한 논리 구조를 요구하는데, 단순한 결론 제시만으로는 학생의 개념 이해와 적용 능력을 효과적으로 향상시키기 어렵다.

따라서 기존 프리패스 방식의 한계를 극복하고, 질문 명료화 과정을 통해 학습자의 사고 과정을 깊이 있게 지원하며, 교사 루브릭 평가에서 확인된 문제점들을 개선할 수 있는 새로운 AI agent 시스템의 개발이 필요하다.

## 1.2 연구 목적

본 연구는 고등학교 2학년 수학적 귀납법 단원을 중심으로, **일반적인 LLM 프리패스 방식보다 우수한 학습 효과를 제공하는 질문 명료화 기반 AI agent 시스템 MAICE(Mathematical AI Chatbot for Education)를 설계 및 개발**하는 데 목적이 있다. 구체적인 연구 목적은 다음과 같다:

1. **명료화 기반 멀티 에이전트 시스템 개발**: 교사 루브릭 평가에서 확인된 질문의 질적 문제를 개선하는 명료화 프로세스를 제공하는 멀티 에이전트 시스템 개발

2. **프리패스 대비 학습 효과성 검증**: MAICE 시스템이 일반적인 LLM 프리패스 방식보다 수학 학습 효과(이해도, 문제해결 능력, 질문 품질)에서 우수함을 실증적으로 검증

3. **학습 경험 개선 증명**: 명료화 프로세스를 통한 구조화된 학습 경험이 즉시 답변 방식보다 학습 만족도와 메타인지 향상에 기여함을 입증

4. **수학적 귀납법 단원 맞춤 설계**: 수학적 귀납법의 학습 특성(논리 구조 이해, 단계별 증명)을 고려한 단원별 맞춤형 agent 설계

## 1.3 연구 문제

본 연구에서 다루고자 하는 핵심 연구 문제는 다음과 같다:

**RQ1**: MAICE agent 시스템이 일반적인 LLM 프리패스 방식보다 수학적 귀납법 학습 효과(이해도, 문제해결 능력, 질문 품질 개선)에서 유의미하게 우수한가?

**RQ2**: MAICE agent의 명료화 프로세스를 통한 학습 경험이 즉시 답변 방식보다 학생의 학습 만족도와 메타인지 향상에 기여하는가?

## 1.4 용어의 정의

- **MAICE (Mathematical AI Chatbot for Education)**: 프리패스 방식보다 우수한 학습 효과를 제공하는 질문 명료화 기반 AI agent 시스템

- **프리패스(FreePass) 방식**: 사용자 질문에 대해 질문의 질이나 맥락과 무관하게 즉시 답변을 제공하는 기존 LLM의 일반적인 응답 방식

- **질문 명료화**: 모호하거나 불완전한 질문을 구체적이고 명확한 질문으로 개선하는 과정으로, 학습자가 스스로 질문을 구조화하고 사고 과정을 명료화하도록 지원하는 교육적 개입

- **멀티 에이전트 시스템**: 질문 분류, 명료화 지원, 답변 생성, 학습 관찰 등 각기 다른 역할을 수행하는 여러 개의 독립적인 AI agent가 협업하여 학습 과정을 지원하는 시스템

- **학습 효과**: 수학적 이해도, 문제해결 능력, 질문 품질 개선, 메타인지 향상 등을 포함하는 학습 성과와 학습 경험의 종합적 측정

---

**이전**: 없음 | **다음**: [[chapters/02-theoretical-background]]
