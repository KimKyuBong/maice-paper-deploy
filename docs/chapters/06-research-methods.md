# VI. 연구 방법

## 1. 연구 방법론: Design-Based Research

본 연구는 설계 기반 연구(Design-Based Research, DBR) 방법론을 채택하였다. DBR은 교육 이론을 실제 교육 맥락에서 검증하고, 실용적 산출물을 개발하며, 반복적 개선을 통해 설계 원리를 도출하는 연구 방법이다(Collins, Joseph, & Bielaczyc, 2004). Wang과 Hannafin(2005)은 DBR의 핵심 특징으로 실용성(pragmatic), 이론 기반(grounded), 상호작용성(interactive), 반복성(iterative), 유연성(flexible), 통합성(integrative)을 제시하였다.

본 연구의 DBR 수행 과정은 다음과 같다:

**1단계: 문제 분석 및 탐색**
- 예비조사(2024년 5월): 학생 질문 385건 분석
- 문제 확인: 질문 품질의 구조적 문제 (72.3% 학습 맥락 정보 부재, 45.8% 구조 불명확)
- 이론 탐색: Dewey의 반성적 사고, Bloom의 교육목표분류학

**2단계: 설계 및 구축**
- 이론 기반 설계: Dewey 5단계 반성적 사고를 멀티 에이전트 구조로 구현
- 시스템 개발: 5개 AI 에이전트(QuestionClassifier, QuestionImprover, AnswerGenerator, LearningObserver, FreeTalker)
- 평가 도구: QAC 루브릭 개발 (8개 항목, 32개 체크리스트, 40점 만점)

**3단계: 평가 및 반성**
- 현장 실험: 무작위 배정 A/B 테스트 (58명, 2024.10.21~11.1, 283개 세션)
- 다각도 평가: AI 3개 모델 자동 채점 + 교사 4명 평가
- 설계 원리 도출: 질문 명료화 중심 설계의 효과성 확인, 학습자 수준별 차별적 효과 발견

DBR의 반복적 특성에 따라, 본 실험 결과를 바탕으로 향후 시스템 개선 및 추가 검증 연구가 가능하다.

## 2. 연구 대상

### 가. 표본 선정

본 연구는 부산광역시 소재 ○○고등학교 2학년 4개 학급을 대상으로 하였다. 표집 방법은 연구자의 접근 가능성을 고려한 편의 표집(convenience sampling)이었으며, 학교와 학급 선정 기준은 다음과 같다:

### 나. 참여자 특성

[표 6-1] 연구 대상 개요

| 구분 | 내용 |
|------|------|
| **총 인원** | 58명 |
| **학년** | 고등학교 2학년 |
| **학교 유형** | 특수목적고등학교(공업계열) |
| **지역** | 부산광역시 |
| **연구 기간** | 2025년 10월 20일 ~ 11월 1일 (약 2주) |

**실험군과 대조군 구성**:
- **Agent 모드**: 28명
- **Freepass 모드**: 30명

**학생 사전 성적 분포** (중간고사 기준):
- 서술형 점수 (30점 만점): 평균 14.8점 (SD=8.5), 범위 0~30점
- 객관식 점수 (70점 만점): 평균 39.3점 (SD=11.1), 범위 14.6~61.7점
- 총점 (100점 만점): 평균 54.0점 (SD=17.5), 범위 17.9~89.9점

### 다. 예비 조사 (Pilot Study)

본 연구 설계에 앞서 2024년 5월에 예비 조사를 실시하여 프리패스 방식 LLM의 교육적 문제점을 파악하였다:

- **목적**: MAICE 시스템 설계의 필요성 검증
- **데이터**: 고등학교 수학 수업에서 수집한 385건의 질문-답변 쌍
- **평가단**: 현직 중등 수학교사 4명 (평균 경력 3.5년: 1년차 2명, 5년차 1명, 7년차 1명)
- **평가 방법**: 교육학 이론 기반 평가 기준 (6개 영역, 5점 척도)
- **총 평가 건수**: 1,012건 (교사 3-4명이 각 질문 평가)

예비 조사 결과, 학생 질문의 72.3%가 학습맥락 최저점을 받았고, 질문 품질과 답변 품질 간 강한 상관관계(r=0.691)가 발견되어, 질문 명료화 기반 AI 에이전트 시스템의 필요성이 실증적으로 확인되었다. 이 결과는 MAICE 시스템 설계의 핵심 근거가 되었다.

(상세 분석 결과는 `analysis/proto/평가결과_핵심요약.md` 참조)

### 라. 무작위 배정

학급 내 학생들을 실험군과 대조군에 무작위 배정하기 위해 MAICE 백엔드 시스템의 UserModeService를 활용하였다. 이 서비스는 학생이 시스템에 가입할 때 Python의 `random` 모듈을 사용하여 "agent" 또는 "freepass" 모드를 50:50 비율로 자동 배정한다. 배정된 모드는 `users` 테이블의 `assigned_mode` 필드에 저장되며, 연구 기간 동안 고정된다.

무작위 배정 결과, Agent 모드 28명, Freepass 모드 30명이 배정되었다. 두 집단 간 사전 중간고사 성적에서 통계적으로 유의한 차이가 없어 동질성이 확보되었다.

[표 6-2] 실험군과 대조군의 사전 동질성 검증 (중간고사 기준)

| 변인 | Agent 모드 (n=28) | Freepass 모드 (n=30) | t | p | 해석 |
|------|------------------|---------------------|---|---|------|
| | M(SD) | M(SD) | | | |
| 중간고사 총점 (100점) | 56.8(16.7) | 51.4(18.1) | 1.18 | .242 | 동질 |
| - 서술형 점수 (30점) | 15.6(8.5) | 14.0(8.5) | 0.74 | .462 | 동질 |
| - 객관식 점수 (70점) | 41.2(9.4) | 37.4(12.4) | 1.30 | .199 | 동질 |

**해석**: 모든 변인에서 p > .05로 두 집단 간 유의한 차이가 없어, 사전 동질성이 확보되었다. 이는 실험 처치 효과의 내적 타당도를 보장하는 중요한 근거가 된다.

### 마. 연구 윤리

**1. 연구 참여 동의**
- 모든 참여 학생과 보호자에게 연구 목적, 절차, 데이터 활용 방법을 설명하였다
- 학생 및 보호자로부터 서면 동의를 받았다
- 참여 거부 및 중도 철회 권리를 명시하였다

**2. 개인정보 보호**
- 수집된 데이터는 연구 목적으로만 사용되었다
- 데이터는 암호화된 서버에 저장하고, 연구자만 접근 가능하도록 제한하였다

**3. 참여자 익명화**
- 모든 학생 학번(24.xxx)을 익명 ID(S01~S58)로 변환하여 사용하였다
- 익명화 규칙:
  - Agent 모드 학생: S01 ~ S28 (28명)
  - Freepass 모드 학생: S29 ~ S58 (30명)
- 익명화 매핑 테이블은 별도 암호화 파일로 관리하며, Git 저장소에서 제외하였다
- 논문 및 연구 보고서에는 익명 ID만 사용하여 개인 식별 불가능하도록 하였다

**4. 참여자 보호**
- 연구 참여로 인한 학업 불이익이 없음을 보장하였다
- 두 모드(Agent/Freepass) 모두 교육적 가치를 제공하도록 설계하였다
- 연구 종료 후 모든 참여자에게 두 모드의 사용 기회를 제공하였다

**5. 데이터 보관 및 폐기**
- 연구 데이터는 연구 종료 후 3년간 보관하며, 이후 안전하게 폐기한다
- 논문 출판 시 개인을 특정할 수 있는 정보는 일체 포함하지 않는다

**6. 비익명 설문 수집 및 Response Bias 대응** ⭐

본 연구는 사후 설문조사에서 학생의 이메일 주소를 수집하였다. 이는 다음과 같은 방법론적 필요성과 윤리적 고려사항을 포함한다:

**비익명 수집의 불가피성**:

완전 익명 설문이 Response Bias(응답 편향)를 줄일 수 있음에도 불구하고, 본 연구의 핵심 질문인 "Agent vs Freepass 모드의 효과성 비교"를 위해서는 식별자 수집이 필수적이었다:

1. **모드 할당 추적**: 각 학생이 어느 모드를 사용했는지 확인하여 설문 응답과 연결
2. **객관적 데이터 연계**: 설문 응답을 다음과 매칭하여 교차 검증
   - QAC 점수 (AI 평가자 채점 결과)
   - 교사 평가 점수 (독립 평가자)
   - 세션 사용 데이터 (행동 패턴)
3. **개인별 학습 궤적 추적**: 사전-사후 변화 및 학습 패턴 분석

**Response Bias 위험 인식**:

연구진은 다음과 같은 편향 위험을 충분히 인지하고 있다:

1. **교사-연구자 이중 역할**: 
   - 주 연구자가 참여 학생들의 수학 담당 교사이자 시스템 개발자
   - 학생들이 이를 인지하고 있어 사회적 바람직성 편향(Social Desirability Bias) 위험
   
2. **비익명 응답**:
   - 이메일 주소 수집으로 완전 익명성 불가
   - 솔직한 비판적 피드백 회피 가능성
   
3. **요구 특성(Demand Characteristics)**:
   - 연구 목적(질문 유도 방식의 효과성)이 은연중 노출 가능
   - 연구자 기대에 부응하려는 경향 가능

**완화 전략 및 방법론적 Trade-off**:

비익명 설계가 편향을 만들었으나, 역설적으로 **동일한 설계가 편향을 검증할 수단**도 제공하였다:

1. **주요 증거는 객관적 데이터**:
   - QAC 점수 (AI 평가): Response Bias 없음
   - 교사 평가: 독립 평가자, 편향 낮음
   - 사용 패턴: 행동 데이터, 편향 없음
   
2. **설문은 보조 자료**:
   - "학습자 인식" 파악 목적
   - 주요 효과성 주장의 근거는 객관적 데이터
   
3. **삼각측정(Triangulation)**:
   - 설문 결과를 객관적 데이터와 교차 검증
   - 수렴 여부 분석
   - 불일치 시 객관적 데이터 우선
   
4. **보수적 해석**:
   - 설문 결과를 "상한선"으로 해석
   - 과장된 주장 회피

**만약 익명이었다면**:
- ❌ 모드별 비교 불가능 (핵심 연구 질문 답변 불가)
- ❌ 객관적 데이터와 교차 검증 불가
- ❌ 편향 정도 추정 불가
- ❌ 설문만으로 주장 (더 약한 연구)

**비익명 설계 덕분에**:
- ✅ 모드별 효과성 객관적 검증 가능
- ✅ 설문-성과 간 상관관계 분석 가능
- ✅ 편향 영향 정도 추정 가능
- ✅ 더 강력한 삼각측정

**결론**: 비익명 수집이 만든 Response Bias 위험은 객관적 데이터와의 강력한 삼각측정으로 보완하였다. 설문은 "학습자 경험과 인식"을 이해하는 보조 자료로 활용하며, 주요 효과성 주장은 QAC 점수와 교사 평가라는 객관적 증거에 기반한다 (상세한 내용은 8.3.6 Limitations 참조).

### 바. 실험 설계 및 진행 절차

**1단계: 수학적 귀납법 개념 학습 (사전 교육)**

A/B 테스트 시작 전, 모든 학생에게 수학적 귀납법에 대한 수업을 진행하였다. 수업은 **학생 선행 학습 + 교사 해설** 방식으로 진행되었으며, 매 수업 해설마다 핵심 개념을 반복적으로 강조하였다:

**[표 6-2-1] 수학적 귀납법 수업 구조 및 핵심 개념**

| 단계 | 내용 | 강조 개념 | 교수법 |
|------|------|----------|--------|
| **첫 수업** | 수학적 귀납법의 원리와 구조 | **① 템플릿과 도미노 모델**<br>• 3단계 구조 (베이스, 가정, 결론)<br>• 도미노 비유: "첫 번째가 넘어지고, 하나가 넘어지면 다음도 넘어지면, 모두 넘어진다"<br>• 증명의 표준 형식 제공 | 강의 중심<br>개념 도입 |
| **매 수업<br>(과제 풀이)** | 학생들이 문제를 미리 풀고 제출 | - | 선행 학습<br>시행착오 경험 |
| **매 수업<br>(교사 해설)** | 제출된 문제를 해설하며<br>핵심 포인트 반복 강조 | **② 귀납가정 → 귀납결론 유도**<br>• k일 때 성립한 가정을 k+1 증명에 어떻게 활용하는가<br>• 논리적 연결고리 찾기<br><br>**③ 등식 vs 부등식 전략**<br>• 등식: "필요한 재료만 딱 맞게" (정확성 강조)<br>• 부등식: "스페어 부품도 있는" (부등호 여유 활용)<br>• 명제 유형별 차별적 접근 | 예제 중심<br>반복 강조 |

**수업의 핵심 특징**:

1. **선행 학습 기반 수업**:
   - 학생들이 먼저 문제를 풀어보고 제출 → 능동적 학습 경험
   - 교사는 학생들의 시도를 바탕으로 맞춤형 해설 제공
   - 시행착오를 통한 깊이 있는 이해 촉진

2. **비유적 접근의 반복**:
   - **도미노 모델**: 증명 원리의 직관적 이해 ("연쇄 반응")
   - **재료 비유**: 등식은 "딱 맞는 재료", 부등식은 "여유 있는 재료"
   - 매 해설마다 반복 강조하여 학생들의 **공통 언어**로 정착

3. **핵심 과정의 강조**:
   - 귀납가정(k일 때 참)을 귀납결론(k+1일 때 참) 증명에 **어떻게 연결**하는가
   - 단순 형식 암기가 아닌 **논리적 연결 과정** 이해

**AI 학습과의 연결**:
이러한 선행 학습 경험과 반복 강조된 개념들은 A/B 테스트 기간 동안 학생들이 AI와 대화할 때 **사고의 틀과 공통 언어**로 작용하였다. 특히 "도미노", "재료" 등의 비유가 학생들의 질문과 AI의 답변에서 자연스럽게 활용되었다.

**2단계: 수리논술 과제 단계적 부여 및 MAICE 활용 학습**

본 연구는 2025학년도 2학기 수학 수리논술 수행평가의 일환으로 총 5개의 수학적 귀납법 증명 과제를 단계적으로 부여하였다. 학생들은 각 과제를 해결하는 과정에서 **수업 시간**(40분) 및 **쉬는 시간**(10-15분)을 활용하여 MAICE 시스템에 자유롭게 접근하였다.

**과제 구성 및 진행 방식**:

[표 6-3] 수리논술 과제 세부 내용

| 과제 | 문제 1 | 문제 2 | 주요 개념 |
|:----:|--------|--------|----------|
| **과제 1** | 등비급수 합 공식<br/>$1+2+4+\cdots+2^{n-1} = 2^n-1$ | 팩토리얼 부등식<br/>$n! > 2^n$ (n≥4) | 기본 급수, 팩토리얼 |
| **과제 2** | 피보나치 수열 합<br/>$F_{n+2}=F_n+F_{n+1}$, $F_1=F_2=1$<br/>→ $\sum_{i=1}^{n} F_i = F_{n+2}-1$ | 지수 부등식<br/>$n^2 < 2^n$ (n≥5) | 점화식, 부등식 |
| **과제 3** | 팩토리얼 곱셈 공식<br/>$1×1!+2×2!+\cdots+n×n! = (n+1)!-1$ | 로그 부등식<br/>$\log_2 n < n$ | 곱셈 전개, 로그 |
| **과제 4** | 제곱수 합 공식<br/>$1^2+2^2+\cdots+n^2 = \frac{n(n+1)(2n+1)}{6}$ | 제곱 부등식<br/>$n < n^2$ (n≥2) | 제곱수 급수, 부등식 |
| **과제 5** | 하노이탑 점화식<br/>$a_{n+1}=2a_n+1$, $a_1=1$<br/>→ $a_n=2^n-1$ 증명 | 거듭제곱 부등식<br/>$n! < n^n$ (n≥2) | 점화식, 거듭제곱 |

**학습 과정 구조**:

```
[과제 부여] → [학생 개별 풀이 시도]
                    ↓
              [막히는 부분 발생]
                    ↓
         [MAICE 시스템 활용]
    - Agent 모드: 명료화 질문 → 문제 구체화 → 맞춤 답변
    - Freepass 모드: 즉시 답변 제공
                    ↓
         [풀이 과정 개선 및 완성]
                    ↓
         [교사와 함께 풀이 검토]
                    ↓
              [다음 과제 진행]
```

**MAICE 활용 방식**:

1. **수업 시간 활용** (주 활용 시간):
   - 교사가 과제를 제시한 후 개별 풀이 시간 제공 (수업 40분 중 20-30분)
   - 학생이 풀이 중 막히는 부분 발생 시 즉시 MAICE 접속
   - 개인 노트북/태블릿으로 AI와 대화하며 문제 해결 과정 탐색
   - 예시 질문: "귀납 가정을 어디에 사용하나요?", "이 식을 어떻게 전개하죠?", "제 풀이 맞나요?"

2. **쉬는 시간 활용** (보조 활용):
   - 수업 시간에 완전히 해결하지 못한 부분을 쉬는 시간에 추가 질문
   - 자신의 풀이를 검토하고 싶을 때 MAICE에 풀이 과정 입력 후 피드백 요청
   - 평균 2-3회의 짧은 대화 세션 (세션당 5-10분)

3. **과제 해결 패턴**:
   - **Agent 모드 학생**: 명료화 질문을 통해 문제를 단계별로 구체화하며 해결
   - **Freepass 모드 학생**: 즉시 제공되는 답변을 참고하여 풀이 작성

**교사 협력 학습**:
- 각 과제 제출 후 교사가 학급 전체와 함께 표준 풀이 과정 검토
- 학생들이 MAICE를 통해 얻은 인사이트를 수업 중 공유
- 일반적인 오류 및 개선 방향 논의

**데이터 수집**:
- 모든 학생-AI 대화 내용 자동 저장 (총 284개 세션)
- 세션별 질문 품질, 답변 품질, 학습 지원 수준 자동 평가
- 학생별 과제 완성도 및 제출 시간 기록

**실험 일정 및 기간**:

[표 6-4] 수리논술 과제 실시 일정

| 회차 | 과제 | 활동 내용 | 수업 시간 |
|:----:|:----:|----------|----------|
| **1회차** | - | 수학적 귀납법 개념 학습<br/>MAICE 시스템 사용법 안내 | 1교시 (40분) |
| **2회차** | 과제 1 | 등비급수, 팩토리얼 부등식<br/>+ 풀이 검토 및 피드백 | 1교시 (40분) |
| **3회차** | 과제 2 | 피보나치 수열, 지수 부등식<br/>+ 풀이 검토 및 피드백 | 1교시 (40분) |
| **4회차** | 과제 3 | 팩토리얼 곱셈, 로그 부등식<br/>+ 풀이 검토 및 피드백 | 1교시 (40분) |
| **5회차** | 과제 4 | 제곱수 합, 제곱 부등식<br/>+ 풀이 검토 및 피드백 | 1교시 (40분) |
| **6회차** | 과제 5 | 하노이탑, 거듭제곱 부등식<br/>+ 풀이 검토 및 피드백 | 1교시 (40분) |
| **7회차** | - | 전체 과제 종합 리뷰 및 심화 문제 풀이 | 1교시 (40분) |
| **8회차** | - | 사후 설문 및 연구 종료 | 1교시 (40분) |

**총 실험 기간**: 약 2주 (2025년 10월 20일~11월 1일, 총 8회차 수업)
- **개념 학습**: 1회차
- **과제 활동 및 풀이 검토**: 2~6회차 (각 과제 수행 + 수업 말미 검토)
- **종합 리뷰**: 7회차
- **사후 설문**: 8회차
- **MAICE 활용 가능 시간**: 수업 중 20-30분 + 쉬는 시간 10-15분
- **총 세션 수**: 284개 (Agent 모드 118개, Freepass 모드 162개)
- **유효 세션** (메시지 ≥2): 280개 (Agent 118개, Freepass 162개)
- **평균 세션 길이**: 약 15분 (최소 3분 ~ 최대 45분)

**3단계: 모드별 AI 활용 패턴 관찰**
- **Agent 모드**: 명료화 질문을 통한 질문 구체화 과정 경험
- **Freepass 모드**: 즉시 답변 제공 방식으로 학습

**4단계: 데이터 수집 및 평가**

본 연구는 수집된 세션 데이터를 다각도로 분석하여 신뢰성과 타당성을 확보하고자 하였다.

#### (1) 다중 AI 모델 채점 시스템

평가자 편향(rater bias)을 최소화하고 채점 신뢰성을 높이기 위해 3개의 독립적인 대규모 언어 모델을 평가자로 활용하여 교차 검증을 실시하였다:

[표 6-5] AI 모델 채점자 구성

| 모델 | 개발사 | 버전 | 선정 이유 |
|------|--------|------|----------|
| **Gemini 2.5 Flash** | Google | gemini-2.5-flash | 긴 맥락 처리 능력, Batch API 지원, 한국어 성능 우수 |
| **Claude 4.5 Haiku** | Anthropic | claude-haiku-4-5 | 빠른 처리 속도, 일관성 있는 평가, Message Batches 지원 |
| **GPT-5 mini** | OpenAI | gpt-5-mini | 범용적 평가 능력, 비용 효율성, Batch API 지원 |

**채점 절차**:
1. 모든 세션 데이터를 JSON 형식으로 수집
2. 각 모델에 동일한 QAC 체크리스트와 평가 프롬프트 제공
3. 모델별로 독립적으로 채점 수행 (블라인드 평가)
4. 3개 모델 점수의 평균(Ensemble)과 개별 모델 점수 모두 분석

**QAC 체크리스트 구성** (40점 만점)
- **A영역: 질문 평가** (16점)
  - A1. 수학적 전문성 (6점)
  - A2. 질문 구조화 (6점)
  - A3. 학습 맥락 (4점)
- **B영역: 답변 평가** (16점)
  - B1. 학습자 적합성 (6점)
  - B2. 설명 체계성 (6점)
  - B3. 학습 확장성 (4점)
- **C영역: 학습 지원** (8점)
  - C2. 대화 일관성 (4점)
  - C3. 학습 지원 (4점)
- **체크리스트**: 32개 세부 요소 (각 영역별 4개 항목)

각 모델은 JSON 형식으로 점수와 함께 체크리스트 달성 여부를 출력하도록 설계되었다.

**모델 간 신뢰도 검증 방법**:
- Pearson 상관계수: 모델 쌍별 점수 일치도
- 급내상관계수(ICC): 전체 평가자 간 신뢰도
- Cronbach's Alpha: 내적 일관성
- Bland-Altman plot: 모델 간 점수 차이 분포

#### (2) 교사 평가를 통한 타당도 검증

AI 채점의 타당성을 검증하기 위해 현직 교사 4명이 무작위로 선정된 세션을 독립적으로 평가하였다:

**[표 6-5-1] 교사 평가단 구성 (외부 평가자)**


**[표 6-6] QAC 체크리스트 구성 (40점 만점, 8개 항목)**

| 평가자 ID | 교과 | 평가 세션 수 | 비고 |
|---------|-----|------------|------|
| 평가자 96 | 수학 | 100개 | 외부 평가자 (대응 평가) |
| 평가자 97 | 수학 | 100개 | 외부 평가자 (대응 평가) |
| **합계** | 수학 2명 | **200개** | 현직 교사 |

> **주**: 연구 객관성 확보를 위해 연구자(평가자 16)와 정보 교사(평가자 93)는 분석에서 제외하고, 수학 교사 2명의 결과만 사용하였다. 두 평가자는 동일한 100개 세션을 독립적으로 평가하여 완벽한 대응 평가(paired evaluation)를 수행하였다.

**평가 방법**: 
  - 두 평가자가 동일한 세션을 독립적으로 평가 (완벽한 대응 평가)
  - AI 모델과 동일한 QAC 체크리스트 사용
  - 학생 모드 정보 블라인드 처리
  - 교사 평가 완료 후 AI 채점 결과와 비교
  
**타당도 검증 방법**:
  - **교사 간 신뢰도 분석**: 
    - Pearson 상관계수를 통한 평가자 쌍별 일치도 계산
    - Spearman 상관계수를 통한 순위 일치도 계산
    - 급내상관계수(ICC), Cronbach's Alpha
  - **AI-교사 일치도 분석**:
    - 교사 평가 평균 vs AI 채점 평균 상관분석 (Pearson r)
    - 영역별(A, B, C) 상관계수 계산
    - 세부 항목별(A1~C3) 일치도 분석
  - **모드별 점수 차이 비교**:
    - 교사별 Agent vs Freepass 점수 차이 분석
    - 효과 크기 (Cohen's d) 계산

#### (3) 다층적 분석 전략

수집된 데이터를 다음과 같은 다층적 기준으로 분석하여 종합적인 효과를 검증하고자 하였다:

**① 항목별 분석**:
- 8개 평가 영역별 점수 비교 (A1~A3, B1~B3, C2~C3)
- 32개 체크리스트 요소별 달성률 분석
- 질문 품질, 답변 품질, 학습 맥락 점수 독립 분석

**② 사전 성취도 수준별 분석**:
- **Quartile 분석**: 중간고사 점수 기준 4분위
  - Q1 (하위 25%), Q2, Q3, Q4 (상위 25%)
- **Tertile 분석**: 3분위로 구분
  - T1 (하위 33%), T2, T3 (상위 33%)
- **연속 구간 분석**: 10점 단위 구간별 비교
- 각 구간에서 Agent vs Freepass 효과 크기 계산

**③ 종단적 학습 효과 분석**:
- 복수 세션 참여 학생 대상 누적 변화 추적
- 각 학생의 첫 세션 점수 vs 마지막 세션 점수 비교
- 세션 순서에 따른 점수 변화 추이 분석
- 점수 변동성(표준편차) 변화 분석

**④ 질적 데이터 수집 및 분석**:

**사후 설문 조사**:

실험 종료 후 학생들의 주관적 경험을 파악하기 위해 사후 설문조사를 실시하였다:

- **응답 학생**: 38명 (응답률 65.5%, Agent 모드 및 Freepass 모드 경험자)
- **블라인드 설계**: 학생들은 자신이 Agent인지 Freepass인지 모르는 상태에서 응답
- **서술형 문항** (5개):
  1. MAICE 대화 경험을 자유롭게 서술
  2. 사용 전후 변화
  3. 답변 방식 선호도 (A: 즉시 답변 vs B: 질문 유도)
  4. 가장 기억에 남는 순간
  5. 개선 제안

**주제 분석 절차** (Braun & Clarke, 2006):

1. **데이터 숙지**: 전체 응답 반복 읽기로 전체적 맥락 파악
2. **초기 코딩**: 의미 있는 응답 단위를 귀납적으로 코드화
3. **테마 탐색**: 유사한 코드를 그룹화하여 후보 테마 도출
4. **테마 검토**: 원본 데이터와 대조하여 타당성 점검
5. **테마 정의**: 각 테마의 명확한 정의와 명칭 확립
6. **보고서 작성**: 학생 응답 원문 인용과 함께 학술적 보고

**블라인드 실험의 장점**:

- **응답 편향 최소화**: 자신의 모드를 지지하려는 경향 제거
- **객관적 평가**: 실제 경험에 기반한 순수한 평가
- **교육적 가치 검증**: 설문에서 A/B 방식을 설명하고 선호도를 조사하여, 경험과 무관하게 교육적 가치를 평가 가능

**삼각검증 전략** (Triangulation):

양적 분석(QAC 점수)과 질적 분석(서술형 응답)을 통합하여 연구 결과의 신뢰성과 타당성을 확보하였다. 이는 Mixed Methods 연구의 핵심 전략으로, 서로 다른 방법론의 강점을 결합하여 더 풍부하고 깊이 있는 이해를 제공한다.

**⑤ 통계 분석 방법**:
- **독립표본 t-검정**: Agent vs Freepass 집단 간 비교
- **대응표본 t-검정**: 같은 학생의 세션 간 변화
- **Cohen's d**: 효과 크기 계산 (small: 0.2, medium: 0.5, large: 0.8)
- **Pearson 상관분석**: 변인 간 관계 분석
- **신뢰도 분석**: ICC, Cronbach's Alpha
- **유의수준**: α = .05 (양측검정)

> 주: QAC 체크리스트 세부 정의와 채점 기준은 `docs/부록_A_루브릭_상세설명서.md` 참조. 실제 분석 결과는 7장에서 제시한다.

## 3. 통제 변인

본 연구에서는 실험 처치(Agent 모드 vs Freepass 모드) 외에 학습 효과에 영향을 미칠 수 있는 변인들을 다음과 같이 통제하였다:

**[표 6-7] 통제 변인 및 통제 방법**


**[표 6-8] QAC 체크리스트 신뢰도 및 타당도 분석 결과**

| 변인 범주 | 구체적 변인 | 통제 방법 |
|----------|-----------|----------|
| **학습 과제** | 과제 내용 | 동일한 수학적 귀납법 과제 5개 부여 |
| | 과제 난이도 | 동일한 순서와 난이도로 제시 |
| | 제출 기한 | 양 집단 동일한 제출 일정 |
| **교사 효과** | 수업 진행 | 동일 교사가 모든 학급 수업 진행 |
| | 수업 내용 | 수학적 귀납법 개념 학습 내용 동일 |
| | 풀이 검토 | 양 집단 동일한 방식으로 과제 검토 |
| **학습 자료** | 교과서 | 동일 교과서 사용 (수학Ⅰ) |
| | 과제 자료 | 동일한 수리논술 문제지 제공 |
| **기술 환경** | 접근 기기 | 개인 노트북 또는 태블릿 사용 |
| | 네트워크 | 학교 Wi-Fi 환경 |
| | MAICE 시스템 | 동일한 시스템 버전 및 UI |
| **사전 지식** | 선수 학습 | 수열 단원 선수 학습 완료 |
| | 기초 개념 | 1회차에 수학적 귀납법 개념 사전 교육 (양 집단 동일) |
| **평가 방법** | AI 채점 | 3개 AI 모델 + Ensemble 평균 (블라인드 채점) |
| | 채점 기준 | 동일 QAC 체크리스트 (40점 만점) |
| | 평가 시점 | 모든 세션 데이터 수집 후 일괄 채점 |

**통제되지 않은 변인 (연구 제한점)**:
- **MAICE 활용 시간**: 학생마다 수업 중/쉬는 시간 활용 정도 상이
- **세션 횟수**: 학생의 자발적 선택에 따라 사용 빈도 다름 (1~13회)
- **학습 습관**: 개인별 학습 전략 및 스타일 차이
- **가정 학습**: 학교 밖 추가 학습 시간 및 자료 사용
- **동료 효과**: 친구 간 정보 공유 및 상호작용
- 개인별 인지 능력 차이

이러한 통제되지 않은 변인들은 무작위 배정을 통해 두 집단에 균등하게 분산되도록 하였으며, 연구 결과 해석 시 한계점으로 고려되었다.

## 4. 연구 도구

### 가. 질문 품질 평가 도구

**QAC 체크리스트 (Question-Answer-Context Checklist)**

- **구성**: 3개 영역 8개 세부 항목 (40점 만점)
  - 질문 영역(A): A1 수학적 전문성, A2 질문 구조, A3 학습 맥락
  - 답변 영역(B): B1 학습자 맞춤, B2 설명 체계성, B3 학습 확장성
  - 맥락 영역(C): C1 대화 일관성, C2 학습 지원
- **척도**: 5점 리커트 척도 (각 항목 0-5점)
- **총점**: 40점 만점 (질문 15점 + 답변 15점 + 맥락 10점)
- **평가자**: AI agent 자동 평가 + 교사 평가

##### QAC 체크리스트 개발 배경

**이론적 기반**:
QAC 체크리스트는 Dewey의 반성적 사고 이론과 질문 생성 이론에 기반하여 개발되었다. **8개 항목**(A1-A3, B1-B3, C2-C3)은 질문 품질(A), 답변 품질(B), 학습 맥락(C)의 3개 영역으로 구조화되었으며, 각 항목당 4개의 체크리스트 요소(총 32개)로 구성되었다.

**개발 과정**:
- 초기 v4.0: 45점, 9개 항목 (C1 명료화 효과성 포함)
- v4.3 (최종): 40점, 8개 항목 (C1 제외하여 Agent 편향 제거)
- 체크리스트 방식 도입: 각 요소를 0/1로 평가하고 근거(evidence) 제시

**타당도 및 신뢰도 확보 방법**:

**1) 내용 타당도 (Content Validity)**
- Dewey의 반성적 사고 이론, 질문 생성 이론 등 교육학 이론 기반
- 8개 항목이 교육적 효과의 핵심 요소를 포함

**2) 전문가 타당도 (Expert Validity)**
- 현직 수학교사 4명의 검토 및 피드백 반영
- 체크리스트 요소의 교육적 타당성 검증

**3) 준거 타당도 (Criterion Validity)**
- 교사 평가(100개 세션)와 AI 채점 간 상관분석 실시
- 상세 결과는 7장에서 제시

**4) 평가자 간 신뢰도 (Inter-rater Reliability)**
- 3개 독립 AI 모델(Gemini, Claude, GPT-5)로 교차 검증
- 221개 공통 세션 분석 결과:
  - ICC(2,1) = 0.595 (보통 수준, Cicchetti 1994 기준)
  - Cronbach's α = 0.840 (좋은 수준, >0.80 기준)
  - 평균 Pearson r = 0.649 (중간~강한 상관)
- 개별 세션 점수는 평가자에 따라 다소 변동할 수 있으나, 전체 통계적 패턴과 결론은 일관적으로 재현됨
- 상세 검증 결과는 7장 7.6.2절 참조

(QAC 체크리스트 상세 설명 및 신뢰도 검증 결과는 부록 A 참조)

### 나. 학생 수준 분류 기준

**중간고사 성적 활용 (수열 단원 선수 학습 수준)**

본 연구는 학생들의 사전 학업 수준을 파악하고 수준별 효과를 분석하기 위해, 수학적 귀납법 단원 학습 **이전에** 실시된 중간고사 성적을 활용하였다. 이 중간고사는 수학적 귀납법의 선수 학습 내용인 **수열 단원**(등차수열, 등비수열, 여러 가지 수열의 합)에 대한 이해도를 평가한 시험이다.

**성적 구성**:
- **서술형 문항** (30점 만점): 수열의 합, 등차/등비수열 증명 과정 서술
- **객관식 문항** (70점 만점): 수열 개념 이해 및 적용
- **총점** (100점 만점): 서술형 + 객관식

**평가 내용** (수학적 귀납법의 선수 학습):
- 등차수열의 일반항 및 합 공식
- 등비수열의 일반항 및 합 공식
- 여러 가지 수열의 합 (∑ 기호 활용)
- 수열의 귀납적 정의 (점화식)

**활용 목적**:
1. **학생 수준 분류**: 삼분위수로 하위 33%, 중위 33%, 상위 33% 구분
2. **사전 동질성 검증**: Agent vs Freepass 집단 간 선수 학습 수준 비교
3. **조절 변수**: 학업 수준별 차별적 효과 분석
4. **선수 학습 지표**: 수학적 귀납법 학습을 위한 기초 개념 이해도 대표

**중요**: 본 연구는 중간고사 성적을 사전-사후 비교에 사용한 것이 아니라, **수학적 귀납법 학습 전 선수 학습 수준을 나타내는 독립적 기준**으로 활용하였다. 실제 학습 효과는 **QAC 체크리스트 점수의 세션별 변화**로 측정하였다.

### 다. 시스템 로그 데이터

세션별 대화 내용과 상호작용 패턴을 분석하기 위해 PostgreSQL 데이터베이스에서 자동 수집된 로그 데이터를 활용하였다.

**Agent 모드 로그**:
- 명료화 대화 횟수 및 질문 개선 정도
- 에이전트별 응답 시간 및 처리 과정
- 학습자 질문 진화 추이
- 세션 단계별 전환 패턴

**Freepass 모드 로그**:
- 즉시 답변 횟수 및 대화 길이
- 후속 질문 발생 패턴
- 메시지 유형별 분포

**수집 데이터**:
- 세션 메시지 수, 평균 메시지 길이
- 세션 지속 시간 (추정)
- 사용자-AI 상호작용 횟수

## 5. 자료 수집 및 분석

### 가. 정량적 분석

**집단 간 비교 분석**:
- 독립표본 t-검정: Agent vs Freepass 모드 간 QAC 점수 차이 검증
- Welch's t-test: 등분산 가정 위배 시 사용
- Mann-Whitney U test: 비모수 검정

**세션 증가폭 분석**:
- 대응표본 t-검정: 각 학생의 1회차 vs 최종회차 QAC 점수 변화
- 천장효과 보정: proportional improvement = (후반 평균 - 전반 평균) / (15 - 전반 평균)

**효과 크기 계산**: 
- Cohen's d를 주 효과 크기 지표로 사용
- Hedge's g (소표본 보정)와 Cliff's delta (비모수 효과 크기)를 보조적으로 산출
- 평균 차이의 95% 신뢰구간은 Bootstrap 방법(재표본추출 1,000회)으로 추정
- 효과 크기 해석은 Cohen(1988)의 기준을 따름: d = 0.2 (작은 효과), 0.5 (중간 효과), 0.8 (큰 효과)
- Hattie (2009)는 교육 개입의 평균 효과크기가 d=0.4임을 제시하였으며, 이를 '힌지 포인트(hinge point)'로 명명하였다. 본 연구에서는 이를 참고하되, Cohen의 전통적 기준을 주요 해석 틀로 사용한다

**학업 수준별 차별적 효과 분석**:
- 중간고사 성적 기준 삼분위수(tertiles) 분류
- 각 수준별 Agent vs Freepass 효과 비교
- 상호작용 효과 검증

### 나. 질적 분석
- **대화 패턴 분석**: 명료화 유형, 학생 응답 패턴, 학습 진화 추이
- **세션 사례 분석**: 명료화 성공/실패 사례의 질적 코딩
- **로그 데이터 분석**: 메시지 유형, 세션 단계, 상호작용 길이

### 다. 데이터 수집 및 필터링 상세

**데이터 수집**:
- **수집 기간**: 2025년 10월 20일 ~ 11월 1일 (실험 기간과 동일)
- **수집 방법**: PostgreSQL 데이터베이스에서 학생 세션 자동 수집
- **수집 대상**: 고등학교 2학년 수학적 귀납법 학습 중 AI 활용 전체 대화 세션
- **원본 데이터**: 
  - 세션 데이터: `학생세션_수집_20251103_134440.json` (총 284개 세션, 58명 학생, 1407개 메시지)
  - AI 채점 데이터 (3개 모델 배치 채점):
    - Gemini 2.5 Flash: `gemini_results_20251105_174045.jsonl` (284개)
    - Claude 4.5 Haiku: `anthropic_batch_20251105_171246.jsonl` (284개)
    - GPT-5 mini: `openai_batch_20251105_171235.jsonl` (284개)

**데이터 필터링 (대화 유효성 검증)**:

본 연구는 학습 상호작용의 질을 정확히 측정하기 위해 다음 기준으로 유효 세션을 선별하였다:

1. **메시지 개수 ≥ 2**: 최소한의 상호작용이 존재하는 세션만 포함
2. **역할 공존**: `user` AND (`maice` OR `assistant`) 메시지가 모두 존재
   - 학생 질문과 AI 응답이 모두 있는 완전한 대화만 분석
3. **내용 유효성**: 모든 메시지 `content`가 공백이 아님
   - 기술적 오류나 빈 메시지가 없는 세션만 포함
4. **세션 완결성**: 마지막 발화자가 `user`가 아님
   - AI가 최종 응답을 제공한 완결된 세션만 분석

**필터링 결과**:
- **전체 세션**: 284개 (Agent 118개, Freepass 162개)
- **유효 세션** (메시지 ≥2): 280개 (Agent 118개, Freepass 162개)
  
  **참고**: 전체 세션과 유효 세션의 Agent 수가 동일한 이유는 Agent 모드의 모든 세션이 메시지 2개 이상을 충족했기 때문이다. Freepass 모드도 동일하게 모든 세션이 유효 세션 기준을 충족하였다.
  
- **분석 대상 학생**: 58명
  - Agent 모드: 28명
  - Freepass 모드: 30명
- **설문 응답자**: 38명 (응답률 65.5%)
- **다회 세션 학생**: 상당수 (2회 이상 세션 이용자, 학습 증가폭 분석 대상)

**AI 배치 채점 (Batch API)**:
- **채점 모델**: 3개 독립 AI 모델 (Gemini 2.5 Flash, Claude 4.5 Haiku, GPT-5 mini)
- **채점 방식**: Batch API를 통한 병렬 채점 (비용 효율적, 일관성 ⬆️)
- **채점 기준**: QAC 체크리스트 (A영역 15점 + B영역 15점 + C영역 10점 = 총 40점)
- **채점 대상**: 전체 284개 세션 (Agent 118개, Freepass 162개)
  - Gemini: 284개 전체
  - Claude: 221개 (일부 세션 처리 오류로 제외)
  - GPT-5: 284개 전체
- **채점 스크립트**: `analysis/newtest/Gemini_배치채점_3모델.py`
- **결과 파일**: 
  - Gemini: `batch_output/gemini_results_20251105_174045.jsonl` (284개)
  - Claude: `batch_output/anthropic_batch_20251105_171246.jsonl` (221개)
  - GPT-5: `batch_output/openai_batch_20251105_171235.jsonl` (284개)

**재현 가능성**:
- **재현 스크립트**: `analysis/repro_stats.py`
- **산출 통계**: 
  - 모드별 평균 점수
  - 점수대별 Welch t-검정 및 효과크기(Cohen's d)
  - 13점 이상 고득점 비율
  - 서술형 점수 기준 구간별 분석

---



**[그림 6-1] 연구 설계 다이어그램 (A/B Test)**

_(그림 위치: 추후 제작 필요)_


**[그림 6-2] 데이터 수집 및 분석 흐름**

_(그림 위치: 추후 제작 필요)_
