## 6. 연구 방법

### 6.1 연구 설계

본 연구는 설계 및 개발 연구(Design and Development Research) 방법론과 준실험 연구 설계를 결합하여 수행한다. 먼저 질문 명료화 기반 AI agent 시스템을 설계 및 개발한 후, 이를 일반적인 LLM 프리패스 방식과 비교하여 학습 효과의 우수성을 검증한다.

연구 단계:
1. **요구 분석**: 프리패스 방식의 한계 분석 및 명료화 필요성 검증
2. **설계**: 프리패스 대비 우수성을 목표로 한 MAICE agent 시스템 아키텍처 설계
3. **개발**: 명료화 프로세스 기반 멀티 에이전트 시스템 개발
4. **비교 실험**: MAICE vs 프리패스 방식의 학습 효과 비교 실험
5. **효과성 검증**: 프리패스 대비 MAICE의 우수성 통계적 검증

### 6.2 연구 대상

#### 6.2.1 학생 질문 데이터
- **규모**: 1,012건의 수학 질문
- **수집 기간**: 2025년 10~11월
- **출처**: 고등학교 수학 학습 과정에서 llm을 통한 학습 중 수집된 대화 세션 내용

#### 6.2.2 교사 평가단
- **인원**: 현직 수학교사 3명
- **경력**: 평균 6년 이상
- **역할**: 학생 질문 및 AI 답변 품질 평가

#### 6.2.3 비교 실험 대상
- **대상**: 고등학교 2학년 학생 59명
  - **실험군(Agent 모드)**: 학생들이 Agent 모드로 무작위 배정
  - **대조군(Freepass 모드)**: 학생들이 Freepass 모드로 무작위 배정
- **단원**: 수학Ⅰ - 수열 (수학적 귀납법)
- **기간**: 2025년 10월 29일 ~ 11월 1일 (약 2주간)
- **학생 사전 성적 데이터 수집**:
  - 서술형 점수 (30점 만점): 평균 14.8점, 범위 0~30점
  - 객관식 점수 (70점 만점): 평균 39.3점, 범위 14.6~61.7점
  - 총점 (100점 만점): 평균 54.1점, 범위 17.9~89.9점

#### 6.2.4 실험 설계 및 진행 절차

**1단계: 수학적 귀납법 개념 학습**
- 학생들에게 수학적 귀납법의 기본 개념 소개
- 기저 단계와 귀납 단계의 원리 학습

**2단계: 문제 세트 단계적 부여 및 교사 협력 학습**
본 연구는 다음과 같은 구조화된 학습 과정을 설계하였다:

```
[문제 세트 1 부여] → [학생 개별 풀이 + AI 활용] → [교사와 함께 풀이]
         ↓
[문제 세트 2 부여] → [학생 개별 풀이 + AI 활용] → [교사와 함께 풀이]
         ↓
[문제 세트 3 부여] → [학생 개별 풀이 + AI 활용] → [교사와 함께 풀이]
         ↓
    (총 5세트 예정, 현재 3세트 완료)
```

- **문제 유형**: 등식 명제 증명, 부등식 명제 증명
- **각 세트 구성**: 2~3개의 수학적 귀납법 증명 문제
- **학습 과정**:
  1. 학생이 문제를 풀이하는 과정에서 AI(Agent 또는 Freepass)를 자유롭게 활용
  2. 풀이 완료 후 교사와 함께 증명 과정 검토 및 피드백
  3. 다음 세트로 진행

**3단계: 모드별 AI 활용 패턴 관찰**
- **Agent 모드**: 명료화 질문을 통한 질문 구체화 과정 경험
- **Freepass 모드**: 즉시 답변 제공 방식으로 학습

**4단계: 데이터 수집 및 평가**
- 모든 세션 대화 내용 자동 수집
- Gemini 2.5 Flash를 활용한 자동 루브릭 채점
- 세션별 질문 점수, 답변 점수, 학습 지원 점수 평가

> 주: 자동 채점은 세션 단위의 최종 질문 품질 중심 루브릭을 사용하며, 출력은 `question_score`, `answer_score`, `context_score`, `total_15`와 함께 `checklist` 및 `process_metrics`를 포함하는 JSON 스키마를 따른다. 세부 정의와 제약은 `docs/부록_A_루브릭_상세설명서.md` 참조.

### 6.3 연구 도구

#### 6.3.1 질문 품질 평가 도구
- **구성**: 3개 영역 9개 세부 항목 (v4.0 루브릭)
  - 질문 영역(A): A1 수학적 전문성, A2 질문 구조, A3 학습 맥락
  - 답변 영역(B): B1 학습자 맞춤, B2 설명 체계성, B3 학습 확장성
  - 맥락 영역(C): C1 명료화 효과성, C2 대화 일관성, C3 학습 지원
- **척도**: 5점 리커트 척도 (각 항목 0-5점)
- **총점**: 45점 만점 (15점 환산 기준으로도 분석)
- **평가자**: AI agent 자동 평가 + 교사 평가

##### 루브릭 타당도 및 신뢰도 검증

개발된 루브릭(v4.0)의 타당도를 검증하기 위해 179개 세션 데이터를 대상으로 탐색적 요인분석(EFA)을 수행하였다.

**요인분석 적합도**: 
- Kaiser-Meyer-Olkin(KMO) 측도는 0.774로 요인분석에 적합한 수준이었다.
- Bartlett 구형성 검정 결과 χ²(36) = 1171.86, p < .001로 변인 간 상관이 유의하였다.

**요인구조**: 
Varimax 회전을 적용한 결과, Kaiser 기준(고유값 > 1.0)으로는 2개 요인이 추출되었으나, 이론적 구조(질문/답변/맥락)에 따라 3요인 모델을 채택하였다. 3요인은 전체 분산의 69.9%를 설명하였다.

**신뢰도**: 
전체 루브릭의 Cronbach's α는 0.879로 매우 우수한 내적 일관성을 보였다. 영역별로는 질문 영역 α = 0.827, 답변 영역 α = 0.779, 맥락 영역 α = 0.733으로 모두 수용 가능한 수준(α ≥ 0.70)이었다.

**항목 품질**: 
일부 항목(A1, A2, B2, C2)에서 천장효과(만점 비율 65-85%)가 관찰되어 변별력이 제한적이었다. 이는 연구 참여자들의 MAICE 사용 능력이 전반적으로 높았거나, 해당 항목의 채점 기준이 다소 관대했을 가능성을 시사한다.

(상세한 요인 적재량, 공통성, 문항 난이도 분석은 부록 G 참조)

#### 6.3.2 프리패스 vs MAICE 비교 평가 도구
- **사전-사후 학습 성과 평가**: 수학적 귀납법 이해도 평가 (100점 만점)
- **학습 경험 평가**: 
  - 학습 만족도 설문 (5점 척도, 7개 문항)
  - 메타인지 능력 평가 (5점 척도, 5개 문항) 
  - 질문 품질 개선도 측정 (12개 세부 항목)
- **학습 과정 데이터**:
  - 문제해결 시간 비교 (프리패스 vs MAICE)
  - 질문 횟수 및 세션 길이 분석
  - 명료화 과정 참여도 측정

#### 6.3.3 시스템 로그 데이터
- **MAICE 그룹**:
  - 명료화 대화 횟수 및 질문 개선 정도
  - 에이전트별 응답 시간 및 처리 과정
  - 학습자 질문 진화 추이
- **프리패스 그룹**:
  - 즉시 답변 횟수 및 대화 길이
  - 후속 질문 발생 패턴

### 6.4 자료 수집 및 분석

#### 6.4.1 정량적 분석
- **MAICE vs 프리패스 학습 효과 비교**: 독립표본 t-검정으로 두 그룹 간 학습 성과 차이 검증
- **사전-사후 성취도 분석**: 대응표본 t-검정으로 각 그룹 내 학습 개선도 측정
- **학습 경험 및 만족도 분석**: 만족도, 메타인지, 질문 품질 영역별 그룹 간 차이 분석
- **효과 크기 계산**: 
  - Cohen's d를 주 효과 크기 지표로 사용
  - Hedge's g (소표본 보정)와 Cliff's delta (비모수 효과 크기)를 보조적으로 산출
  - 평균 차이의 95% 신뢰구간은 Bootstrap 방법(재표본추출 1,000회)으로 추정
  - 효과 크기 해석은 Cohen(1988)의 기준을 따름: d = 0.2 (작은 효과), 0.5 (중간 효과), 0.8 (큰 효과)
  - 교육학 연구에서는 d = 0.2~0.3 정도의 작은 효과 크기도 실용적으로 의미 있는 것으로 간주됨(Hattie, 2009)
- **상관관계 분석**: 명료화 참여도와 학습 성과 간 관련성 분석

#### 6.4.2 질적 분석
- **학습 과정 비교 분석**: MAICE 그룹의 명료화 과정과 프리패스 그룹의 즉시 답변 패턴 비교
- **학생 피드백 분석**: 두 그룹별 학습 경험 및 어려움에 대한 귀납적 코딩
- **교사 관찰 분석**: 두 방식의 교육적 효과성에 대한 교사 평가 분석

#### 6.4.3 데이터 수집 및 필터링 상세

**데이터 수집**:
- **수집 기간**: 2025년 10월 20일 ~ 11월 1일
- **수집 방법**: PostgreSQL 데이터베이스에서 학생 세션 자동 수집
- **수집 대상**: 고등학교 2학년 수학적 귀납법 학습 중 AI 활용 전체 대화 세션
- **원본 데이터**: 
  - 세션 데이터: `학생세션_수집_20251101_114113.json` (총 232개 세션)
  - AI 채점 데이터: `Gemini_루브릭채점_after_20251020_20251101_135623.json` (총 177개 채점)

**데이터 필터링 (대화 유효성 검증)**:

본 연구는 학습 상호작용의 질을 정확히 측정하기 위해 다음 기준으로 유효 세션을 선별하였다:

1. **메시지 개수 ≥ 2**: 최소한의 상호작용이 존재하는 세션만 포함
2. **역할 공존**: `user` AND (`maice` OR `assistant`) 메시지가 모두 존재
   - 학생 질문과 AI 응답이 모두 있는 완전한 대화만 분석
3. **내용 유효성**: 모든 메시지 `content`가 공백이 아님
   - 기술적 오류나 빈 메시지가 없는 세션만 포함
4. **세션 완결성**: 마지막 발화자가 `user`가 아님
   - AI가 최종 응답을 제공한 완결된 세션만 분석

**필터링 결과**:
- **유효 세션**: 177개 (Agent 73개, Freepass 104개)
- **분석 대상 학생**: 59명 (중간고사 점수 데이터 보유 학생)
  - Agent 모드: 30명
  - Freepass 모드: 29명
- **매칭 성공**: 53명 (AI 채점 + 중간고사 점수 모두 보유)
- **다회 세션 학생**: 39명 (2회 이상 세션 이용자, 학습 증가폭 분석 대상)

**AI 자동 채점**:
- **채점 모델**: Google Gemini 2.5 Flash
- **채점 방식**: 병렬 채점 (최대 50개 동시 처리)
- **채점 기준**: 개선된 루브릭 (질문 5점 + 답변 5점 + 맥락 5점 = 총 15점)
- **채점 스크립트**: `analysis/Gemini_병렬_채점.py`
- **샘플링 옵션**: 
  - 전체 데이터 채점: `--per-mode None`
  - 모드별 균등 샘플링: `--per-mode N` (각 모드에서 N개씩 추출)
  - 날짜 필터링: `--min-date YYYY-MM-DD` (특정 날짜 이후 세션만 분석)

**재현 가능성**:
- **재현 스크립트**: `analysis/repro_stats.py`
- **산출 통계**: 
  - 모드별 평균 점수
  - 점수대별 Welch t-검정 및 효과크기(Cohen's d)
  - 13점 이상 고득점 비율
  - 서술형 점수 기준 구간별 분석

---

