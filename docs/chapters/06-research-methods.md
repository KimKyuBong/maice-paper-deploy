## 6. 연구 방법

### 6.1 연구 설계

본 연구는 설계 및 개발 연구(Design and Development Research) 방법론과 준실험 연구 설계를 결합하여 수행한다. 먼저 질문 명료화 기반 AI agent 시스템을 설계 및 개발한 후, 이를 일반적인 LLM 프리패스 방식과 비교하여 학습 효과의 우수성을 검증한다.

연구 단계:
1. **요구 분석**: 프리패스 방식의 한계 분석 및 명료화 필요성 검증
2. **설계**: 프리패스 대비 우수성을 목표로 한 MAICE agent 시스템 아키텍처 설계
3. **개발**: 명료화 프로세스 기반 멀티 에이전트 시스템 개발
4. **비교 실험**: MAICE vs 프리패스 방식의 학습 효과 비교 실험
5. **효과성 검증**: 프리패스 대비 MAICE의 우수성 통계적 검증

### 6.2 연구 대상

#### 6.2.1 표본 선정

본 연구는 부산광역시 소재 ○○고등학교 2학년 4개 학급을 대상으로 하였다. 표집 방법은 연구자의 접근 가능성을 고려한 편의 표집(convenience sampling)이었으며, 학교와 학급 선정 기준은 다음과 같다:

#### 6.2.2 참여자 특성

[표 6-1] 연구 대상 개요

| 구분 | 내용 |
|------|------|
| **총 인원** | 58명 |
| **학년** | 고등학교 2학년 |
| **학교 유형** | 특수목적고등학교(공업계열) |
| **지역** | 부산광역시 |
| **연구 기간** | 2025년 10월 21일 ~ 11월 7일 (3주) |

**실험군과 대조군 구성**:
- **Agent 모드**: 28명
- **Freepass 모드**: 30명

**학생 사전 성적 분포** (중간고사 기준):
- 서술형 점수 (30점 만점): 평균 14.8점 (SD=8.5), 범위 0~30점
- 객관식 점수 (70점 만점): 평균 39.3점 (SD=11.1), 범위 14.6~61.7점
- 총점 (100점 만점): 평균 54.0점 (SD=17.5), 범위 17.9~89.9점

#### 6.2.3 예비 조사 (Pilot Study)

본 연구 설계에 앞서 2024년 5월에 예비 조사를 실시하여 프리패스 방식 LLM의 교육적 문제점을 파악하였다:

- **목적**: MAICE 시스템 설계의 필요성 검증
- **데이터**: 고등학교 수학 수업에서 수집한 385건의 질문-답변 쌍
- **평가단**: 현직 중등 수학교사 4명 (평균 경력 7년)
- **평가 방법**: 교육학 이론 기반 평가 기준 (6개 영역, 5점 척도)
- **총 평가 건수**: 1,012건 (교사 3-4명이 각 질문 평가)

예비 조사 결과, 학생 질문의 72.3%가 학습맥락 최저점을 받았고, 질문 품질과 답변 품질 간 강한 상관관계(r=0.691)가 발견되어, 질문 명료화 기반 AI 에이전트 시스템의 필요성이 실증적으로 확인되었다. 이 결과는 MAICE 시스템 설계의 핵심 근거가 되었다.

(상세 분석 결과는 `analysis/proto/평가결과_핵심요약.md` 참조)

#### 6.2.4 무작위 배정

학급 내 학생들을 실험군과 대조군에 무작위 배정하기 위해 MAICE 백엔드 시스템의 UserModeService를 활용하였다. 이 서비스는 학생이 시스템에 가입할 때 Python의 `random` 모듈을 사용하여 "agent" 또는 "freepass" 모드를 50:50 비율로 자동 배정한다. 배정된 모드는 `users` 테이블의 `assigned_mode` 필드에 저장되며, 연구 기간 동안 고정된다.

무작위 배정 결과, Agent 모드 28명, Freepass 모드 30명이 배정되었다. 두 집단 간 사전 중간고사 성적에서 통계적으로 유의한 차이가 없어 동질성이 확보되었다.

[표 6-2] 실험군과 대조군의 사전 동질성 검증 (중간고사 기준)

| 변인 | Agent 모드 (n=28) | Freepass 모드 (n=30) | t | p | 해석 |
|------|------------------|---------------------|---|---|------|
| | M(SD) | M(SD) | | | |
| 중간고사 총점 (100점) | 56.8(16.7) | 51.4(18.1) | 1.18 | .242 | 동질 |
| - 서술형 점수 (30점) | 15.6(8.5) | 14.0(8.5) | 0.74 | .462 | 동질 |
| - 객관식 점수 (70점) | 41.2(9.4) | 37.4(12.4) | 1.30 | .199 | 동질 |

**해석**: 모든 변인에서 p > .05로 두 집단 간 유의한 차이가 없어, 사전 동질성이 확보되었다. 이는 실험 처치 효과의 내적 타당도를 보장하는 중요한 근거가 된다.

#### 6.2.5 연구 윤리

**1. 연구 참여 동의**
- 모든 참여 학생과 보호자에게 연구 목적, 절차, 데이터 활용 방법을 설명하였다
- 학생 및 보호자로부터 서면 동의를 받았다
- 참여 거부 및 중도 철회 권리를 명시하였다

**2. 개인정보 보호**
- 수집된 데이터는 연구 목적으로만 사용되었다
- 데이터는 암호화된 서버에 저장하고, 연구자만 접근 가능하도록 제한하였다

**3. 참여자 보호**
- 연구 참여로 인한 학업 불이익이 없음을 보장하였다
- 두 모드(Agent/Freepass) 모두 교육적 가치를 제공하도록 설계하였다
- 연구 종료 후 모든 참여자에게 두 모드의 사용 기회를 제공하였다

**4. 데이터 보관 및 폐기**
- 연구 데이터는 연구 종료 후 3년간 보관하며, 이후 안전하게 폐기한다
- 논문 출판 시 개인을 특정할 수 있는 정보는 일체 포함하지 않는다

#### 6.2.6 실험 설계 및 진행 절차

**1단계: 수학적 귀납법 개념 학습**
- 학생들에게 수학적 귀납법의 기본 개념 소개
- 기저 단계와 귀납 단계의 원리 학습

**2단계: 수리논술 과제 단계적 부여 및 MAICE 활용 학습**

본 연구는 2025학년도 2학기 수학 수리논술 수행평가의 일환으로 총 5개의 수학적 귀납법 증명 과제를 단계적으로 부여하였다. 학생들은 각 과제를 해결하는 과정에서 **수업 시간**(40분) 및 **쉬는 시간**(10-15분)을 활용하여 MAICE 시스템에 자유롭게 접근하였다.

**과제 구성 및 진행 방식**:

[표 6-3] 수리논술 과제 세부 내용

| 과제 | 문제 1 | 문제 2 | 주요 개념 |
|:----:|--------|--------|----------|
| **과제 1** | 등비급수 합 공식<br/>$1+2+4+\cdots+2^{n-1} = 2^n-1$ | 팩토리얼 부등식<br/>$n! > 2^n$ (n≥4) | 기본 급수, 팩토리얼 |
| **과제 2** | 피보나치 수열 합<br/>$F_{n+2}=F_n+F_{n+1}$, $F_1=F_2=1$<br/>→ $\sum_{i=1}^{n} F_i = F_{n+2}-1$ | 지수 부등식<br/>$n^2 < 2^n$ (n≥5) | 점화식, 부등식 |
| **과제 3** | 팩토리얼 곱셈 공식<br/>$1×1!+2×2!+\cdots+n×n! = (n+1)!-1$ | 로그 부등식<br/>$\log_2 n < n$ | 곱셈 전개, 로그 |
| **과제 4** | 제곱수 합 공식<br/>$1^2+2^2+\cdots+n^2 = \frac{n(n+1)(2n+1)}{6}$ | 제곱 부등식<br/>$n < n^2$ (n≥2) | 제곱수 급수, 부등식 |
| **과제 5** | 하노이탑 점화식<br/>$a_{n+1}=2a_n+1$, $a_1=1$<br/>→ $a_n=2^n-1$ 증명 | 거듭제곱 부등식<br/>$n! < n^n$ (n≥2) | 점화식, 거듭제곱 |

**학습 과정 구조**:

```
[과제 부여] → [학생 개별 풀이 시도]
                    ↓
              [막히는 부분 발생]
                    ↓
         [MAICE 시스템 활용]
    - Agent 모드: 명료화 질문 → 문제 구체화 → 맞춤 답변
    - Freepass 모드: 즉시 답변 제공
                    ↓
         [풀이 과정 개선 및 완성]
                    ↓
         [교사와 함께 풀이 검토]
                    ↓
              [다음 과제 진행]
```

**MAICE 활용 방식**:

1. **수업 시간 활용** (주 활용 시간):
   - 교사가 과제를 제시한 후 개별 풀이 시간 제공 (수업 40분 중 20-30분)
   - 학생이 풀이 중 막히는 부분 발생 시 즉시 MAICE 접속
   - 개인 노트북/태블릿으로 AI와 대화하며 문제 해결 과정 탐색
   - 예시 질문: "귀납 가정을 어디에 사용하나요?", "이 식을 어떻게 전개하죠?", "제 풀이 맞나요?"

2. **쉬는 시간 활용** (보조 활용):
   - 수업 시간에 완전히 해결하지 못한 부분을 쉬는 시간에 추가 질문
   - 자신의 풀이를 검토하고 싶을 때 MAICE에 풀이 과정 입력 후 피드백 요청
   - 평균 2-3회의 짧은 대화 세션 (세션당 5-10분)

3. **과제 해결 패턴**:
   - **Agent 모드 학생**: 명료화 질문을 통해 문제를 단계별로 구체화하며 해결
   - **Freepass 모드 학생**: 즉시 제공되는 답변을 참고하여 풀이 작성

**교사 협력 학습**:
- 각 과제 제출 후 교사가 학급 전체와 함께 표준 풀이 과정 검토
- 학생들이 MAICE를 통해 얻은 인사이트를 수업 중 공유
- 일반적인 오류 및 개선 방향 논의

**데이터 수집**:
- 모든 학생-AI 대화 내용 자동 저장 (총 284개 세션)
- 세션별 질문 품질, 답변 품질, 학습 지원 수준 자동 평가
- 학생별 과제 완성도 및 제출 시간 기록

**실험 일정 및 기간**:

[표 6-4] 수리논술 과제 실시 일정

| 회차 | 과제 | 활동 내용 | 수업 시간 |
|:----:|:----:|----------|----------|
| **1회차** | - | 수학적 귀납법 개념 학습<br/>MAICE 시스템 사용법 안내 | 1교시 (40분) |
| **2회차** | 과제 1 | 등비급수, 팩토리얼 부등식<br/>+ 풀이 검토 및 피드백 | 1교시 (40분) |
| **3회차** | 과제 2 | 피보나치 수열, 지수 부등식<br/>+ 풀이 검토 및 피드백 | 1교시 (40분) |
| **4회차** | 과제 3 | 팩토리얼 곱셈, 로그 부등식<br/>+ 풀이 검토 및 피드백 | 1교시 (40분) |
| **5회차** | 과제 4 | 제곱수 합, 제곱 부등식<br/>+ 풀이 검토 및 피드백 | 1교시 (40분) |
| **6회차** | 과제 5 | 하노이탑, 거듭제곱 부등식<br/>+ 풀이 검토 및 피드백 | 1교시 (40분) |
| **7회차** | - | 전체 과제 종합 리뷰 및 심화 문제 풀이 | 1교시 (40분) |
| **8회차** | - | 사후 설문 및 연구 종료 | 1교시 (40분) |

**총 실험 기간**: 약 3주 (총 8회차 수업)
- **개념 학습**: 1회차
- **과제 활동 및 풀이 검토**: 2~6회차 (각 과제 수행 + 수업 말미 검토)
- **종합 리뷰**: 7회차
- **사후 설문**: 8회차
- **MAICE 활용 가능 시간**: 수업 중 20-30분 + 쉬는 시간 10-15분
- **총 세션 수**: 284개 (Agent 모드 122개, Freepass 모드 162개)
- **유효 세션** (메시지 ≥2): 280개 (Agent 118개, Freepass 162개)
- **평균 세션 길이**: 약 15분 (최소 3분 ~ 최대 45분)

**3단계: 모드별 AI 활용 패턴 관찰**
- **Agent 모드**: 명료화 질문을 통한 질문 구체화 과정 경험
- **Freepass 모드**: 즉시 답변 제공 방식으로 학습

**4단계: 데이터 수집 및 평가**

본 연구는 수집된 세션 데이터를 다각도로 분석하여 신뢰성과 타당성을 확보하고자 하였다.

#### (1) 다중 AI 모델 채점 시스템

평가자 편향(rater bias)을 최소화하고 채점 신뢰성을 높이기 위해 3개의 독립적인 대규모 언어 모델을 평가자로 활용하여 교차 검증을 실시하였다:

[표 6-5] AI 모델 채점자 구성

| 모델 | 개발사 | 버전 | 선정 이유 |
|------|--------|------|----------|
| **Gemini 2.5 Flash** | Google | gemini-2.5-flash | 긴 맥락 처리 능력, Batch API 지원, 한국어 성능 우수 |
| **Claude 4.5 Haiku** | Anthropic | claude-haiku-4-5 | 빠른 처리 속도, 일관성 있는 평가, Message Batches 지원 |
| **GPT-5 mini** | OpenAI | gpt-5-mini | 범용적 평가 능력, 비용 효율성, Batch API 지원 |

**채점 절차**:
1. 모든 세션 데이터를 JSON 형식으로 수집
2. 각 모델에 동일한 QAC 체크리스트와 평가 프롬프트 제공
3. 모델별로 독립적으로 채점 수행 (블라인드 평가)
4. 3개 모델 점수의 평균(Ensemble)과 개별 모델 점수 모두 분석

**QAC 체크리스트 구성** (40점 만점)
- **A영역: 질문 평가** (16점)
  - A1. 수학적 전문성 (6점)
  - A2. 질문 구조화 (6점)
  - A3. 학습 맥락 (4점)
- **B영역: 답변 평가** (16점)
  - B1. 학습자 적합성 (6점)
  - B2. 설명 체계성 (6점)
  - B3. 학습 확장성 (4점)
- **C영역: 학습 지원** (8점)
  - C2. 대화 일관성 (4점)
  - C3. 학습 지원 (4점)
- **체크리스트**: 32개 세부 요소 (각 영역별 4개 항목)

각 모델은 JSON 형식으로 점수와 함께 체크리스트 달성 여부를 출력하도록 설계되었다.

**모델 간 신뢰도 검증 방법**:
- Pearson 상관계수: 모델 쌍별 점수 일치도
- 급내상관계수(ICC): 전체 평가자 간 신뢰도
- Cronbach's Alpha: 내적 일관성
- Bland-Altman plot: 모델 간 점수 차이 분포

#### (2) 교사 평가를 통한 타당도 검증

AI 채점의 타당성을 검증하기 위해 현직 교사 4명이 무작위로 선정된 세션을 독립적으로 평가하였다:

- **평가 교사**: 중등 수학교사 2명, 정보교사 1명, 국어교사 1명 (평균 경력 13년)
- **평가 세션**: 
  - **현재 완료**: 25개 세션 (잠정 분석)
  - **계획**: 전체 100개 세션으로 확장 예정 (진행 중)
- **평가 방법**: 
  - AI 모델과 동일한 QAC 체크리스트 (40점 만점) 사용
  - 학생 모드 정보 블라인드 처리
  - 각 교사가 독립적으로 세션 채점
  - 교사 평가 완료 후 AI 채점 결과와 비교
- **타당도 검증 방법**:
  - 교사 평가 평균 vs AI 채점 평균 상관분석 (Pearson r)
  - 영역별(A, B, C) 상관계수 계산
  - 세부 항목별(A1~C3) 일치도 분석
  - 교사 간 신뢰도 분석 (급내상관계수, Cronbach's Alpha)

**⚠️ 중요**: 현재 25개 세션의 잠정 결과를 바탕으로 분석하였으며, 100개 세션 완료 시 재분석 예정

#### (3) 다층적 분석 전략

수집된 데이터를 다음과 같은 다층적 기준으로 분석하여 종합적인 효과를 검증하고자 하였다:

**① 항목별 분석**:
- 8개 평가 영역별 점수 비교 (A1~A3, B1~B3, C2~C3)
- 32개 체크리스트 요소별 달성률 분석
- 질문 품질, 답변 품질, 학습 맥락 점수 독립 분석

**② 사전 성취도 수준별 분석**:
- **Quartile 분석**: 중간고사 점수 기준 4분위
  - Q1 (하위 25%), Q2, Q3, Q4 (상위 25%)
- **Tertile 분석**: 3분위로 구분
  - T1 (하위 33%), T2, T3 (상위 33%)
- **연속 구간 분석**: 10점 단위 구간별 비교
- 각 구간에서 Agent vs Freepass 효과 크기 계산

**③ 종단적 학습 효과 분석**:
- 복수 세션 참여 학생 대상 누적 변화 추적
- 각 학생의 첫 세션 점수 vs 마지막 세션 점수 비교
- 세션 순서에 따른 점수 변화 추이 분석
- 점수 변동성(표준편차) 변화 분석

**④ 질적 데이터 수집 및 분석**:

**사후 설문 조사**:

실험 종료 후 학생들의 주관적 경험을 파악하기 위해 사후 설문조사를 실시하였다:

- **응답 학생**: 17명 (응답률 29.3%, Agent 9명, Freepass 8명)
- **블라인드 설계**: 학생들은 자신이 Agent인지 Freepass인지 모르는 상태에서 응답
- **서술형 문항** (5개):
  1. MAICE 대화 경험을 자유롭게 서술
  2. 사용 전후 변화
  3. 답변 방식 선호도 (A: 즉시 답변 vs B: 질문 유도)
  4. 가장 기억에 남는 순간
  5. 개선 제안

**주제 분석 절차** (Braun & Clarke, 2006):

1. **데이터 숙지**: 전체 응답 반복 읽기로 전체적 맥락 파악
2. **초기 코딩**: 의미 있는 응답 단위를 귀납적으로 코드화
3. **테마 탐색**: 유사한 코드를 그룹화하여 후보 테마 도출
4. **테마 검토**: 원본 데이터와 대조하여 타당성 점검
5. **테마 정의**: 각 테마의 명확한 정의와 명칭 확립
6. **보고서 작성**: 학생 응답 원문 인용과 함께 학술적 보고

**블라인드 실험의 장점**:

- **응답 편향 최소화**: 자신의 모드를 지지하려는 경향 제거
- **객관적 평가**: 실제 경험에 기반한 순수한 평가
- **교육적 가치 검증**: 설문에서 A/B 방식을 설명하고 선호도를 조사하여, 경험과 무관하게 교육적 가치를 평가 가능

**삼각검증 전략** (Triangulation):

양적 분석(QAC 점수)과 질적 분석(서술형 응답)을 통합하여 연구 결과의 신뢰성과 타당성을 확보하였다. 이는 Mixed Methods 연구의 핵심 전략으로, 서로 다른 방법론의 강점을 결합하여 더 풍부하고 깊이 있는 이해를 제공한다.

**⑤ 통계 분석 방법**:
- **독립표본 t-검정**: Agent vs Freepass 집단 간 비교
- **대응표본 t-검정**: 같은 학생의 세션 간 변화
- **Cohen's d**: 효과 크기 계산 (small: 0.2, medium: 0.5, large: 0.8)
- **Pearson 상관분석**: 변인 간 관계 분석
- **신뢰도 분석**: ICC, Cronbach's Alpha
- **유의수준**: α = .05 (양측검정)

> 주: QAC 체크리스트 세부 정의와 채점 기준은 `docs/부록_A_루브릭_상세설명서.md` 참조. 실제 분석 결과는 7장에서 제시한다.

### 6.3 통제 변인

본 연구에서는 실험 처치(Agent 모드 vs Freepass 모드) 외에 학습 효과에 영향을 미칠 수 있는 변인들을 다음과 같이 통제하였다:

[표 6-6] 통제 변인 및 통제 방법

| 변인 범주 | 구체적 변인 | 통제 방법 |
|----------|-----------|----------|
| **학습 과제** | 과제 내용 | 동일한 수학적 귀납법 과제 5개 부여 |
| | 과제 난이도 | 동일한 순서와 난이도로 제시 |
| | 제출 기한 | 양 집단 동일한 제출 일정 |
| **교사 효과** | 수업 진행 | 동일 교사가 모든 학급 수업 진행 |
| | 수업 내용 | 수학적 귀납법 개념 학습 내용 동일 |
| | 풀이 검토 | 양 집단 동일한 방식으로 과제 검토 |
| **학습 자료** | 교과서 | 동일 교과서 사용 (수학Ⅰ) |
| | 과제 자료 | 동일한 수리논술 문제지 제공 |
| **기술 환경** | 접근 기기 | 개인 노트북 또는 태블릿 사용 |
| | 네트워크 | 학교 Wi-Fi 환경 |
| | MAICE 시스템 | 동일한 시스템 버전 및 UI |
| **사전 지식** | 선수 학습 | 수열 단원 선수 학습 완료 |
| | 기초 개념 | 1회차에 수학적 귀납법 개념 사전 교육 (양 집단 동일) |
| **평가 방법** | AI 채점 | 3개 AI 모델 + Ensemble 평균 (블라인드 채점) |
| | 채점 기준 | 동일 QAC 체크리스트 (40점 만점) |
| | 평가 시점 | 모든 세션 데이터 수집 후 일괄 채점 |

**통제되지 않은 변인 (연구 제한점)**:
- **MAICE 활용 시간**: 학생마다 수업 중/쉬는 시간 활용 정도 상이
- **세션 횟수**: 학생의 자발적 선택에 따라 사용 빈도 다름 (1~13회)
- **학습 습관**: 개인별 학습 전략 및 스타일 차이
- **가정 학습**: 학교 밖 추가 학습 시간 및 자료 사용
- **동료 효과**: 친구 간 정보 공유 및 상호작용
- 개인별 인지 능력 차이

이러한 통제되지 않은 변인들은 무작위 배정을 통해 두 집단에 균등하게 분산되도록 하였으며, 연구 결과 해석 시 한계점으로 고려되었다.

### 6.4 연구 도구

#### 6.4.1 질문 품질 평가 도구

**QAC 체크리스트 (Question-Answer-Context Checklist)**

- **구성**: 3개 영역 8개 세부 항목 (40점 만점)
  - 질문 영역(A): A1 수학적 전문성, A2 질문 구조, A3 학습 맥락
  - 답변 영역(B): B1 학습자 맞춤, B2 설명 체계성, B3 학습 확장성
  - 맥락 영역(C): C1 대화 일관성, C2 학습 지원
- **척도**: 5점 리커트 척도 (각 항목 0-5점)
- **총점**: 40점 만점 (질문 15점 + 답변 15점 + 맥락 10점)
- **평가자**: AI agent 자동 평가 + 교사 평가

##### QAC 체크리스트 개발 배경

**이론적 기반**:
QAC 체크리스트는 Dewey의 반성적 사고 이론과 질문 생성 이론에 기반하여 개발되었다. **8개 항목**(A1-A3, B1-B3, C2-C3)은 질문 품질(A), 답변 품질(B), 학습 맥락(C)의 3개 영역으로 구조화되었으며, 각 항목당 4개의 체크리스트 요소(총 32개)로 구성되었다.

**개발 과정**:
- 초기 v4.0: 45점, 9개 항목 (C1 명료화 효과성 포함)
- v4.3 (최종): 40점, 8개 항목 (C1 제외하여 Agent 편향 제거)
- 체크리스트 방식 도입: 각 요소를 0/1로 평가하고 근거(evidence) 제시

**타당도 및 신뢰도 확보 방법**:

**1) 내용 타당도 (Content Validity)**
- Dewey의 반성적 사고 이론, 질문 생성 이론 등 교육학 이론 기반
- 8개 항목이 교육적 효과의 핵심 요소를 포함

**2) 전문가 타당도 (Expert Validity)**
- 현직 수학교사 4명의 검토 및 피드백 반영
- 체크리스트 요소의 교육적 타당성 검증

**3) 준거 타당도 (Criterion Validity)**
- 교사 평가(100개 세션)와 AI 채점 간 상관분석 실시
- 상세 결과는 7장에서 제시

**4) 평가자 간 신뢰도 (Inter-rater Reliability)**
- 3개 독립 AI 모델(Gemini, Claude, GPT-5)로 교차 검증
- 151개 공통 세션 분석 결과:
  - ICC = 0.786 (매우 좋음)
  - Cronbach's α = 0.930 (매우 높음)
  - 평균 Pearson r = 0.849 (매우 강함)
- 모델에 독립적으로 일관된 평가 입증

(QAC 체크리스트 상세 설명 및 신뢰도 검증 결과는 부록 A 참조)

#### 6.4.2 학생 수준 분류 기준

**중간고사 성적 활용 (수열 단원 선수 학습 수준)**

본 연구는 학생들의 사전 학업 수준을 파악하고 수준별 효과를 분석하기 위해, 수학적 귀납법 단원 학습 **이전에** 실시된 중간고사 성적을 활용하였다. 이 중간고사는 수학적 귀납법의 선수 학습 내용인 **수열 단원**(등차수열, 등비수열, 여러 가지 수열의 합)에 대한 이해도를 평가한 시험이다.

**성적 구성**:
- **서술형 문항** (30점 만점): 수열의 합, 등차/등비수열 증명 과정 서술
- **객관식 문항** (70점 만점): 수열 개념 이해 및 적용
- **총점** (100점 만점): 서술형 + 객관식

**평가 내용** (수학적 귀납법의 선수 학습):
- 등차수열의 일반항 및 합 공식
- 등비수열의 일반항 및 합 공식
- 여러 가지 수열의 합 (∑ 기호 활용)
- 수열의 귀납적 정의 (점화식)

**활용 목적**:
1. **학생 수준 분류**: 삼분위수로 하위 33%, 중위 33%, 상위 33% 구분
2. **사전 동질성 검증**: Agent vs Freepass 집단 간 선수 학습 수준 비교
3. **조절 변수**: 학업 수준별 차별적 효과 분석
4. **선수 학습 지표**: 수학적 귀납법 학습을 위한 기초 개념 이해도 대표

**중요**: 본 연구는 중간고사 성적을 사전-사후 비교에 사용한 것이 아니라, **수학적 귀납법 학습 전 선수 학습 수준을 나타내는 독립적 기준**으로 활용하였다. 실제 학습 효과는 **QAC 체크리스트 점수의 세션별 변화**로 측정하였다.

#### 6.4.3 시스템 로그 데이터

세션별 대화 내용과 상호작용 패턴을 분석하기 위해 PostgreSQL 데이터베이스에서 자동 수집된 로그 데이터를 활용하였다.

**Agent 모드 로그**:
- 명료화 대화 횟수 및 질문 개선 정도
- 에이전트별 응답 시간 및 처리 과정
- 학습자 질문 진화 추이
- 세션 단계별 전환 패턴

**Freepass 모드 로그**:
- 즉시 답변 횟수 및 대화 길이
- 후속 질문 발생 패턴
- 메시지 유형별 분포

**수집 데이터**:
- 세션 메시지 수, 평균 메시지 길이
- 세션 지속 시간 (추정)
- 사용자-AI 상호작용 횟수

### 6.5 자료 수집 및 분석

#### 6.5.1 정량적 분석

**집단 간 비교 분석**:
- 독립표본 t-검정: Agent vs Freepass 모드 간 QAC 점수 차이 검증
- Welch's t-test: 등분산 가정 위배 시 사용
- Mann-Whitney U test: 비모수 검정

**세션 증가폭 분석**:
- 대응표본 t-검정: 각 학생의 1회차 vs 최종회차 QAC 점수 변화
- 천장효과 보정: proportional improvement = (후반 평균 - 전반 평균) / (15 - 전반 평균)

**효과 크기 계산**: 
- Cohen's d를 주 효과 크기 지표로 사용
- Hedge's g (소표본 보정)와 Cliff's delta (비모수 효과 크기)를 보조적으로 산출
- 평균 차이의 95% 신뢰구간은 Bootstrap 방법(재표본추출 1,000회)으로 추정
- 효과 크기 해석은 Cohen(1988)의 기준을 따름: d = 0.2 (작은 효과), 0.5 (중간 효과), 0.8 (큰 효과)
- Hattie (2009)는 교육 개입의 평균 효과크기가 d=0.4임을 제시하였으며, 이를 '힌지 포인트(hinge point)'로 명명하였다. 본 연구에서는 이를 참고하되, Cohen의 전통적 기준을 주요 해석 틀로 사용한다

**학업 수준별 차별적 효과 분석**:
- 중간고사 성적 기준 삼분위수(tertiles) 분류
- 각 수준별 Agent vs Freepass 효과 비교
- 상호작용 효과 검증

#### 6.5.2 질적 분석
- **대화 패턴 분석**: 명료화 유형, 학생 응답 패턴, 학습 진화 추이
- **세션 사례 분석**: 명료화 성공/실패 사례의 질적 코딩
- **로그 데이터 분석**: 메시지 유형, 세션 단계, 상호작용 길이

#### 6.4.3 데이터 수집 및 필터링 상세

**데이터 수집**:
- **수집 기간**: 2025년 10월 20일 ~ 11월 3일
- **수집 방법**: PostgreSQL 데이터베이스에서 학생 세션 자동 수집
- **수집 대상**: 고등학교 2학년 수학적 귀납법 학습 중 AI 활용 전체 대화 세션
- **원본 데이터**: 
  - 세션 데이터: `학생세션_수집_20251103_134440.json` (총 284개 세션, 58명 학생, 1407개 메시지)
  - AI 채점 데이터 (3개 모델 배치 채점):
    - Gemini 2.5 Flash: `gemini_results_20251105_174045.jsonl` (284개)
    - Claude 4.5 Haiku: `anthropic_batch_20251105_171246.jsonl` (284개)
    - GPT-5 mini: `openai_batch_20251105_171235.jsonl` (284개)

**데이터 필터링 (대화 유효성 검증)**:

본 연구는 학습 상호작용의 질을 정확히 측정하기 위해 다음 기준으로 유효 세션을 선별하였다:

1. **메시지 개수 ≥ 2**: 최소한의 상호작용이 존재하는 세션만 포함
2. **역할 공존**: `user` AND (`maice` OR `assistant`) 메시지가 모두 존재
   - 학생 질문과 AI 응답이 모두 있는 완전한 대화만 분석
3. **내용 유효성**: 모든 메시지 `content`가 공백이 아님
   - 기술적 오류나 빈 메시지가 없는 세션만 포함
4. **세션 완결성**: 마지막 발화자가 `user`가 아님
   - AI가 최종 응답을 제공한 완결된 세션만 분석

**필터링 결과**:
- **전체 세션**: 284개 (Agent 122개, Freepass 162개)
- **유효 세션** (메시지 ≥2): 280개 (Agent 118개, Freepass 162개)
- **분석 대상 학생**: 58명
  - Agent 모드: 28명
  - Freepass 모드: 30명
- **설문 응답자**: 17명 (Agent 9명, Freepass 8명, 응답률 29.3%)
- **다회 세션 학생**: 상당수 (2회 이상 세션 이용자, 학습 증가폭 분석 대상)

**AI 배치 채점 (Batch API)**:
- **채점 모델**: 3개 독립 AI 모델 (Gemini 2.5 Flash, Claude 4.5 Haiku, GPT-5 mini)
- **채점 방식**: Batch API를 통한 병렬 채점 (비용 효율적, 일관성 ⬆️)
- **채점 기준**: QAC 체크리스트 (A영역 16점 + B영역 16점 + C영역 8점 = 총 40점)
- **채점 대상**: 전체 284개 세션 (Agent 122개, Freepass 162개)
- **채점 스크립트**: `analysis/newtest/Gemini_배치채점_3모델.py`
- **결과 파일**: 
  - Gemini: `batch_output/gemini_results_20251105_174045.jsonl` (284개)
  - Claude: `batch_output/anthropic_batch_20251105_171246.jsonl` (284개)
  - GPT-5: `batch_output/openai_batch_20251105_171235.jsonl` (284개)

**재현 가능성**:
- **재현 스크립트**: `analysis/repro_stats.py`
- **산출 통계**: 
  - 모드별 평균 점수
  - 점수대별 Welch t-검정 및 효과크기(Cohen's d)
  - 13점 이상 고득점 비율
  - 서술형 점수 기준 구간별 분석

---

