# MAICE 시스템 A/B 테스트 실험 계획서

## 🎯 1. 실험 개요

### 1.1 연구 목적
MAICE 시스템의 **에이전트 모드**가 학생들의 수학 학습에 실제로 **교육적 효과**가 있는지 검증

### 1.2 핵심 연구 질문
> "명료화 과정과 질문 품질 피드백을 포함한 에이전트 모드가 단순히 빠른 답변을 제공하는 프리패스 모드보다 학습 성과, 메타인지 능력, 문제해결 능력을 더 효과적으로 향상시키는가?"

### 1.3 세부 연구 목표
1. **학습 성과**: 사전-사후 평가를 통한 지식 향상도 측정
2. **메타인지 능력**: 질문 구체화, 자기 인식, 학습 전략 수립 능력 변화
3. **문제해결 능력**: 새로운 유형 문제 접근, 개념 연결, 풀이 전략 다양화
4. **학습 효율성**: 시간 대비 학습 성과 비교
5. **학습 지속성**: 재사용 의향, 지식 유지율, 학습 태도 변화

---

## 🔬 2. 실험 설계

### 2.1 실험 유형
- **설계**: Between-subjects A/B Test (독립표본 설계)
- **통제**: 무작위 배정 (Randomized Controlled Trial)
- **측정**: 사전-사후 평가 설계 (Pre-Post Test Design)

### 2.2 그룹 구성

#### A그룹 (실험군): 에이전트 모드
- **특징**:
  - 명료화 과정 포함
  - 12개 항목 질문 품질 평가 및 피드백
  - 커리큘럼 기반 학습 가이드
  - 대화 세션 관리
  - 단계별 개념 설명

- **교육적 메커니즘**:
  - 질문 구체화를 통한 메타인지 훈련
  - 소크라테스식 대화를 통한 깊이 있는 이해
  - 선수 학습 확인을 통한 체계적 학습
  - 단계별 피드백을 통한 학습 강화

#### B그룹 (대조군): 프리패스 모드
- **특징**:
  - 빠른 답변 제공
  - 명료화 과정 없음
  - 일반적인 AI 챗봇 방식
  - 즉각적인 정보 제공

- **교육적 메커니즘**:
  - 빠른 정보 접근을 통한 효율성
  - 주도적 탐색 및 시도
  - 간결한 답변을 통한 시간 절약

### 2.3 참여자 구성
- **목표 인원**: 40명 (각 그룹 20명)
- **실제 모집**: 50-60명 (드롭아웃 고려 20% 여유)
- **모집 대상**: 중학교 1학년 ~ 고등학교 3학년
- **배정 방법**: 완전 무작위 배정
- **배정 균형 확인**: 사전 평가 점수, 학년, 수학 성적 수준 균형

### 2.4 실험 기간
- **총 기간**: 4주
  - Week 0: 준비 및 사전 평가 (1주)
  - Week 1-2: 실험 기간 (2주)
  - Week 3-4: 대기 및 지연 평가 (2주)

- **일일 권장 사용량**:
  - 하루 30분 이상
  - 주 3-5회 이상 접속
  - 최소 3-5개 질문

### 2.5 학습 단원
- **선정 기준**: 
  - 명확한 위계성이 있는 단원
  - 개념 이해가 중요한 단원
  - 2주 내 학습 가능한 범위

- **추천 단원**:
  - 중등: 일차방정식, 일차함수, 확률, 통계
  - 고등: 이차함수, 수열, 지수로그, 삼각함수

---

## 📊 3. 측정 지표 체계

### 3.1 정량적 지표

#### 학습 성과 (Learning Outcomes)
```yaml
주요_지표:
  사전_평가_점수:
    - 기본 개념 문제 (3-5개)
    - 응용 문제 (2-3개)
    - 심화 문제 (1-2개)
    - 총점: 100점
  
  사후_평가_점수:
    - 사전과 동형 문제
    - 전이 문제 (1-2개) 추가
    - 총점: 100점
  
  향상도_지표:
    - 절대 향상도: 사후 - 사전
    - 정규화 향상도: (사후-사전)/(100-사전)
    - 효과 크기: Cohen's d
```

#### 메타인지 능력 (Metacognitive Skills)
```yaml
측정_항목:
  자기_인식_능력:
    - 사전: Q10 (1-5점)
    - 사후: Q25 (1-5점)
    - 향상도: 사후 - 사전
  
  질문_구체화_능력:
    - 사후: Q26 (1-5점)
    - 시스템_로그: 질문 품질 점수 변화 추이
  
  학습_전략_수립:
    - 사전: Q11 (1-5점)
    - 사후: Q28 (1-5점)
  
  자기_평가_능력:
    - 사전: Q12 (1-5점)
    - 사후: Q29 (1-5점)
  
  개념_연결_능력:
    - 사전: Q13 (1-5점)
    - 사후: Q31 (1-5점)
```

#### 문제해결 능력 (Problem-Solving Skills)
```yaml
측정_항목:
  새_유형_접근_자신감: Q30 (1-5점)
  개념_연결_능력: Q31 (1-5점)
  풀이_전략_다양성: Q32 (1-5점)
  단계별_접근_능력: Q33 (1-5점)
  
  종합_점수: 4개 항목 평균 (1-5점)
```

#### 학습 효율성 (Learning Efficiency)
```yaml
계산_방식:
  시간당_성과: (사후점수 - 사전점수) / 총_학습시간_분
  질문당_성과: (사후점수 - 사전점수) / 총_질문_수
  세션당_성과: (사후점수 - 사전점수) / 총_세션_수
  
  비교: A그룹 vs B그룹
```

#### 학습 지속성 (Learning Sustainability)
```yaml
측정_항목:
  재사용_의향: Q48 (1-5점)
  추천_의향: Q49 (1-5점)
  실제_지속_사용: Q50 (사용 빈도)
  지식_유지율: 지연평가점수 / 사후평가점수
  태도_변화: Q53 (1-5점)
```

### 3.2 질적 지표

#### 학습 경험 (Learning Experience)
```yaml
데이터_소스:
  - Q43: 가장 큰 배움
  - Q44: 학습 방식 변화
  - Q45: 기억에 남는 순간
  - Q46: 시스템의 장점
  - Q47: 시스템의 단점

분석_방법:
  - 주제 분석 (Thematic Analysis)
  - 코딩 및 범주화
  - 그룹 간 비교
```

#### 명료화 효과 (Clarification Effect) - A그룹만
```yaml
데이터_소스:
  - Q38: 명료화 과정의 구체적 도움
  - 시스템_로그: 명료화 대화 내용
  - 시스템_로그: 질문 품질 변화

분석_초점:
  - 질문이 어떻게 구체화되었는가
  - 명료화 과정에서 어떤 깨달음이 있었는가
  - 최종 답변보다 과정이 더 도움이 되었는가
```

#### 사용 맥락 (Usage Context)
```yaml
데이터_소스:
  - Q17: 주로 사용한 상황
  - Q42: 가장 유용했던 상황 (B그룹)
  - 시스템_로그: 사용 패턴

분석_초점:
  - 어떤 상황에서 시스템을 찾았는가
  - 어떤 학습 목적으로 사용했는가
```

---

## 🧪 4. 연구 가설

### 가설 1: 학습 성과 향상
```
H1-0 (귀무가설): μA = μB
  두 그룹의 정규화 향상도 평균이 같다.

H1-1 (대립가설): μA > μB
  에이전트 모드 그룹(A)의 정규화 향상도가 
  프리패스 모드 그룹(B)보다 크다.

검증_방법:
  - Independent t-test (정규분포 가정)
  - Mann-Whitney U test (비모수 대안)
  - 유의수준: α = 0.05
  - 효과 크기: Cohen's d ≥ 0.5 (중간 효과 기대)

성공_기준:
  - p < 0.05
  - Cohen's d ≥ 0.5
  - A그룹 평균 향상도 ≥ B그룹 + 10점
```

### 가설 2: 메타인지 능력 향상
```
H2-0: 두 그룹의 메타인지 점수 향상도가 같다.
H2-1: A그룹의 메타인지 점수 향상도가 B그룹보다 크다.

측정_지표:
  - 5개 메타인지 항목 평균 (Q10→Q25, Q26, Q27, Q28, Q29)
  - 질문 품질 점수 변화 (시스템 로그)

검증_방법:
  - Repeated Measures ANOVA (사전-사후 비교)
  - ANCOVA (사전점수 공변량)
  
성공_기준:
  - A그룹 메타인지 향상도 ≥ +1.0점
  - p < 0.05
  - A그룹 > B그룹 (통계적 유의)
```

### 가설 3: 문제해결 능력 향상
```
H3-0: 두 그룹의 문제해결 능력이 같다.
H3-1: A그룹의 문제해결 능력이 B그룹보다 크다.

측정_지표:
  - 4개 문제해결 항목 평균 (Q30, Q31, Q32, Q33)
  - 전이 문제 정답률

검증_방법:
  - Independent t-test
  - Chi-square test (전이 문제 정답 여부)

성공_기준:
  - A그룹 문제해결 점수 ≥ 4.0
  - A그룹 > B그룹 (p < 0.05)
  - 전이 문제 정답률: A그룹 > B그룹
```

### 가설 4: 학습 효율성
```
H4-0: 두 그룹의 시간당 학습 성과가 같다.
H4-1: A그룹의 시간당 학습 성과가 B그룹보다 크다.

측정_지표:
  - 시간당 성과 = (사후-사전) / 총_학습시간
  - 질문당 성과 = (사후-사전) / 총_질문수

검증_방법:
  - ANCOVA (사전점수, 학습시간 공변량)
  
성공_기준:
  - 시간당 성과: A그룹 > B그룹
  - 효과 크기 η² ≥ 0.06 (중간 효과)
```

### 가설 5: 학습 지속성
```
H5-0: 두 그룹의 학습 지속성이 같다.
H5-1: A그룹의 학습 지속성이 B그룹보다 크다.

측정_지표:
  - 재사용 의향 (Q48)
  - 추천 의향 (Q49)
  - 지연 평가 점수 (4주 후)
  - 지식 유지율

검증_방법:
  - Independent t-test (의향 점수)
  - 지식 유지율 = 지연평가 / 사후평가

성공_기준:
  - 재사용 의향: A그룹 평균 ≥ 4.0
  - 추천 의향: A그룹 평균 ≥ 4.0
  - 지식 유지율: A그룹 > B그룹
```

---

## 📅 5. 실험 진행 일정

### Week 0: 준비 단계 (Day -7 ~ Day 0)

```
Day -7 ~ -4: 참여자 모집
  - 모집 공고 게시
  - 설명회 개최
  - 참여 의향서 수집
  - 목표: 50-60명 모집

Day -3 ~ -2: 그룹 배정 및 오리엔테이션
  - 완전 무작위 배정
  - 배정 균형 확인
  - A그룹 오리엔테이션 (에이전트 모드 사용법)
  - B그룹 오리엔테이션 (프리패스 모드 사용법)
  - 실험 윤리 안내 및 동의서 수집

Day -1: 시스템 준비
  - 사전 설문 폼 활성화
  - 사전 평가 문제 등록
  - 시스템 접근 권한 설정
  - 모니터링 대시보드 준비

Day 0: 사전 평가
  - 오전: 사전 설문 작성 (30분)
  - 오후: 사전 평가 문제 풀이 (60분)
  - 저녁: 시스템 접근 권한 부여
  - 시작 안내 메시지 발송
```

### Week 1: 집중 사용 기간 (Day 1 ~ Day 7)

```
Day 1-2: 초기 적응
  - 시스템 탐색 및 적응
  - 기술 지원 집중 대기
  - 사용 현황 실시간 모니터링
  - 미접속자 독려 (Day 2 저녁)

Day 3-5: 활발한 사용
  - 일일 사용 현황 체크
  - 기술 문제 즉시 해결
  - 사용 패턴 분석
  - 우수 사용 사례 수집

Day 6: 사용 독려
  - 미달 사용자 개별 연락
  - 기술 지원 강화
  - 질문 독려 (최소 10개 이상)

Day 7: 중간 체크인
  - 오전: 중간 설문 작성 (20분)
  - 오후: 형성평가 (30분)
  - 저녁: Week 2 독려 메시지
  - 중간 데이터 백업
```

### Week 2: 자연스러운 사용 (Day 8 ~ Day 14)

```
Day 8-10: 지속적 사용
  - 자율적 사용 권장
  - 필요 시 기술 지원
  - 사용 패턴 관찰

Day 11-13: 실험 마무리
  - 사용 독려 메시지
  - 미완료자 독려
  - 사후 평가 안내

Day 14: 사후 평가
  - 오전: 사후 설문 작성 (40분)
  - 오후: 사후 평가 문제 풀이 (60분)
  - 저녁: 주관식 평가 (20분)
  - 감사 메시지 발송
  - 데이터 수집 완료
```

### Week 3-4: 대기 및 지연 평가 (Day 15 ~ Day 28)

```
Day 15-27: 자연스러운 지식 유지 기간
  - 시스템 사용은 자유
  - 별도 독려 없음
  - 자연스러운 망각 곡선 관찰

Day 28: 지연 평가
  - 오전: 지연 평가 설문 (15분)
  - 오후: 유지 평가 문제 (30분)
  - 최종 감사 메시지
  - 인센티브 지급 안내
```

---

## 📊 6. 데이터 수집 및 관리

### 6.1 자동 수집 데이터

```python
system_logs = {
    "사용_패턴": {
        "일일_접속_시간": [],
        "세션_길이": [],
        "질문_횟수": [],
        "답변_수": []
    },
    
    "질문_품질": {
        "12개_항목_점수": [],
        "총점_변화_추이": [],
        "명료화_필요_횟수": [],
        "명료화_성공률": []
    },
    
    "학습_진행": {
        "다룬_개념_리스트": [],
        "어려움_영역": [],
        "해결된_개념": [],
        "세션별_요약": []
    },
    
    "상호작용": {
        "메시지_교환_수": [],
        "평균_응답_시간": [],
        "피드백_반영_여부": [],
        "도구_사용_빈도": {
            "desmos": 0,
            "latex": 0,
            "step_by_step": 0
        }
    }
}
```

### 6.2 설문 데이터

```yaml
데이터_구조:
  사전_설문:
    - 기본_정보 (4개 문항)
    - 학습_단원_평가 (4개 문항)
    - 메타인지_기저선 (5개 문항)
    - 사전_평가_점수
  
  중간_체크인:
    - 사용_경험 (3개 문항)
    - 학습_진행 (3개 문항)
    - 형성평가_점수
  
  사후_설문:
    - 학습_성과 (4개 문항)
    - 메타인지_변화 (5개 문항)
    - 문제해결_능력 (4개 문항)
    - 시스템_효과성_A그룹 (5개 문항)
    - 시스템_효과성_B그룹 (4개 문항)
    - 사후_평가_점수
    - 주관식_평가 (7개 문항)
  
  지연_평가:
    - 학습_지속성 (5개 문항)
    - 유지_평가_점수
```

### 6.3 데이터 관리

```yaml
저장_위치:
  백엔드_DB:
    - ab_test_sessions
    - ab_test_interactions
    - ab_test_surveys
    - assessment_responses
    - metacognitive_surveys
  
  파일_백업:
    - /data/experiments/ab_test_2025/
    - 일일_백업: 자동
    - 주간_백업: 수동 검증

개인정보_보호:
  - 참여자_ID_암호화
  - 개인식별정보_분리_저장
  - 분석_시_익명화_데이터_사용
  - GDPR_준수
```

---

## 📈 7. 데이터 분석 계획

### 7.1 정량적 분석

#### 기술 통계 (Descriptive Statistics)
```r
# 각 그룹별 기본 통계
group_A_stats <- data %>%
  filter(group == "A") %>%
  summarise(
    n = n(),
    mean_gain = mean(gain_score),
    sd_gain = sd(gain_score),
    mean_time = mean(total_time_minutes),
    mean_questions = mean(total_questions)
  )

group_B_stats <- data %>%
  filter(group == "B") %>%
  summarise(...)
```

#### 추론 통계 (Inferential Statistics)
```r
# 가설 1: 학습 성과 비교
t_test_result <- t.test(
  gain_score ~ group,
  data = data,
  alternative = "greater",  # A > B
  var.equal = FALSE
)

# 효과 크기 계산
cohens_d <- (mean_A - mean_B) / pooled_sd

# 가설 2: 메타인지 능력
metacog_anova <- aov(
  metacog_score ~ group * time,
  data = long_data
)

# 가설 3: 학습 효율성
efficiency_ancova <- aov(
  gain_score ~ group + pre_score + total_time,
  data = data
)

# 가설 4: 학습 지속성
retention_test <- t.test(
  retention_rate ~ group,
  data = data
)
```

#### 상관 분석
```r
# 질문 품질과 학습 성과 상관
cor.test(
  data$avg_question_quality,
  data$gain_score
)

# 명료화 참여도와 메타인지 향상 상관 (A그룹만)
cor.test(
  data_A$clarification_engagement,
  data_A$metacog_gain
)
```

### 7.2 질적 분석

#### 주제 분석 (Thematic Analysis)
```yaml
절차:
  1단계_친숙화:
    - 모든 주관식 응답 반복적 읽기
    - 전체적인 패턴 파악
  
  2단계_초기_코딩:
    - 의미 있는 텍스트 단위에 코드 부여
    - 귀납적 코딩 방식
    - 코드북 작성
  
  3단계_주제_탐색:
    - 관련 코드들을 묶어 후보 주제 도출
    - 주제 맵 작성
  
  4단계_주제_검토:
    - 주제의 적절성 검증
    - 데이터로 돌아가 재확인
  
  5단계_주제_정의:
    - 각 주제의 핵심 정의
    - 주제 간 관계 설정
  
  6단계_보고서_작성:
    - 생생한 인용문 선택
    - 그룹 간 비교 분석
```

#### 명료화 효과 분석 (A그룹만)
```yaml
분석_대상:
  - Q38: 명료화 과정의 구체적 도움
  - 시스템_로그: 명료화 대화 내용
  
분석_초점:
  질문_변화:
    - Before: "이차함수 모르겠어요"
    - After: "이차함수의 꼭짓점 구할 때 왜 완전제곱식으로 변형하나요?"
  
  깨달음_순간:
    - 어떤 질문이 어떤 깨달음으로 이어졌는가
    - 명료화 과정에서 스스로 답을 찾은 사례
  
  메타인지_발달:
    - 자신의 이해도를 정확히 파악하게 된 과정
    - 질문 구체화 능력의 실제 증거
```

### 7.3 혼합 분석 (Mixed Methods)

```yaml
통합_분석:
  정량_데이터가_질적_데이터를_설명:
    예시:
      - "A그룹의 메타인지 점수가 +1.5점 향상"
      - 주관식 응답에서 "질문을 구체화하는 법을 배웠다"는 증언
      - 통합: 명료화 과정이 실제로 메타인지 향상에 기여
  
  질적_데이터가_정량_결과를_보완:
    예시:
      - "A그룹의 학습 효율성이 B그룹보다 낮음"
      - 주관식: "처음엔 시간이 오래 걸렸지만, 나중엔 더 빨랐다"
      - 통합: 초기 학습 곡선은 있지만, 장기적으론 효율적
```

---

## 🎯 8. 성공 기준 및 평가

### 8.1 최소 성공 기준 (Minimum Viable Success)

```yaml
필수_조건:
  참여율:
    - 사전-사후 평가 모두 완료: ≥ 30명
    - 완료율: ≥ 70%
  
  데이터_품질:
    - 설문 응답 완성도: ≥ 90%
    - 시스템 사용 최소 기준 달성: ≥ 60%
      (최소 10회 질문, 5회 이상 접속)
  
  핵심_가설_검증:
    - 가설 1 (학습 성과) 검증 성공
    - p < 0.05
    - Cohen's d ≥ 0.5
```

### 8.2 이상적 성공 기준 (Ideal Success)

```yaml
이상적_조건:
  모든_가설_검증:
    - 가설 1-5 모두 통계적 유의
    - 효과 크기 중간 이상
  
  질적_증거:
    - 명료화 효과에 대한 명확한 증언
    - 학습 방식 변화에 대한 구체적 사례
    - 깨달음의 순간에 대한 생생한 설명
  
  장기_효과:
    - 지연 평가에서도 A그룹 우세
    - 재사용 의향 ≥ 4.5
    - 추천 의향 ≥ 4.5
```

### 8.3 부분 성공 시나리오

```yaml
시나리오_1: 학습 성과만 유의미
  결과:
    - 가설 1 검증 성공
    - 가설 2-5 검증 실패
  
  해석:
    - 에이전트 모드가 지식 습득엔 효과적
    - 메타인지나 학습 효율은 차이 없음
  
  후속_조치:
    - 명료화 과정 개선
    - 메타인지 훈련 강화

시나리오_2: 메타인지만 유의미
  결과:
    - 가설 2 검증 성공
    - 가설 1, 3-5 검증 실패
  
  해석:
    - 질문 구체화 능력은 향상
    - 단기 학습 성과로 이어지지 않음
  
  후속_조치:
    - 장기 실험 필요
    - 메타인지 → 학습 성과 경로 분석

시나리오_3: 효율성 낮지만 성과 높음
  결과:
    - 가설 1 검증 성공
    - 가설 4 (효율성) 검증 실패
  
  해석:
    - 더 많은 시간이 필요하지만 성과는 높음
    - 깊이 있는 학습 vs 빠른 학습 트레이드오프
  
  후속_조치:
    - UX 개선으로 시간 단축
    - 사용 가이드 강화
```

---

## 🛠️ 9. 구현 로드맵

### Phase 1: 백엔드 개발 (1-2주)

```yaml
필요_테이블:
  - pre_post_assessments
  - assessment_questions
  - student_assessment_responses
  - metacognitive_surveys
  - experiment_participants

필요_API:
  - POST /api/experiments/register
  - POST /api/experiments/pre-survey
  - POST /api/experiments/pre-assessment
  - POST /api/experiments/mid-checkin
  - POST /api/experiments/post-survey
  - POST /api/experiments/post-assessment
  - POST /api/experiments/follow-up
  - GET /api/experiments/dashboard

자동_채점_시스템:
  - 객관식: 자동 채점
  - 주관식: 교사 채점 인터페이스
```

### Phase 2: 프론트엔드 개발 (1-2주)

```yaml
필요_페이지:
  - /experiment/register (참여 등록)
  - /experiment/pre-survey (사전 설문)
  - /experiment/pre-assessment (사전 평가)
  - /experiment/mid-checkin (중간 체크인)
  - /experiment/post-survey (사후 설문)
  - /experiment/post-assessment (사후 평가)
  - /experiment/follow-up (지연 평가)
  - /experiment/dashboard (진행 현황)

사용자_경험:
  - 진행률 표시
  - 저장 및 이어하기
  - 모바일 반응형
  - 접근성 준수
```

### Phase 3: 분석 도구 개발 (1주)

```yaml
데이터_수집:
  - 자동 데이터 내보내기 스크립트
  - CSV/Excel 변환 기능
  
통계_분석:
  - R 스크립트 (t-test, ANOVA, ANCOVA)
  - Python 스크립트 (데이터 전처리)
  
시각화:
  - 대시보드 (실시간 진행 현황)
  - 그래프 생성 (결과 시각화)
```

### Phase 4: 파일럿 테스트 (1주)

```yaml
목적:
  - 시스템 기능 검증
  - 설문 문항 검증
  - 프로세스 검증
  
참여자:
  - 5-10명 내부 테스터
  
검증_항목:
  - 설문 소요 시간
  - 문항 명확성
  - 기술적 오류
  - 사용자 경험

개선:
  - 피드백 반영
  - 최종 조정
```

### Phase 5: 본 실험 (4주)

```yaml
Week_0: 모집 및 사전 평가
Week_1-2: 실험 진행
Week_3-4: 대기 및 지연 평가
```

### Phase 6: 분석 및 보고 (2-3주)

```yaml
Week_1: 데이터 정제 및 검증
Week_2: 통계 분석 및 질적 분석
Week_3: 보고서 작성 및 발표 준비
```

---

## 📋 10. 체크리스트

### 실험 시작 전
- [ ] IRB 승인 획득 (윤리 심의)
- [ ] 참여자 모집 완료 (50-60명)
- [ ] 동의서 수집
- [ ] 무작위 그룹 배정
- [ ] 배정 균형 확인
- [ ] 시스템 기능 테스트
- [ ] 오리엔테이션 자료 준비
- [ ] 사전 설문/평가 준비
- [ ] 모니터링 대시보드 구축

### Week 0
- [ ] 오리엔테이션 실시
- [ ] 사전 설문 수집 (100%)
- [ ] 사전 평가 수집 (100%)
- [ ] 시스템 접근 권한 부여
- [ ] 데이터 백업 확인

### Week 1
- [ ] 일일 사용 현황 모니터링
- [ ] 기술 지원 제공
- [ ] 미사용자 독려
- [ ] 중간 체크인 실시 (Day 7)
- [ ] 중간 데이터 백업

### Week 2
- [ ] 지속 사용 독려
- [ ] 사후 평가 안내
- [ ] 사후 설문 수집 (≥ 70%)
- [ ] 사후 평가 수집 (≥ 70%)
- [ ] 감사 메시지 발송

### Week 3-4
- [ ] 지연 평가 안내
- [ ] 지연 평가 수집
- [ ] 최종 데이터 백업
- [ ] 인센티브 지급

### 분석 단계
- [ ] 데이터 정제 완료
- [ ] 이상치 확인 및 처리
- [ ] 기술 통계 완료
- [ ] 가설 검증 완료
- [ ] 질적 분석 완료
- [ ] 보고서 작성
- [ ] 결과 발표

---

## 📞 11. 참여자 안내사항

### 오리엔테이션 스크립트

```markdown
# MAICE 시스템 A/B 테스트 실험 안내

## 실험 소개
안녕하세요! MAICE 시스템 실험에 참여해주셔서 감사합니다.

이 실험의 목적은 **AI를 활용한 수학 학습의 효과**를 과학적으로 검증하는 것입니다.

## 그룹 배정
여러분은 무작위로 두 그룹 중 하나에 배정됩니다:
- **A그룹 (에이전트 모드)**: 대화형 학습 지원, 질문 명료화 포함
- **B그룹 (프리패스 모드)**: 빠른 답변 제공

⚠️ 중요: 두 그룹 모두 동일하게 소중한 데이터를 제공합니다.
어느 그룹이 더 좋거나 나쁜 것이 아닙니다!

## 실험 기간 및 일정
- **전체 기간**: 4주
- **집중 사용 기간**: 2주 (Week 1-2)
- **권장 사용량**:
  - 하루 30분 이상
  - 주 3-5회 이상
  - 최소 10개 질문

## 설문 일정
1. **사전 평가 (오늘)**: 설문 30분 + 평가 60분
2. **중간 체크인 (1주 후)**: 설문 20분 + 평가 30분
3. **사후 평가 (2주 후)**: 설문 40분 + 평가 60분
4. **지연 평가 (4주 후)**: 설문 15분 + 평가 30분

## 인센티브
- **완료 시**: 문화상품권 2만원
- **성실 참여 (상위 30%)**: 추가 1만원
- **우수 참여 사례**: 추가 보상

## 유의사항
- 다른 AI 도구 동시 사용 자제 (데이터 왜곡 방지)
- 솔직한 응답 부탁 (정답이 없습니다!)
- 기술적 문제 발생 시 즉시 연락
- 개인정보는 철저히 보호됩니다

## 연락처
- 이메일: experiment@maice.edu
- 카카오톡: @maice_support
- 긴급: 010-XXXX-XXXX

여러분의 참여가 수학 교육의 미래를 만듭니다!
궁금한 점이 있으면 언제든 연락주세요. 😊
```

---

## 📊 12. 예상 결과 및 논의 포인트

### 12.1 긍정적 결과 시나리오

```yaml
예상_결과:
  학습_성과:
    - A그룹 정규화 향상도: 45-50%
    - B그룹 정규화 향상도: 30-35%
    - Cohen's d: 0.6-0.8 (중-대 효과)
  
  메타인지:
    - A그룹 메타인지 향상: +1.2-1.5점
    - B그룹 메타인지 향상: +0.5-0.8점
    - 질문 품질 점수: A그룹 +3점 이상
  
  학습_효율:
    - 시간당 성과: 비슷하거나 A그룹 약간 낮음
    - 장기 효율: A그룹 높음 (지연 평가)

논의_포인트:
  명료화의_교육적_가치:
    - 즉각적 답변보다 과정 중심 학습이 효과적
    - 소크라테스식 대화의 현대적 구현
    - 메타인지 훈련의 중요성
  
  AI_교육의_방향성:
    - 단순 정보 제공 넘어선 학습 촉진자 역할
    - 개인화된 학습 지원의 가능성
    - 교사와의 협력 모델
```

### 12.2 부정적/중립적 결과 시나리오

```yaml
예상_결과:
  학습_성과:
    - 두 그룹 간 유의미한 차이 없음
    - 또는 B그룹이 더 높음
  
  학습_효율:
    - A그룹이 시간이 더 오래 걸림
    - 비용-효과 측면에서 비효율적

논의_포인트:
  명료화_과정의_개선_필요:
    - 명료화 질문이 너무 복잡하거나 불명확
    - 학생 수준에 맞지 않는 가이드
    - UX 개선 필요
  
  학습자_특성_고려:
    - 자기주도적 학생에게만 효과적
    - 즉각적 답변 선호 학생에겐 부적합
    - 맞춤형 모드 제안 필요
  
  단기_vs_장기_효과:
    - 단기적으론 비효율적이지만
    - 장기적(지연 평가)으론 효과적일 가능성
    - 추가 연구 필요
```

---

## 🎓 13. 윤리적 고려사항

### 13.1 연구 윤리

```yaml
IRB_승인:
  - 기관 생명윤리위원회 심의 필수
  - 실험 프로토콜 제출
  - 위험-이익 분석

informed_consent:
  - 실험 목적 명확히 설명
  - 참여 자발성 강조
  - 철회 가능성 명시
  - 데이터 사용 범위 설명

개인정보_보호:
  - 익명화 처리
  - 암호화 저장
  - 접근 권한 제한
  - GDPR/개인정보보호법 준수
```

### 13.2 참여자 보호

```yaml
공정성:
  - 두 그룹 모두 유익한 학습 경험
  - 실험 종료 후 모든 기능 접근 허용
  - 불이익 없음 보장

취약_참여자_보호:
  - 미성년자: 법정대리인 동의
  - 학습 부진: 추가 지원 제공
  - 기술 접근성: 기기/인터넷 지원

스트레스_최소화:
  - 과도한 평가 부담 회피
  - 적절한 휴식 시간
  - 정서적 지원 제공
```

---

## 📚 14. 참고문헌 및 이론적 배경

### 14.1 이론적 기반

```yaml
메타인지_이론:
  - Flavell (1979): 메타인지 개념 정립
  - Schraw & Dennison (1994): 메타인지 측정
  - Zimmerman (2002): 자기조절학습

소크라테스식_대화:
  - Questioning method in education
  - Guided discovery learning
  - Scaffolding in ZPD (Vygotsky)

AI_교육_연구:
  - Intelligent Tutoring Systems (ITS)
  - Adaptive Learning Systems
  - Conversational AI in Education
```

### 14.2 선행 연구

```yaml
관련_연구:
  - VanLehn et al. (2007): ITS 효과성
  - Koedinger et al. (2015): Learning by doing
  - Graesser et al. (2018): Conversational agents

본_연구의_차별성:
  - 명료화 과정에 초점
  - 메타인지 능력 측정
  - 질문 품질 자동 평가
  - 실제 학습 환경 적용
```

---

이 실험 계획서는 MAICE 시스템의 교육적 효과를 과학적으로 검증하기 위한 체계적인 로드맵을 제공합니다.

**다음 단계**: 구현 착수 및 파일럿 테스트

