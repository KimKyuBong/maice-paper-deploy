# MAICE A/B í…ŒìŠ¤íŠ¸ êµ¬í˜„ ë¡œë“œë§µ

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” MAICE ì‹œìŠ¤í…œ A/B í…ŒìŠ¤íŠ¸ ì‹¤í—˜ì„ ìœ„í•œ ê¸°ìˆ ì  êµ¬í˜„ ë¡œë“œë§µì„ ì œê³µí•©ë‹ˆë‹¤.

---

## ğŸ—„ï¸ 1. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

### 1.1 ìƒˆë¡œìš´ í…Œì´ë¸”

#### experiment_participants (ì‹¤í—˜ ì°¸ì—¬ì)
```sql
CREATE TABLE experiment_participants (
    id SERIAL PRIMARY KEY,
    user_id INTEGER NOT NULL REFERENCES users(id),
    experiment_id INTEGER NOT NULL,  -- ì‹¤í—˜ ì‹ë³„ì
    group_assignment VARCHAR(10) NOT NULL,  -- 'A' or 'B'
    consent_given BOOLEAN DEFAULT FALSE,
    consent_date TIMESTAMP,
    
    -- ì¸êµ¬í†µê³„ ì •ë³´
    grade VARCHAR(50),
    recent_math_score VARCHAR(50),
    weekly_study_hours VARCHAR(50),
    ai_experience VARCHAR(50),
    
    -- í•™ìŠµ ë‹¨ì›
    learning_unit VARCHAR(100),
    
    -- ì°¸ì—¬ ìƒíƒœ
    status VARCHAR(20) DEFAULT 'registered',  -- registered, active, completed, dropped
    registration_date TIMESTAMP DEFAULT NOW(),
    completion_date TIMESTAMP,
    
    -- ì¸ì„¼í‹°ë¸Œ
    incentive_earned DECIMAL(10,2) DEFAULT 0.00,
    incentive_paid BOOLEAN DEFAULT FALSE,
    
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    
    UNIQUE(user_id, experiment_id)
);

CREATE INDEX idx_exp_participants_user ON experiment_participants(user_id);
CREATE INDEX idx_exp_participants_group ON experiment_participants(experiment_id, group_assignment);
```

#### pre_post_assessments (ì‚¬ì „-ì‚¬í›„ í‰ê°€)
```sql
CREATE TABLE pre_post_assessments (
    id SERIAL PRIMARY KEY,
    participant_id INTEGER NOT NULL REFERENCES experiment_participants(id),
    assessment_type VARCHAR(20) NOT NULL,  -- 'pre', 'mid', 'post', 'followup'
    
    -- í‰ê°€ ì ìˆ˜
    total_score DECIMAL(5,2),
    basic_score DECIMAL(5,2),
    application_score DECIMAL(5,2),
    advanced_score DECIMAL(5,2),
    transfer_score DECIMAL(5,2),  -- post, followupë§Œ
    
    -- ë¬¸ì œë³„ ìƒì„¸ ì ìˆ˜ (JSON)
    question_scores JSONB,
    
    -- í™•ì‹ ë„ ì ìˆ˜ (JSON)
    confidence_scores JSONB,
    
    -- í’€ì´ ê³¼ì • (ì„ íƒì‚¬í•­)
    solution_processes TEXT,
    
    -- ì†Œìš” ì‹œê°„
    time_taken_minutes INTEGER,
    
    -- ì™„ë£Œ ì •ë³´
    started_at TIMESTAMP,
    completed_at TIMESTAMP,
    is_completed BOOLEAN DEFAULT FALSE,
    
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_assessments_participant ON pre_post_assessments(participant_id);
CREATE INDEX idx_assessments_type ON pre_post_assessments(assessment_type);
```

#### metacognitive_surveys (ë©”íƒ€ì¸ì§€ ì„¤ë¬¸)
```sql
CREATE TABLE metacognitive_surveys (
    id SERIAL PRIMARY KEY,
    participant_id INTEGER NOT NULL REFERENCES experiment_participants(id),
    survey_timing VARCHAR(20) NOT NULL,  -- 'pre', 'post', 'followup'
    
    -- ë©”íƒ€ì¸ì§€ í•­ëª©ë“¤ (1-5ì )
    self_awareness INTEGER CHECK (self_awareness BETWEEN 1 AND 5),
    planning_ability INTEGER CHECK (planning_ability BETWEEN 1 AND 5),
    reflection_ability INTEGER CHECK (reflection_ability BETWEEN 1 AND 5),
    concept_connection INTEGER CHECK (concept_connection BETWEEN 1 AND 5),
    self_monitoring INTEGER CHECK (self_monitoring BETWEEN 1 AND 5),
    
    -- Post only
    question_refinement INTEGER CHECK (question_refinement BETWEEN 1 AND 5),
    self_regulation INTEGER CHECK (self_regulation BETWEEN 1 AND 5),
    problem_decomposition INTEGER CHECK (problem_decomposition BETWEEN 1 AND 5),
    thought_elaboration INTEGER CHECK (thought_elaboration BETWEEN 1 AND 5),
    
    -- í‰ê·  ì ìˆ˜
    avg_score DECIMAL(3,2),
    
    completed_at TIMESTAMP DEFAULT NOW(),
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_metacog_participant ON metacognitive_surveys(participant_id);
```

#### problem_solving_surveys (ë¬¸ì œí•´ê²° ëŠ¥ë ¥ ì„¤ë¬¸)
```sql
CREATE TABLE problem_solving_surveys (
    id SERIAL PRIMARY KEY,
    participant_id INTEGER NOT NULL REFERENCES experiment_participants(id),
    
    -- ë¬¸ì œí•´ê²° í•­ëª©ë“¤ (1-5ì )
    new_problem_confidence INTEGER CHECK (new_problem_confidence BETWEEN 1 AND 5),
    concept_connection_ability INTEGER CHECK (concept_connection_ability BETWEEN 1 AND 5),
    strategy_diversity INTEGER CHECK (strategy_diversity BETWEEN 1 AND 5),
    step_by_step_approach INTEGER CHECK (step_by_step_approach BETWEEN 1 AND 5),
    
    -- í‰ê·  ì ìˆ˜
    avg_score DECIMAL(3,2),
    
    completed_at TIMESTAMP DEFAULT NOW(),
    created_at TIMESTAMP DEFAULT NOW()
);
```

#### learning_outcome_surveys (í•™ìŠµ ì„±ê³¼ ì„¤ë¬¸)
```sql
CREATE TABLE learning_outcome_surveys (
    id SERIAL PRIMARY KEY,
    participant_id INTEGER NOT NULL REFERENCES experiment_participants(id),
    survey_timing VARCHAR(20) NOT NULL,  -- 'pre', 'post', 'followup'
    
    -- í•™ìŠµ ì„±ê³¼ í•­ëª©
    unit_understanding INTEGER CHECK (unit_understanding BETWEEN 1 AND 5),
    confidence_level INTEGER CHECK (confidence_level BETWEEN 1 AND 5),
    new_concepts_learned VARCHAR(50),  -- post only
    application_ability INTEGER CHECK (application_ability BETWEEN 1 AND 5),  -- post only
    
    completed_at TIMESTAMP DEFAULT NOW(),
    created_at TIMESTAMP DEFAULT NOW()
);
```

#### system_effectiveness_surveys (ì‹œìŠ¤í…œ íš¨ê³¼ì„± ì„¤ë¬¸)
```sql
CREATE TABLE system_effectiveness_surveys (
    id SERIAL PRIMARY KEY,
    participant_id INTEGER NOT NULL REFERENCES experiment_participants(id),
    group_type VARCHAR(10) NOT NULL,  -- 'A' or 'B'
    
    -- Aê·¸ë£¹ ì „ìš©
    clarification_help INTEGER CHECK (clarification_help BETWEEN 1 AND 5),
    clarification_learning INTEGER CHECK (clarification_learning BETWEEN 1 AND 5),
    quality_feedback INTEGER CHECK (quality_feedback BETWEEN 1 AND 5),
    step_guidance INTEGER CHECK (step_guidance BETWEEN 1 AND 5),
    clarification_description TEXT,
    
    -- Bê·¸ë£¹ ì „ìš©
    fast_response_help INTEGER CHECK (fast_response_help BETWEEN 1 AND 5),
    learning_efficiency INTEGER CHECK (learning_efficiency BETWEEN 1 AND 5),
    exploration_ability INTEGER CHECK (exploration_ability BETWEEN 1 AND 5),
    useful_situation TEXT,
    
    completed_at TIMESTAMP DEFAULT NOW(),
    created_at TIMESTAMP DEFAULT NOW()
);
```

#### qualitative_responses (ì£¼ê´€ì‹ ì‘ë‹µ)
```sql
CREATE TABLE qualitative_responses (
    id SERIAL PRIMARY KEY,
    participant_id INTEGER NOT NULL REFERENCES experiment_participants(id),
    survey_timing VARCHAR(20) NOT NULL,  -- 'mid', 'post', 'followup'
    
    -- ì£¼ê´€ì‹ ì‘ë‹µë“¤
    biggest_learning TEXT,
    learning_change TEXT,
    memorable_moment TEXT,
    biggest_strength TEXT,
    biggest_weakness TEXT,
    would_continue VARCHAR(50),
    would_continue_reason TEXT,
    recommendation_score INTEGER CHECK (recommendation_score BETWEEN 1 AND 5),
    recommendation_reason TEXT,
    
    -- ì¤‘ê°„ ì²´í¬ì¸ ì „ìš©
    difficult_concepts TEXT,
    solved_concepts TEXT,
    
    -- ì§€ì—° í‰ê°€ ì „ìš©
    method_change VARCHAR(50),
    method_change_description TEXT,
    
    completed_at TIMESTAMP DEFAULT NOW(),
    created_at TIMESTAMP DEFAULT NOW()
);
```

#### usage_statistics (ì‚¬ìš© í†µê³„ - ìë™ ìˆ˜ì§‘)
```sql
CREATE TABLE usage_statistics (
    id SERIAL PRIMARY KEY,
    participant_id INTEGER NOT NULL REFERENCES experiment_participants(id),
    week_number INTEGER NOT NULL,  -- 1 or 2
    
    -- ì‚¬ìš© íŒ¨í„´
    total_sessions INTEGER DEFAULT 0,
    total_time_minutes INTEGER DEFAULT 0,
    total_questions INTEGER DEFAULT 0,
    total_answers INTEGER DEFAULT 0,
    avg_session_length DECIMAL(5,2),
    
    -- ì§ˆë¬¸ í’ˆì§ˆ (Aê·¸ë£¹ë§Œ)
    avg_question_quality DECIMAL(5,2),
    quality_trend VARCHAR(20),  -- 'improving', 'stable', 'declining'
    clarification_count INTEGER DEFAULT 0,
    clarification_success_rate DECIMAL(5,2),
    
    -- í•™ìŠµ ë‚´ìš©
    concepts_covered JSONB,
    difficulty_areas JSONB,
    
    -- ë„êµ¬ ì‚¬ìš©
    desmos_usage INTEGER DEFAULT 0,
    latex_usage INTEGER DEFAULT 0,
    
    calculated_at TIMESTAMP DEFAULT NOW(),
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_usage_participant ON usage_statistics(participant_id);
```

#### assessment_questions (í‰ê°€ ë¬¸ì œ ì€í–‰)
```sql
CREATE TABLE assessment_questions (
    id SERIAL PRIMARY KEY,
    question_bank_id INTEGER NOT NULL,  -- ë¬¸ì œ ì„¸íŠ¸ ì‹ë³„
    question_order INTEGER NOT NULL,
    
    question_type VARCHAR(20) NOT NULL,  -- 'basic', 'application', 'advanced', 'transfer'
    question_text TEXT NOT NULL,
    question_latex TEXT,
    question_image_url VARCHAR(500),
    
    -- ì •ë‹µ ì •ë³´
    answer_type VARCHAR(20) NOT NULL,  -- 'multiple_choice', 'short_answer', 'numeric', 'open_ended'
    correct_answer TEXT,
    answer_options JSONB,  -- ê°ê´€ì‹ ì„ íƒì§€
    
    -- ì±„ì  ì •ë³´
    points DECIMAL(5,2) DEFAULT 1.00,
    auto_gradable BOOLEAN DEFAULT TRUE,
    
    -- ë©”íƒ€ë°ì´í„°
    difficulty_level VARCHAR(20),  -- 'easy', 'medium', 'hard'
    topic VARCHAR(100),
    
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_questions_bank ON assessment_questions(question_bank_id);
```

---

## ğŸ”§ 2. API ì—”ë“œí¬ì¸íŠ¸

### 2.1 ì‹¤í—˜ ë“±ë¡ ë° ê´€ë¦¬

```python
# back/app/api/v1/experiment.py

@router.post("/experiments/register")
async def register_participant(
    request: ExperimentRegistrationRequest,
    current_user: UserModel = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    ì‹¤í—˜ ì°¸ì—¬ì ë“±ë¡ ë° ê·¸ë£¹ ë°°ì •
    """
    # 1. ì´ë¯¸ ë“±ë¡ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    # 2. ë¬´ì‘ìœ„ ê·¸ë£¹ ë°°ì • (ê· í˜• ìœ ì§€)
    # 3. ë™ì˜ì„œ í™•ì¸
    # 4. ì°¸ì—¬ì ì •ë³´ ì €ì¥
    # 5. í™˜ì˜ ì´ë©”ì¼ ë°œì†¡
    pass

@router.get("/experiments/{experiment_id}/status")
async def get_experiment_status(
    experiment_id: int,
    current_user: UserModel = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    ì‹¤í—˜ ì§„í–‰ ìƒí™© ì¡°íšŒ
    """
    # ì™„ë£Œí•œ ë‹¨ê³„, ë‹¤ìŒ ë‹¨ê³„, ì§„í–‰ë¥  ë°˜í™˜
    pass

@router.get("/experiments/{experiment_id}/dashboard")
async def get_experiment_dashboard(
    experiment_id: int,
    current_user: UserModel = Depends(get_current_admin),
    db: AsyncSession = Depends(get_db)
):
    """
    ì‹¤í—˜ ì „ì²´ ëŒ€ì‹œë³´ë“œ (ê´€ë¦¬ììš©)
    """
    # ì°¸ì—¬ì ìˆ˜, ì™„ë£Œìœ¨, ê·¸ë£¹ë³„ í†µê³„ ë“±
    pass
```

### 2.2 ì‚¬ì „-ì‚¬í›„ í‰ê°€

```python
@router.post("/experiments/pre-survey")
async def submit_pre_survey(
    request: PreSurveyRequest,
    current_user: UserModel = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    ì‚¬ì „ ì„¤ë¬¸ ì œì¶œ
    """
    # 1. ê¸°ë³¸ ì •ë³´ ì €ì¥
    # 2. í•™ìŠµ ë‹¨ì› í‰ê°€ ì €ì¥
    # 3. ë©”íƒ€ì¸ì§€ ê¸°ì €ì„  ì €ì¥
    pass

@router.get("/experiments/assessment-questions/{assessment_type}")
async def get_assessment_questions(
    assessment_type: str,  # 'pre', 'mid', 'post', 'followup'
    current_user: UserModel = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    í‰ê°€ ë¬¸ì œ ì¡°íšŒ
    """
    # ë¬¸ì œ ì€í–‰ì—ì„œ ë¬¸ì œ ê°€ì ¸ì˜¤ê¸°
    pass

@router.post("/experiments/assessment-response")
async def submit_assessment_response(
    request: AssessmentResponseRequest,
    current_user: UserModel = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    í‰ê°€ ë‹µì•ˆ ì œì¶œ ë° ìë™ ì±„ì 
    """
    # 1. ë‹µì•ˆ ì €ì¥
    # 2. ìë™ ì±„ì  (ê°€ëŠ¥í•œ ê²½ìš°)
    # 3. ì ìˆ˜ ê³„ì‚°
    pass

@router.post("/experiments/post-survey")
async def submit_post_survey(
    request: PostSurveyRequest,
    current_user: UserModel = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    ì‚¬í›„ ì„¤ë¬¸ ì œì¶œ
    """
    # 1. í•™ìŠµ ì„±ê³¼ í‰ê°€
    # 2. ë©”íƒ€ì¸ì§€ ë³€í™”
    # 3. ë¬¸ì œí•´ê²° ëŠ¥ë ¥
    # 4. ì‹œìŠ¤í…œ íš¨ê³¼ì„±
    # 5. ì£¼ê´€ì‹ ì‘ë‹µ
    pass
```

### 2.3 ë°ì´í„° ë¶„ì„ ë° ë‚´ë³´ë‚´ê¸°

```python
@router.get("/experiments/{experiment_id}/export")
async def export_experiment_data(
    experiment_id: int,
    format: str = "csv",  # 'csv', 'excel', 'json'
    current_user: UserModel = Depends(get_current_admin),
    db: AsyncSession = Depends(get_db)
):
    """
    ì‹¤í—˜ ë°ì´í„° ë‚´ë³´ë‚´ê¸°
    """
    # ëª¨ë“  ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ë¶„ì„ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë‚´ë³´ë‚´ê¸°
    pass

@router.get("/experiments/{experiment_id}/statistics")
async def get_experiment_statistics(
    experiment_id: int,
    current_user: UserModel = Depends(get_current_admin),
    db: AsyncSession = Depends(get_db)
):
    """
    ì‹¤í—˜ í†µê³„ ì¡°íšŒ
    """
    # ê¸°ìˆ  í†µê³„, ê·¸ë£¹ ë¹„êµ, íš¨ê³¼ í¬ê¸° ë“±
    pass

@router.post("/experiments/{experiment_id}/calculate-usage")
async def calculate_usage_statistics(
    experiment_id: int,
    current_user: UserModel = Depends(get_current_admin),
    db: AsyncSession = Depends(get_db)
):
    """
    ì‚¬ìš© í†µê³„ ê³„ì‚° (ì‹œìŠ¤í…œ ë¡œê·¸ë¡œë¶€í„°)
    """
    # ab_test_interactionsì—ì„œ ë°ì´í„° ì§‘ê³„
    # usage_statistics í…Œì´ë¸”ì— ì €ì¥
    pass
```

---

## ğŸ¨ 3. í”„ë¡ íŠ¸ì—”ë“œ ì»´í¬ë„ŒíŠ¸

### 3.1 í˜ì´ì§€ êµ¬ì¡°

```
front/src/routes/experiment/
â”œâ”€â”€ register/
â”‚   â””â”€â”€ +page.svelte              # ì‹¤í—˜ ë“±ë¡
â”œâ”€â”€ pre-survey/
â”‚   â””â”€â”€ +page.svelte              # ì‚¬ì „ ì„¤ë¬¸
â”œâ”€â”€ pre-assessment/
â”‚   â””â”€â”€ +page.svelte              # ì‚¬ì „ í‰ê°€
â”œâ”€â”€ mid-checkin/
â”‚   â””â”€â”€ +page.svelte              # ì¤‘ê°„ ì²´í¬ì¸
â”œâ”€â”€ post-survey/
â”‚   â””â”€â”€ +page.svelte              # ì‚¬í›„ ì„¤ë¬¸
â”œâ”€â”€ post-assessment/
â”‚   â””â”€â”€ +page.svelte              # ì‚¬í›„ í‰ê°€
â”œâ”€â”€ followup/
â”‚   â””â”€â”€ +page.svelte              # ì§€ì—° í‰ê°€
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ +page.svelte              # ì§„í–‰ í˜„í™©
â””â”€â”€ admin/
    â””â”€â”€ +page.svelte              # ê´€ë¦¬ì ëŒ€ì‹œë³´ë“œ
```

### 3.2 ì£¼ìš” ì»´í¬ë„ŒíŠ¸

#### ExperimentProgress.svelte
```svelte
<script lang="ts">
  export let currentStep: number;
  export let totalSteps: number;
  
  const steps = [
    { name: 'ì‚¬ì „ ì„¤ë¬¸', status: 'completed' },
    { name: 'ì‚¬ì „ í‰ê°€', status: 'completed' },
    { name: '1ì£¼ì°¨ ì‚¬ìš©', status: 'in_progress' },
    { name: 'ì¤‘ê°„ ì²´í¬ì¸', status: 'pending' },
    { name: '2ì£¼ì°¨ ì‚¬ìš©', status: 'pending' },
    { name: 'ì‚¬í›„ í‰ê°€', status: 'pending' },
    { name: 'ì§€ì—° í‰ê°€', status: 'pending' }
  ];
</script>

<div class="progress-tracker">
  {#each steps as step, i}
    <div class="step" class:completed={step.status === 'completed'}
         class:current={step.status === 'in_progress'}>
      <div class="step-number">{i + 1}</div>
      <div class="step-name">{step.name}</div>
    </div>
  {/each}
</div>
```

#### LikertScale.svelte
```svelte
<script lang="ts">
  export let question: string;
  export let value: number = 3;
  export let labels: string[] = ['ì „í˜€ ì•„ë‹˜', 'ì•„ë‹˜', 'ë³´í†µ', 'ê·¸ë ‡ë‹¤', 'ë§¤ìš° ê·¸ë ‡ë‹¤'];
  
  function handleChange(newValue: number) {
    value = newValue;
  }
</script>

<div class="likert-scale">
  <p class="question">{question}</p>
  <div class="scale">
    {#each [1, 2, 3, 4, 5] as score}
      <label class="option">
        <input type="radio" name={question} value={score}
               checked={value === score}
               on:change={() => handleChange(score)} />
        <span class="score">{score}</span>
        <span class="label">{labels[score - 1]}</span>
      </label>
    {/each}
  </div>
</div>
```

#### AssessmentQuestion.svelte
```svelte
<script lang="ts">
  import MathRenderer from '$lib/components/MathRenderer.svelte';
  
  export let question: AssessmentQuestion;
  export let answer: any;
  export let showConfidence: boolean = true;
  
  let confidence: number = 3;
</script>

<div class="assessment-question">
  <div class="question-header">
    <span class="question-number">ë¬¸ì œ {question.order}</span>
    <span class="question-type">{question.type}</span>
    <span class="points">{question.points}ì </span>
  </div>
  
  <div class="question-text">
    {#if question.latex}
      <MathRenderer latex={question.latex} />
    {:else}
      {@html question.text}
    {/if}
  </div>
  
  {#if question.answerType === 'multiple_choice'}
    <div class="options">
      {#each question.options as option, i}
        <label>
          <input type="radio" name="q{question.id}" value={option.value}
                 bind:group={answer} />
          <MathRenderer latex={option.text} />
        </label>
      {/each}
    </div>
  {:else if question.answerType === 'short_answer'}
    <input type="text" bind:value={answer} placeholder="ë‹µì„ ì…ë ¥í•˜ì„¸ìš”" />
  {:else if question.answerType === 'numeric'}
    <input type="number" bind:value={answer} placeholder="ìˆ«ìë¡œ ì…ë ¥" />
  {/if}
  
  {#if showConfidence}
    <div class="confidence">
      <p>ì´ ë¬¸ì œë¥¼ ë§í˜”ë‹¤ê³  í™•ì‹ í•˜ë‚˜ìš”?</p>
      <LikertScale bind:value={confidence} labels={['ì „í˜€', 'ì•½ê°„', 'ë³´í†µ', 'í™•ì‹ ', 'ë§¤ìš° í™•ì‹ ']} />
    </div>
  {/if}
</div>
```

---

## ğŸ“Š 4. ë°ì´í„° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

### 4.1 R ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

```r
# scripts/analysis/analyze_ab_test.R

library(tidyverse)
library(effsize)
library(lme4)

# ë°ì´í„° ë¡œë“œ
data <- read_csv("data/experiments/ab_test_results.csv")

# ===== ê¸°ìˆ  í†µê³„ =====
descriptive_stats <- data %>%
  group_by(group) %>%
  summarise(
    n = n(),
    
    # í•™ìŠµ ì„±ê³¼
    pre_mean = mean(pre_score, na.rm = TRUE),
    pre_sd = sd(pre_score, na.rm = TRUE),
    post_mean = mean(post_score, na.rm = TRUE),
    post_sd = sd(post_score, na.rm = TRUE),
    gain_mean = mean(gain_score, na.rm = TRUE),
    gain_sd = sd(gain_score, na.rm = TRUE),
    normalized_gain_mean = mean(normalized_gain, na.rm = TRUE),
    
    # ë©”íƒ€ì¸ì§€
    metacog_pre_mean = mean(metacog_pre, na.rm = TRUE),
    metacog_post_mean = mean(metacog_post, na.rm = TRUE),
    metacog_gain_mean = mean(metacog_gain, na.rm = TRUE),
    
    # í•™ìŠµ íš¨ìœ¨
    time_mean = mean(total_time_minutes, na.rm = TRUE),
    efficiency_mean = mean(gain_score / total_time_minutes, na.rm = TRUE),
    
    # ì§€ì†ì„±
    retention_mean = mean(retention_score, na.rm = TRUE),
    would_continue_mean = mean(would_continue, na.rm = TRUE),
    recommendation_mean = mean(recommendation_score, na.rm = TRUE)
  )

print(descriptive_stats)

# ===== ê°€ì„¤ 1: í•™ìŠµ ì„±ê³¼ =====
# Independent t-test
gain_test <- t.test(
  gain_score ~ group,
  data = data,
  alternative = "greater",  # A > B
  var.equal = FALSE
)

print("=== ê°€ì„¤ 1: í•™ìŠµ ì„±ê³¼ ===")
print(gain_test)

# Cohen's d
cohens_d_gain <- cohen.d(
  data$gain_score[data$group == "A"],
  data$gain_score[data$group == "B"]
)
print(cohens_d_gain)

# Normalized gain
normalized_test <- t.test(
  normalized_gain ~ group,
  data = data,
  alternative = "greater"
)
print(normalized_test)

# ===== ê°€ì„¤ 2: ë©”íƒ€ì¸ì§€ =====
# Repeated measures ANOVA
metacog_long <- data %>%
  select(participant_id, group, metacog_pre, metacog_post) %>%
  pivot_longer(
    cols = starts_with("metacog"),
    names_to = "time",
    values_to = "score"
  )

metacog_anova <- aov(
  score ~ group * time + Error(participant_id/time),
  data = metacog_long
)

print("=== ê°€ì„¤ 2: ë©”íƒ€ì¸ì§€ ===")
summary(metacog_anova)

# ANCOVA (ì‚¬ì „ ì ìˆ˜ í†µì œ)
metacog_ancova <- aov(
  metacog_post ~ group + metacog_pre,
  data = data
)
summary(metacog_ancova)

# ===== ê°€ì„¤ 3: ë¬¸ì œí•´ê²° ëŠ¥ë ¥ =====
problem_solving_test <- t.test(
  problem_solving_score ~ group,
  data = data,
  alternative = "greater"
)

print("=== ê°€ì„¤ 3: ë¬¸ì œí•´ê²° ===")
print(problem_solving_test)

# ì „ì´ ë¬¸ì œ ì •ë‹µë¥ 
transfer_chisq <- chisq.test(table(data$group, data$transfer_correct))
print(transfer_chisq)

# ===== ê°€ì„¤ 4: í•™ìŠµ íš¨ìœ¨ì„± =====
efficiency_ancova <- aov(
  gain_score ~ group + pre_score + total_time_minutes,
  data = data
)

print("=== ê°€ì„¤ 4: í•™ìŠµ íš¨ìœ¨ì„± ===")
summary(efficiency_ancova)

# íš¨ê³¼ í¬ê¸° (eta squared)
eta_squared <- function(aov_result) {
  ss <- summary(aov_result)[[1]]$'Sum Sq'
  ss[1] / sum(ss)
}

print(paste("Eta squared:", eta_squared(efficiency_ancova)))

# ===== ê°€ì„¤ 5: í•™ìŠµ ì§€ì†ì„± =====
retention_test <- t.test(
  retention_rate ~ group,
  data = data,
  alternative = "greater"
)

print("=== ê°€ì„¤ 5: í•™ìŠµ ì§€ì†ì„± ===")
print(retention_test)

would_continue_test <- t.test(
  would_continue ~ group,
  data = data,
  alternative = "greater"
)
print(would_continue_test)

# ===== ì‹œê°í™” =====
# í•™ìŠµ ì„±ê³¼ ë¹„êµ
ggplot(data, aes(x = group, y = gain_score, fill = group)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, alpha = 0.5) +
  labs(
    title = "í•™ìŠµ ì„±ê³¼ ë¹„êµ (Gain Score)",
    x = "ê·¸ë£¹",
    y = "í–¥ìƒë„"
  ) +
  theme_minimal()

ggsave("results/gain_score_comparison.png", width = 8, height = 6)

# ë©”íƒ€ì¸ì§€ ë³€í™”
ggplot(metacog_long, aes(x = time, y = score, group = participant_id, color = group)) +
  geom_line(alpha = 0.3) +
  geom_point() +
  facet_wrap(~group) +
  labs(
    title = "ë©”íƒ€ì¸ì§€ ì ìˆ˜ ë³€í™”",
    x = "ì‹œì ",
    y = "ë©”íƒ€ì¸ì§€ ì ìˆ˜"
  ) +
  theme_minimal()

ggsave("results/metacog_change.png", width = 10, height = 6)

# ===== ë³´ê³ ì„œ ìƒì„± =====
sink("results/statistical_report.txt")

cat("======================================\n")
cat("MAICE A/B í…ŒìŠ¤íŠ¸ í†µê³„ ë¶„ì„ ê²°ê³¼\n")
cat("======================================\n\n")

cat("1. ê¸°ìˆ  í†µê³„\n")
print(descriptive_stats)

cat("\n2. ê°€ì„¤ ê²€ì¦ ê²°ê³¼\n")
cat("\nê°€ì„¤ 1: í•™ìŠµ ì„±ê³¼\n")
print(gain_test)
print(cohens_d_gain)

cat("\nê°€ì„¤ 2: ë©”íƒ€ì¸ì§€\n")
print(summary(metacog_anova))

cat("\nê°€ì„¤ 3: ë¬¸ì œí•´ê²°\n")
print(problem_solving_test)

cat("\nê°€ì„¤ 4: í•™ìŠµ íš¨ìœ¨ì„±\n")
print(summary(efficiency_ancova))

cat("\nê°€ì„¤ 5: í•™ìŠµ ì§€ì†ì„±\n")
print(retention_test)

sink()

cat("ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ëŠ” results/ í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n")
```

### 4.2 Python ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/analysis/preprocess_data.py

import pandas as pd
import json
from sqlalchemy import create_engine

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
engine = create_engine('postgresql://user:password@localhost:5432/maice')

# ===== ë°ì´í„° ìˆ˜ì§‘ =====
def collect_experiment_data(experiment_id: int):
    """ì‹¤í—˜ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë¶„ì„ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ë³€í™˜"""
    
    # ì°¸ì—¬ì ì •ë³´
    participants = pd.read_sql(
        f"""
        SELECT * FROM experiment_participants
        WHERE experiment_id = {experiment_id}
        """,
        engine
    )
    
    # ì‚¬ì „-ì‚¬í›„ í‰ê°€
    assessments = pd.read_sql(
        f"""
        SELECT a.*, p.user_id, p.group_assignment
        FROM pre_post_assessments a
        JOIN experiment_participants p ON a.participant_id = p.id
        WHERE p.experiment_id = {experiment_id}
        """,
        engine
    )
    
    # ë©”íƒ€ì¸ì§€ ì„¤ë¬¸
    metacog = pd.read_sql(
        f"""
        SELECT m.*, p.user_id, p.group_assignment
        FROM metacognitive_surveys m
        JOIN experiment_participants p ON m.participant_id = p.id
        WHERE p.experiment_id = {experiment_id}
        """,
        engine
    )
    
    # ì‚¬ìš© í†µê³„
    usage = pd.read_sql(
        f"""
        SELECT u.*, p.user_id, p.group_assignment
        FROM usage_statistics u
        JOIN experiment_participants p ON u.participant_id = p.id
        WHERE p.experiment_id = {experiment_id}
        """,
        engine
    )
    
    # ì£¼ê´€ì‹ ì‘ë‹µ
    qualitative = pd.read_sql(
        f"""
        SELECT q.*, p.user_id, p.group_assignment
        FROM qualitative_responses q
        JOIN experiment_participants p ON q.participant_id = p.id
        WHERE p.experiment_id = {experiment_id}
        """,
        engine
    )
    
    return {
        'participants': participants,
        'assessments': assessments,
        'metacog': metacog,
        'usage': usage,
        'qualitative': qualitative
    }

def create_analysis_dataset(data: dict):
    """ë¶„ì„ì„ ìœ„í•œ í†µí•© ë°ì´í„°ì…‹ ìƒì„±"""
    
    participants = data['participants']
    assessments = data['assessments']
    metacog = data['metacog']
    usage = data['usage']
    
    # ì‚¬ì „-ì‚¬í›„ ì ìˆ˜ í”¼ë²—
    pre_scores = assessments[assessments['assessment_type'] == 'pre'][
        ['participant_id', 'total_score']
    ].rename(columns={'total_score': 'pre_score'})
    
    post_scores = assessments[assessments['assessment_type'] == 'post'][
        ['participant_id', 'total_score', 'transfer_score']
    ].rename(columns={'total_score': 'post_score'})
    
    # ë©”íƒ€ì¸ì§€ ì ìˆ˜ í”¼ë²—
    metacog_pre = metacog[metacog['survey_timing'] == 'pre'][
        ['participant_id', 'avg_score']
    ].rename(columns={'avg_score': 'metacog_pre'})
    
    metacog_post = metacog[metacog['survey_timing'] == 'post'][
        ['participant_id', 'avg_score']
    ].rename(columns={'avg_score': 'metacog_post'})
    
    # ì‚¬ìš© í†µê³„ ì§‘ê³„
    usage_summary = usage.groupby('participant_id').agg({
        'total_time_minutes': 'sum',
        'total_questions': 'sum',
        'total_sessions': 'sum',
        'avg_question_quality': 'mean',
        'clarification_count': 'sum',
        'clarification_success_rate': 'mean'
    }).reset_index()
    
    # ëª¨ë‘ í•©ì¹˜ê¸°
    analysis_df = participants[['id', 'user_id', 'group_assignment', 'grade', 'recent_math_score']]
    analysis_df = analysis_df.merge(pre_scores, left_on='id', right_on='participant_id', how='left')
    analysis_df = analysis_df.merge(post_scores, left_on='id', right_on='participant_id', how='left')
    analysis_df = analysis_df.merge(metacog_pre, left_on='id', right_on='participant_id', how='left')
    analysis_df = analysis_df.merge(metacog_post, left_on='id', right_on='participant_id', how='left')
    analysis_df = analysis_df.merge(usage_summary, left_on='id', right_on='participant_id', how='left')
    
    # ê³„ì‚°ëœ ë³€ìˆ˜
    analysis_df['gain_score'] = analysis_df['post_score'] - analysis_df['pre_score']
    analysis_df['normalized_gain'] = (
        analysis_df['gain_score'] / (100 - analysis_df['pre_score'])
    )
    analysis_df['metacog_gain'] = analysis_df['metacog_post'] - analysis_df['metacog_pre']
    analysis_df['efficiency'] = analysis_df['gain_score'] / analysis_df['total_time_minutes']
    
    # ê·¸ë£¹ ì´ë¦„ ë³€ê²½
    analysis_df['group'] = analysis_df['group_assignment']
    
    return analysis_df

def export_for_analysis(experiment_id: int):
    """ë¶„ì„ìš© ë°ì´í„° ë‚´ë³´ë‚´ê¸°"""
    
    # ë°ì´í„° ìˆ˜ì§‘
    data = collect_experiment_data(experiment_id)
    
    # í†µí•© ë°ì´í„°ì…‹ ìƒì„±
    analysis_df = create_analysis_dataset(data)
    
    # CSVë¡œ ì €ì¥ (R ë¶„ì„ìš©)
    analysis_df.to_csv(f'data/experiments/ab_test_results.csv', index=False)
    
    # ì£¼ê´€ì‹ ì‘ë‹µ ë³„ë„ ì €ì¥
    data['qualitative'].to_csv(f'data/experiments/qualitative_responses.csv', index=False)
    
    print(f"ë°ì´í„° ë‚´ë³´ë‚´ê¸° ì™„ë£Œ: {len(analysis_df)}ëª…")
    print(f"Aê·¸ë£¹: {len(analysis_df[analysis_df['group'] == 'A'])}ëª…")
    print(f"Bê·¸ë£¹: {len(analysis_df[analysis_df['group'] == 'B'])}ëª…")
    
    return analysis_df

if __name__ == "__main__":
    export_for_analysis(experiment_id=1)
```

---

## ğŸ“… 5. êµ¬í˜„ ìŠ¤ì¼€ì¤„

### Week 1-2: ë°±ì—”ë“œ ê°œë°œ
- [ ] Day 1-2: ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ ì„¤ê³„ ë° ë§ˆì´ê·¸ë ˆì´ì…˜
- [ ] Day 3-4: API ì—”ë“œí¬ì¸íŠ¸ ê°œë°œ (ë“±ë¡, ì„¤ë¬¸)
- [ ] Day 5-6: API ì—”ë“œí¬ì¸íŠ¸ ê°œë°œ (í‰ê°€, ë¶„ì„)
- [ ] Day 7-8: ìë™ ì±„ì  ì‹œìŠ¤í…œ ê°œë°œ
- [ ] Day 9-10: í…ŒìŠ¤íŠ¸ ë° ë²„ê·¸ ìˆ˜ì •

### Week 3-4: í”„ë¡ íŠ¸ì—”ë“œ ê°œë°œ
- [ ] Day 11-12: í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ë° ë¼ìš°íŒ…
- [ ] Day 13-14: ì„¤ë¬¸ ì»´í¬ë„ŒíŠ¸ ê°œë°œ
- [ ] Day 15-16: í‰ê°€ ì»´í¬ë„ŒíŠ¸ ê°œë°œ
- [ ] Day 17-18: ëŒ€ì‹œë³´ë“œ ë° ì§„í–‰ ìƒí™© í‘œì‹œ
- [ ] Day 19-20: ë°˜ì‘í˜• ë””ìì¸ ë° ì ‘ê·¼ì„±

### Week 5: ë¶„ì„ ë„êµ¬ ë° í…ŒìŠ¤íŠ¸
- [ ] Day 21-22: ë°ì´í„° ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [ ] Day 23-24: ì‹œê°í™” ëŒ€ì‹œë³´ë“œ ê°œë°œ
- [ ] Day 25: í†µí•© í…ŒìŠ¤íŠ¸
- [ ] Day 26-27: íŒŒì¼ëŸ¿ í…ŒìŠ¤íŠ¸ (5-10ëª…)
- [ ] Day 28: í”¼ë“œë°± ë°˜ì˜ ë° ìµœì¢… ì¡°ì •

### Week 6: ë³¸ ì‹¤í—˜ ì¤€ë¹„
- [ ] ì°¸ì—¬ì ëª¨ì§‘
- [ ] ìµœì¢… ì‹œìŠ¤í…œ ì ê²€
- [ ] ëª¨ë‹ˆí„°ë§ ë„êµ¬ ì¤€ë¹„
- [ ] ì˜¤ë¦¬ì—”í…Œì´ì…˜ ìë£Œ ì¤€ë¹„

---

## ğŸ§ª 6. í…ŒìŠ¤íŠ¸ ê³„íš

### 6.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```python
# tests/test_experiment_api.py

import pytest
from httpx import AsyncClient

@pytest.mark.asyncio
async def test_register_participant(client: AsyncClient, test_user):
    response = await client.post(
        "/api/experiments/register",
        json={
            "consent_given": True,
            "grade": "ê³ ë“±í•™êµ 2í•™ë…„",
            "learning_unit": "ìˆ˜ì—´"
        },
        headers={"Authorization": f"Bearer {test_user.access_token}"}
    )
    
    assert response.status_code == 200
    data = response.json()
    assert "participant_id" in data
    assert "group_assignment" in data
    assert data["group_assignment"] in ["A", "B"]

@pytest.mark.asyncio
async def test_submit_pre_survey(client: AsyncClient, test_participant):
    response = await client.post(
        "/api/experiments/pre-survey",
        json={
            "participant_id": test_participant.id,
            "unit_understanding": 3,
            "confidence_level": 3,
            "metacog_scores": {
                "self_awareness": 3,
                "planning_ability": 2,
                "reflection_ability": 3
            }
        }
    )
    
    assert response.status_code == 200
```

### 6.2 í†µí•© í…ŒìŠ¤íŠ¸

```python
@pytest.mark.asyncio
async def test_complete_experiment_flow(client: AsyncClient):
    # 1. ë“±ë¡
    register_response = await client.post("/api/experiments/register", ...)
    participant_id = register_response.json()["participant_id"]
    
    # 2. ì‚¬ì „ ì„¤ë¬¸
    await client.post("/api/experiments/pre-survey", ...)
    
    # 3. ì‚¬ì „ í‰ê°€
    await client.post("/api/experiments/assessment-response", ...)
    
    # 4. ìƒíƒœ í™•ì¸
    status_response = await client.get(f"/api/experiments/status/{participant_id}")
    assert status_response.json()["current_step"] == "week1_usage"
```

---

ì´ ë¡œë“œë§µì€ A/B í…ŒìŠ¤íŠ¸ ì‹œìŠ¤í…œì˜ ì™„ì „í•œ êµ¬í˜„ì„ ìœ„í•œ ê¸°ìˆ ì  ê°€ì´ë“œë¥¼ ì œê³µí•©ë‹ˆë‹¤.
ê° ë‹¨ê³„ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ì§„í–‰í•˜ë©°, ì§€ì†ì ì¸ í…ŒìŠ¤íŠ¸ì™€ í”¼ë“œë°±ì„ í†µí•´ í’ˆì§ˆì„ í™•ë³´í•©ë‹ˆë‹¤.

