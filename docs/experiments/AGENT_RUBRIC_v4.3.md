# 수학 학습 세션 평가 루브릭 (v4.3 체크리스트)

## 평가 개요
- **평가 대상**: 학생 질문(15점), AI 응답(15점), 대화 맥락(10점)
- **전체 총점**: 40점 만점 (C1 명료화 항목 제외)
- **방식**: 체크리스트 - 각 항목당 4개 요소를 0/1로 체크
- **점수 산정**: 충족 요소 개수 + 1 (0개=1점, 1개=2점, 2개=3점, 3개=4점, 4개=5점)

---

## A. 학생 질문 평가 (15점 만점)

### A1. 수학적 전문성

다음 **4가지 요소**를 체크하세요 (0=미충족, 1=충족):
- A1-1. ☐ **concept_accuracy** (수학적 개념/원리의 정확성): 수학 용어를 정확하게 사용했는가?
- A1-2. ☐ **curriculum_hierarchy** (교과과정 내 위계성 파악): 학년 수준에 맞는 개념인가?
- A1-3. ☐ **terminology_appropriateness** (수학적 용어 사용의 적절성): 전문 용어를 적절히 사용했는가?
- A1-4. ☐ **problem_direction_specificity** (문제해결 방향의 구체성): 해결하려는 문제가 구체적인가?

### A2. 질문 구조화

다음 **4가지 요소**를 체크하세요 (0=미충족, 1=충족):
- A2-1. ☐ **question_singularity** (핵심 질문의 단일성): 한 번에 하나의 명확한 질문을 하는가?
- A2-2. ☐ **condition_completeness** (조건 제시의 완결성): 필요한 조건/정보를 모두 제시했는가?
- A2-3. ☐ **sentence_logic** (문장 구조의 논리성): 문장이 논리적으로 구성되었는가?
- A2-4. ☐ **intent_clarity** (질문 의도의 명시성): 무엇을 알고 싶은지 명확한가?

### A3. 학습 맥락 적용

다음 **4가지 요소**를 체크하세요 (0=미충족, 1=충족):
- A3-1. ☐ **current_stage_description** (현재 학습 단계 설명): 학년/단원/진도를 언급했는가?
- A3-2. ☐ **prior_learning_mention** (선수학습 내용 언급): 이전에 배운 내용을 언급했는가?
- A3-3. ☐ **difficulty_specification** (구체적 어려움 명시): 어디서 막혔는지 구체적으로 말했는가?
- A3-4. ☐ **learning_goal_presentation** (학습 목표 제시): 무엇을 배우고 싶은지 목표를 제시했는가?

---

## B. AI 응답 평가 (15점 만점)

### B1. 학습자 맞춤도

다음 **4가지 요소**를 체크하세요 (0=미충족, 1=충족):
- B1-1. ☐ **level_based_approach** (학습자 수준별 접근): 학생 수준에 맞게 설명했는가?
- B1-2. ☐ **prior_knowledge_connection** (선수지식 연계성): 이미 배운 내용과 연결했는가?
- B1-3. ☐ **difficulty_adjustment** (학습 난이도 조절): 너무 어렵거나 쉽지 않은가?
- B1-4. ☐ **personalized_feedback** (개인화된 피드백): 학생 상황을 고려한 피드백인가?

### B2. 설명의 체계성

다음 **4가지 요소**를 체크하세요 (0=미충족, 1=충족):
- B2-1. ☐ **concept_hierarchy** (개념 설명의 위계화): 쉬운 것부터 어려운 것으로 단계적으로 설명했는가?
- B2-2. ☐ **stepwise_logic** (단계별 논리 전개): 각 단계가 논리적으로 연결되는가?
- B2-3. ☐ **key_emphasis** (핵심 요소 강조): 중요한 내용을 명확히 강조했는가?
- B2-4. ☐ **example_appropriateness** (예시 활용의 적절성): 이해를 돕는 적절한 예시를 제공했는가?

### B3. 학습 내용 확장성

다음 **4가지 요소**를 체크하세요 (0=미충족, 1=충족):
- B3-1. ☐ **advanced_direction** (심화학습 방향 제시): 더 깊이 공부할 방향을 제시했는가?
- B3-2. ☐ **application_connection** (응용문제 연계성): 관련된 응용 문제를 연결했는가?
- B3-3. ☐ **misconception_correction** (오개념 교정 전략): 잘못된 이해를 바로잡았는가?
- B3-4. ☐ **self_directed_induction** (자기주도 학습 유도): 스스로 탐구하도록 유도했는가?

---

## C. 대화 맥락 평가 (10점 만점)

**주의**: 원래 C1(명료화 효과성) 항목은 Agent 모드에 구조적으로 유리하므로 공정한 비교를 위해 제외했습니다.

### C1. 대화 일관성 및 연속성

다음 **4가지 요소**를 체크하세요 (0=미충족, 1=충족):
- C1-1. ☐ **goal_centered_consistency** (학습 목표 중심 일관성): 학습 목표를 벗어나지 않고 진행되는가?
- C1-2. ☐ **context_reference** (이전 맥락 참조): 이전 대화 내용을 참조하는가?
- C1-3. ☐ **topic_continuity** (주제 연속성): 주제가 자연스럽게 연결되는가?
- C1-4. ☐ **previous_turn_connection** (이전 턴 연결성): 각 턴이 이전 턴과 논리적으로 연결되는가?

### C2. 학습 과정 지원성

다음 **4가지 요소**를 체크하세요 (0=미충족, 1=충족):
- C2-1. ☐ **thinking_process_induction** (사고 과정 유도): 학생의 사고 과정을 유도하는가?
- C2-2. ☐ **understanding_check** (이해도 확인): 학생의 이해도를 확인하는가?
- C2-3. ☐ **metacognitive_promotion** (메타인지 촉진): 학생이 자신의 학습 과정을 돌아보게 하는가?
- C2-4. ☐ **deep_thinking_guidance** (깊이 있는 사고 유도): 단순 암기를 넘어 깊이 있는 사고를 유도하는가?

---

## 평가 지침

- 각 세부 요소는 **0 (미충족)** 또는 **1 (충족)**로만 체크
- 세션 전체에서 **가장 우수한 질문** 기준으로 A 영역 평가
- 각 요소마다 간단한 근거(evidence)를 한 문장으로 기록
- 점수 합산은 시스템이 자동으로 처리

## JSON 출력 형식

```json
{
  "A1_math_expertise": {
    "concept_accuracy": {"value": 1, "evidence": "귀납법 용어 정확"},
    "curriculum_hierarchy": {"value": 0, "evidence": "학년 미언급"},
    "terminology_appropriateness": {"value": 1, "evidence": "용어 적절"},
    "problem_direction_specificity": {"value": 1, "evidence": "증명 목표 명확"}
  },
  ...
}
```

## 체크리스트 요소 전체 목록 (32개)

### A 영역 (학생 질문, 12개 요소)
1. A1-1: concept_accuracy
2. A1-2: curriculum_hierarchy
3. A1-3: terminology_appropriateness
4. A1-4: problem_direction_specificity
5. A2-1: question_singularity
6. A2-2: condition_completeness
7. A2-3: sentence_logic
8. A2-4: intent_clarity
9. A3-1: current_stage_description
10. A3-2: prior_learning_mention
11. A3-3: difficulty_specification
12. A3-4: learning_goal_presentation

### B 영역 (AI 응답, 12개 요소)
13. B1-1: level_based_approach
14. B1-2: prior_knowledge_connection
15. B1-3: difficulty_adjustment
16. B1-4: personalized_feedback
17. B2-1: concept_hierarchy
18. B2-2: stepwise_logic
19. B2-3: key_emphasis
20. B2-4: example_appropriateness
21. B3-1: advanced_direction
22. B3-2: application_connection
23. B3-3: misconception_correction
24. B3-4: self_directed_induction

### C 영역 (대화 맥락, 8개 요소)
25. C1-1: goal_centered_consistency
26. C1-2: context_reference
27. C1-3: topic_continuity
28. C1-4: previous_turn_connection
29. C2-1: thinking_process_induction
30. C2-2: understanding_check
31. C2-3: metacognitive_promotion
32. C2-4: deep_thinking_guidance

---

## 버전 비교

| 버전 | 총점 | 항목 수 | C1 명료화 | 방식 | 특징 |
|------|------|---------|----------|------|------|
| v4.0 | 45점 | 9개 | 포함 | 5점 척도 | Agent 편향 존재 |
| v4.1 | 40점 | 8개 | 제외 | 5점 척도 | 편향 제거, 여전히 주관적 |
| v4.2 | 40점 | 8개 | 제외 | 체크리스트 | 객관성 향상, 자동 합산 |
| **v4.3** | 40점 | 8개 | 제외 | 체크리스트+근거 | **투명성 극대화, 근거 추적 가능** ✅ |

