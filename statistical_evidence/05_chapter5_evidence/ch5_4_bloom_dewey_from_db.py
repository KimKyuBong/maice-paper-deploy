#!/usr/bin/env python3
"""
5ì¥ 4ì ˆ: Bloom-Dewey ì´ë¡  ì‹¤ì¦ ë¶„ì„ (DB ë°ì´í„° ê¸°ë°˜)

ëª©ì : í‘œâ…¤-23, â…¤-25, â…¤-26 ê³„ì‚°ìš© ì›ë³¸ ë°ì´í„° ì¶”ì¶œ
- DB ë¡œê·¸ 1,589ê±´ í™•ì¸ ë° ì¶”ì¶œ
- LLM í‰ê°€ì ìˆ˜ì™€ ë§¤ì¹­
- Bloom/Dewey ë¶„ì„ì„ ìœ„í•œ ê¸°ë³¸ ë°ì´í„° ì œê³µ
"""

import pandas as pd
import json
from pathlib import Path

print("="*80)
print("5ì¥ 4ì ˆ: Bloom-Dewey ì´ë¡  ì‹¤ì¦ ë¶„ì„")
print("DB ë¡œê·¸ ë°ì´í„° í™•ì¸ ë° ì¶”ì¶œ")
print("="*80)
print()

BASE_DIR = Path(__file__).parent.parent

# ë°ì´í„° ë¡œë“œ
DB_LOGS_FILE = BASE_DIR / "data" / "db_exports" / "public_llm_prompt_logs_full.csv"
DB_RESPONSE_FILE = BASE_DIR / "data" / "db_exports" / "public_llm_response_logs_full.csv"
LLM_FILE = BASE_DIR / "01_llm_scoring" / "results" / "llm_3models_averaged_perfect.csv"
SESSION_FILE = BASE_DIR / "data" / "session_data" / "full_sessions_with_scores.csv"

df_logs = pd.read_csv(DB_LOGS_FILE)
df_responses = pd.read_csv(DB_RESPONSE_FILE)
df_llm = pd.read_csv(LLM_FILE)
df_session = pd.read_csv(SESSION_FILE)

print("[1] ë°ì´í„° ë¡œë“œ...")
print(f"âœ“ í”„ë¡¬í”„íŠ¸ ë¡œê·¸: {len(df_logs)}ê°œ")
print(f"âœ“ ì‘ë‹µ ë¡œê·¸: {len(df_responses)}ê°œ")
print(f"âœ“ LLM í‰ê°€: {len(df_llm)}ê°œ ì„¸ì…˜")
print(f"âœ“ ì„¸ì…˜ ë©”íƒ€: {len(df_session)}ê°œ")
print()

# ì—ì´ì „íŠ¸ë³„ ë¶„ë¥˜
print("[2] ì—ì´ì „íŠ¸ë³„ ë¶„ë¥˜...")
if 'tool_name' in df_logs.columns:
    agent_counts = df_logs['tool_name'].value_counts()
    print("í”„ë¡¬í”„íŠ¸ ë¡œê·¸ (tool_name):")
    for agent, count in agent_counts.items():
        print(f"  - {agent}: {count:,}ê±´")
elif 'agent_name' in df_logs.columns:
    agent_counts = df_logs['agent_name'].value_counts()
    print("í”„ë¡¬í”„íŠ¸ ë¡œê·¸ (agent_name):")
    for agent, count in agent_counts.items():
        print(f"  - {agent}: {count:,}ê±´")
else:
    print("âš ï¸  tool_name/agent_name ì»¬ëŸ¼ ì—†ìŒ")
print()

# ì´ ë¡œê·¸ ê±´ìˆ˜ í™•ì¸
total_logs = len(df_logs) + len(df_responses)
print(f"ì´ í”„ë¡¬í”„íŠ¸-ì‘ë‹µ ë¡œê·¸: {total_logs:,}ê±´")
print(f"  (í”„ë¡¬í”„íŠ¸: {len(df_logs):,}ê±´ + ì‘ë‹µ: {len(df_responses):,}ê±´)")
print()

# ì„¸ì…˜ ID ë§¤ì¹­ í™•ì¸
print("[3] ì„¸ì…˜ ID ë§¤ì¹­ í™•ì¸...")
log_session_ids = set(df_logs['session_id'].dropna().unique())
response_session_ids = set(df_responses['session_id'].dropna().unique())
llm_session_ids = set(df_llm['session_id'].unique())
session_meta_ids = set(df_session['session_id'].unique())

common_sessions = log_session_ids & llm_session_ids & session_meta_ids
print(f"  DB ë¡œê·¸ ì„¸ì…˜: {len(log_session_ids)}ê°œ")
print(f"  LLM í‰ê°€ ì„¸ì…˜: {len(llm_session_ids)}ê°œ")
print(f"  ì„¸ì…˜ ë©”íƒ€ ì„¸ì…˜: {len(session_meta_ids)}ê°œ")
print(f"  ê³µí†µ ì„¸ì…˜: {len(common_sessions)}ê°œ")
print()

# ê²°ê³¼ ì €ì¥
results = {
    "table": "í‘œâ…¤-23, â…¤-25, â…¤-26",
    "title": "Bloom-Dewey ì´ë¡  ì‹¤ì¦ ë¶„ì„ ì›ë³¸ ë°ì´í„°",
    "note": "ì§ˆì  ì½”ë”© ê¸°ë°˜ ë¶„ì„. DB ë¡œê·¸ë¥¼ ìˆ˜ë™ìœ¼ë¡œ Bloom/Dewey ë‹¨ê³„ ì½”ë”© í•„ìš”",
    "db_logs_summary": {
        "prompt_logs": len(df_logs),
        "response_logs": len(df_responses),
        "total_logs": total_logs,
        "unique_sessions_in_logs": len(log_session_ids),
        "common_sessions_with_llm": len(common_sessions)
    },
    "agent_distribution": agent_counts.to_dict() if 'tool_name' in df_logs.columns or 'agent_name' in df_logs.columns else {},
    "data_files": {
        "prompt_logs": str(DB_LOGS_FILE.relative_to(BASE_DIR)),
        "response_logs": str(DB_RESPONSE_FILE.relative_to(BASE_DIR)),
        "llm_scores": str(LLM_FILE.relative_to(BASE_DIR)),
        "session_metadata": str(SESSION_FILE.relative_to(BASE_DIR))
    },
    "analysis_note": {
        "bloom_coding": "237ê±´ ë‹µë³€(answer_generator_llm)ì„ Bloom ë‹¨ê³„ë¡œ ìˆ˜ë™ ì½”ë”©",
        "dewey_tracking": "ëŒ€í™” íë¦„ì„ Dewey 5ë‹¨ê³„ë¡œ ì¶”ì  (278ê±´ ëª…ë£Œí™” ì§ˆë¬¸)",
        "score_matching": "LLM í‰ê°€ì ìˆ˜ì™€ ëŒ€í™” ë¡œê·¸ ë§¤ì¹­í•˜ì—¬ ì ìˆ˜ êµ¬ê°„ë³„ ë¶„ì„"
    }
}

OUTPUT_DIR = Path(__file__).parent / "results"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

output_file = OUTPUT_DIR / "ch5_4_bloom_dewey_from_db.json"
with open(output_file, 'w', encoding='utf-8') as f:
    json.dump(results, f, ensure_ascii=False, indent=2, default=str)

# ì›ë³¸ ë°ì´í„°ë„ ì €ì¥ (ë¶„ì„ìš©)
df_logs_merged = pd.merge(
    df_logs,
    df_llm[['session_id', 'avg_overall']],
    on='session_id',
    how='left'
)

output_csv = OUTPUT_DIR / "llm_prompt_logs_with_scores.csv"
df_logs_merged.to_csv(output_csv, index=False, encoding='utf-8')
print(f"âœ“ ì ìˆ˜ ë§¤ì¹­ëœ í”„ë¡¬í”„íŠ¸ ë¡œê·¸ ì €ì¥: {output_csv}")
print()

print(f"âœ“ ê²°ê³¼ ì €ì¥: {output_file}")
print()
print("ğŸ“Œ Bloom/Dewey ë¶„ì„ì€ DB ë¡œê·¸ë¥¼ ì§ˆì  ì½”ë”©í•˜ëŠ” ë³„ë„ í”„ë¡œì„¸ìŠ¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
print("="*80)


