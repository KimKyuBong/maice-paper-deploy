#!/usr/bin/env python3
"""
êµì‚¬ ì±„ì ì ìˆ˜ ì²˜ë¦¬ ë° ê²€ì¦

ë…¼ë¬¸ 5ì¥ 2ì ˆ ë‹¤í•­ "êµì‚¬ í‰ê°€ (N=100)"ì—ì„œ ì‚¬ìš©ëœ êµì‚¬ í‰ê°€ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. êµì‚¬ 2ëª…(ID: 96, 97) í‰ê°€ ë°ì´í„° ë¡œë“œ
2. ë™ì¼ ì„¸ì…˜ ëŒ€ì‘ í™•ì¸
3. í‰ê°€ìë³„ ê¸°ìˆ í†µê³„
4. ì˜ì—­ë³„ ì ìˆ˜ ê³„ì‚°

ê·¼ê±°:
- ë…¼ë¬¸ 5ì¥ 2ì ˆ ë‹¤í•­(1) "í‰ê°€ ì„¤ê³„"
- í‘œâ…¤-8: êµì‚¬ í‰ê°€ ì„¤ê³„
- í‘œâ…¤-9: ëª¨ë“œë³„ ì ìˆ˜ ë¹„êµ
"""

import json
import pandas as pd
import numpy as np
from pathlib import Path
import sys

print("="*80)
print("êµì‚¬ ì±„ì ì ìˆ˜ ì²˜ë¦¬ ë° ê²€ì¦")
print("="*80)
print()

# ê²½ë¡œ ì„¤ì •
BASE_PATH = Path(__file__).parent.parent / "data"
OUTPUT_PATH = Path(__file__).parent / "results"
OUTPUT_PATH.mkdir(exist_ok=True)

# ============================================================================
# 1. ë°ì´í„° ë¡œë“œ
# ============================================================================

print("1. êµì‚¬ í‰ê°€ ë°ì´í„° ë¡œë“œ")
print("-" * 80)

# êµì‚¬ í‰ê°€ ë°ì´í„° íŒŒì¼
teacher_file = BASE_PATH / "teacher_evaluations" / "latest_evaluations.json"

if not teacher_file.exists():
    print(f"âš ï¸  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {teacher_file}")
    sys.exit(1)

with open(teacher_file, 'r', encoding='utf-8') as f:
    teacher_data = json.load(f)

df = pd.DataFrame(teacher_data)

print(f"âœ“ ì´ í‰ê°€ ë ˆì½”ë“œ: {len(df)}ê°œ")
print()

# í‰ê°€ì í™•ì¸
evaluators = sorted(df['evaluated_by'].unique())
print(f"í‰ê°€ì: {evaluators}")

for evaluator in evaluators:
    count = len(df[df['evaluated_by'] == evaluator])
    sessions = df[df['evaluated_by'] == evaluator]['conversation_session_id'].nunique()
    print(f"  êµì‚¬ {evaluator}: {count}ê°œ ë ˆì½”ë“œ, {sessions}ê°œ ì„¸ì…˜")

print()

# ============================================================================
# 2. êµì‚¬ 96, 97ë§Œ í•„í„°ë§
# ============================================================================

print("2. êµì‚¬ 96, 97 ë°ì´í„° í•„í„°ë§")
print("-" * 80)

# ë…¼ë¬¸ì—ì„œëŠ” êµì‚¬ 96, 97ë§Œ ì‚¬ìš©
df_filtered = df[df['evaluated_by'].isin([96, 97])].copy()

print(f"í•„í„°ë§ í›„: {len(df_filtered)}ê°œ ë ˆì½”ë“œ")

evaluators_96_97 = sorted(df_filtered['evaluated_by'].unique())
for evaluator in evaluators_96_97:
    count = len(df_filtered[df_filtered['evaluated_by'] == evaluator])
    sessions = df_filtered[df_filtered['evaluated_by'] == evaluator]['conversation_session_id'].nunique()
    print(f"  êµì‚¬ {evaluator}: {count}ê°œ ë ˆì½”ë“œ, {sessions}ê°œ ì„¸ì…˜")

print()

# ============================================================================
# 3. ë™ì¼ ì„¸ì…˜ ëŒ€ì‘ í™•ì¸ (ì™„ì „í•œ ëŒ€ì‘ ì„¤ê³„)
# ============================================================================

print("3. ë™ì¼ ì„¸ì…˜ ëŒ€ì‘ í™•ì¸")
print("-" * 80)

sessions_96 = set(df_filtered[df_filtered['evaluated_by'] == 96]['conversation_session_id'])
sessions_97 = set(df_filtered[df_filtered['evaluated_by'] == 97]['conversation_session_id'])

common_sessions = sessions_96 & sessions_97

print(f"êµì‚¬ 96 í‰ê°€ ì„¸ì…˜: {len(sessions_96)}ê°œ")
print(f"êµì‚¬ 97 í‰ê°€ ì„¸ì…˜: {len(sessions_97)}ê°œ")
print(f"ê³µí†µ í‰ê°€ ì„¸ì…˜: {len(common_sessions)}ê°œ")
print()

if len(common_sessions) == len(sessions_96) == len(sessions_97):
    print("âœ“ ì™„ì „í•œ ëŒ€ì‘ ì„¤ê³„ í™•ì¸ (ë™ì¼ ì„¸ì…˜ ë…ë¦½ í‰ê°€)")
else:
    print("âš ï¸  ëŒ€ì‘ ì„¤ê³„ ë¶ˆì™„ì „: ì¼ë¶€ ì„¸ì…˜ì´ í•œ ëª…ì—ê²Œë§Œ í‰ê°€ë¨")

print()

# ê³µí†µ ì„¸ì…˜ë§Œ í•„í„°ë§
df_matched = df_filtered[df_filtered['conversation_session_id'].isin(common_sessions)].copy()

print(f"ëŒ€ì‘ ì„¤ê³„ ë°ì´í„°: {len(df_matched)}ê°œ ë ˆì½”ë“œ ({len(common_sessions)} Ã— 2)")
print()

# ============================================================================
# 4. ì ìˆ˜ í•­ëª© ì •ì˜ ë° ê³„ì‚°
# ============================================================================

print("4. ì˜ì—­ë³„ ì ìˆ˜ ê³„ì‚°")
print("-" * 80)

# ë£¨ë¸Œë¦­ í•­ëª© ì •ì˜
score_columns = {
    'ì§ˆë¬¸': ['question_professionalism_score', 'question_structuring_score', 
              'question_context_application_score', 'question_total_score'],
    'ì‘ë‹µ': ['answer_customization_score', 'answer_systematicity_score',
              'answer_expandability_score', 'response_total_score'],
    'ë§¥ë½': ['context_dialogue_coherence_score', 'context_learning_support_score',
              'context_total_score'],
    'ì¢…í•©': ['overall_score']
}

# ìˆ«ì ë³€í™˜
numeric_columns = [
    'question_professionalism_score',
    'question_structuring_score',
    'question_context_application_score',
    'question_total_score',
    'answer_customization_score',
    'answer_systematicity_score',
    'answer_expandability_score',
    'response_total_score',
    'context_dialogue_coherence_score',
    'context_learning_support_score',
    'context_total_score',
    'overall_score'
]

for col in numeric_columns:
    df_matched[col] = pd.to_numeric(df_matched[col], errors='coerce')

# ê¸°ìˆ í†µê³„ ì¶œë ¥
for area, cols in score_columns.items():
    if area == 'ì¢…í•©':
        col = 'overall_score'
    else:
        col = [c for c in cols if '_total_' in c][0]
    
    print(f"\nã€{area} ì˜ì—­ã€‘")
    for evaluator in [96, 97]:
        data = df_matched[df_matched['evaluated_by'] == evaluator][col]
        print(f"  êµì‚¬ {evaluator}: M={data.mean():.2f}, SD={data.std():.2f}, "
              f"Min={data.min():.0f}, Max={data.max():.0f}")

print()

# ============================================================================
# 5. í‰ê·  ì ìˆ˜ ê³„ì‚° (2ëª… í‰ê· )
# ============================================================================

print("5. êµì‚¬ 2ëª… í‰ê·  ê³„ì‚°")
print("-" * 80)

# ì„¸ì…˜ë³„ë¡œ êµì‚¬ 2ëª… í‰ê·  ê³„ì‚°
averaged_data = []

for session_id in common_sessions:
    session_data = df_matched[df_matched['conversation_session_id'] == session_id]
    
    if len(session_data) != 2:
        continue
    
    # 2ëª…ì˜ ì ìˆ˜ í‰ê· 
    avg_record = {'conversation_session_id': session_id}
    
    for col in numeric_columns:
        scores = session_data[col].values
        avg_record[col] = np.mean(scores)
    
    averaged_data.append(avg_record)

df_averaged = pd.DataFrame(averaged_data)

print(f"âœ“ {len(df_averaged)}ê°œ ì„¸ì…˜ì— ëŒ€í•´ êµì‚¬ 2ëª… í‰ê·  ê³„ì‚° ì™„ë£Œ")
print()

# í‰ê·  ì ìˆ˜ ê¸°ìˆ í†µê³„
print("êµì‚¬ 2ëª… í‰ê·  ì ìˆ˜ ê¸°ìˆ í†µê³„:")
print("-" * 80)

for area, cols in score_columns.items():
    if area == 'ì¢…í•©':
        col = 'overall_score'
    else:
        col = [c for c in cols if '_total_' in c][0]
    
    data = df_averaged[col]
    print(f"{area:6s}: M={data.mean():.2f}, SD={data.std():.2f}, "
          f"Min={data.min():.2f}, Max={data.max():.2f}")

print()

# ============================================================================
# 6. ê²°ê³¼ ì €ì¥
# ============================================================================

print("6. ê²°ê³¼ ì €ì¥")
print("-" * 80)

# ì›ë³¸ ë§¤ì¹­ ë°ì´í„° (êµì‚¬ë³„)
matched_csv = OUTPUT_PATH / "teacher_matched_scores.csv"
df_matched.to_csv(matched_csv, index=False, encoding='utf-8-sig')
print(f"âœ“ êµì‚¬ë³„ ë§¤ì¹­ ì ìˆ˜ ì €ì¥: {matched_csv}")

# 2ëª… í‰ê·  ë°ì´í„°
averaged_csv = OUTPUT_PATH / "teacher_averaged_scores.csv"
df_averaged.to_csv(averaged_csv, index=False, encoding='utf-8-sig')
print(f"âœ“ êµì‚¬ 2ëª… í‰ê·  ì ìˆ˜ ì €ì¥: {averaged_csv}")

# ìš”ì•½ í†µê³„
summary = {
    'n_teachers': 2,
    'teacher_ids': [96, 97],
    'n_common_sessions': len(common_sessions),
    'n_total_records': len(df_matched),
    'score_categories': list(score_columns.keys()),
    'descriptive_stats': {
        area: {
            'mean': float(df_averaged[[c for c in cols if '_total_' in c or c == 'overall_score'][0]].mean()),
            'std': float(df_averaged[[c for c in cols if '_total_' in c or c == 'overall_score'][0]].std()),
            'min': float(df_averaged[[c for c in cols if '_total_' in c or c == 'overall_score'][0]].min()),
            'max': float(df_averaged[[c for c in cols if '_total_' in c or c == 'overall_score'][0]].max())
        }
        for area, cols in score_columns.items()
    }
}

summary_json = OUTPUT_PATH / "teacher_score_summary.json"
with open(summary_json, 'w', encoding='utf-8') as f:
    json.dump(summary, f, ensure_ascii=False, indent=2)
print(f"âœ“ ìš”ì•½ í†µê³„ ì €ì¥: {summary_json}")

print()
print("="*80)
print("êµì‚¬ ì±„ì ì ìˆ˜ ì²˜ë¦¬ ì™„ë£Œ!")
print("="*80)
print()
print(f"ğŸ“Š ìµœì¢… ë°ì´í„°ì…‹: N={len(common_sessions)} (êµì‚¬ 2ëª… ì™„ì „ ëŒ€ì‘)")
print(f"ğŸ‘¥ í‰ê°€ì: êµì‚¬ 96, 97 (ì™¸ë¶€ ìˆ˜í•™ êµì‚¬)")
print(f"ğŸ“‹ í‰ê°€ ì˜ì—­: 4ê°œ (ì§ˆë¬¸, ì‘ë‹µ, ë§¥ë½, ì¢…í•©)")
print()

