# LLM-교사 평가 일치도 검증 보고서

**분석 일시**: 2025-11-17

## 1. 분석 개요

- **목적**: LLM 평가와 교사 평가 간의 일치도 검증
- **방법**: Pearson 상관계수, Spearman 상관계수
- **공통 세션**: N=100
- **LLM**: 3개 모델 평균 (Gemini 2.5 Flash, Claude 4.5 Haiku, GPT-5-mini)
- **교사**: 2명 평균 (평가자 96, 97)

## 2. 대분류 상관관계 (영역별)

### 2.1 전체 결과

| 영역 | LLM 평균 (SD) | 교사 평균 (SD) | 차이 | Pearson r | Spearman ρ | p-value | 해석 |
|-----|:------------:|:-------------:|:----:|:---------:|:----------:|:-------:|:----:|
| **A. 질문 (/15)** | 9.54 (1.90) | 7.78 (2.71) | +1.76 | **0.682*** | 0.586*** | <0.001 | 강한 상관 |
| **B. 답변 (/15)** | 9.93 (2.73) | 7.86 (2.69) | +2.07 | **0.735*** | 0.635*** | <0.001 | 강한 상관 |
| **C. 맥락 (/10)** | 6.60 (1.40) | 4.96 (1.79) | +1.63 | **0.653*** | 0.639*** | <0.001 | 강한 상관 |
| **전체 (/40)** | 26.06 (5.40) | 20.61 (6.52) | +5.46 | **0.754*** | 0.622*** | <0.001 | 강한 상관 |

### 2.2 주요 발견

1. **전체 점수 상관**: r=0.754*** - 매우 강한 양의 상관관계
2. **영역별 상관**: 모든 영역에서 r > 0.65, 강한 상관관계 유지
3. **답변 영역 최고**: r=0.735*** - LLM과 교사의 평가 기준이 가장 일치
4. **맥락 영역 상대적 낮음**: r=0.653*** - 교육적 의도 해석 차이 가능성

### 2.3 LLM 과대평가 경향

- **전체**: LLM이 교사보다 평균 +5.46점 높게 평가 (40점 만점 대비 13.7%)
- **영역별 차이**:
  - 답변 영역: +2.07점 (최대)
  - 질문 영역: +1.76점
  - 맥락 영역: +1.63점

## 3. 중분류 상관관계 (8개 항목별)

| 항목 | 코드 | Pearson r | p-value | 일치도 수준 |
|-----|:----:|:---------:|:-------:|:----------:|
| **B1 학습자 맞춤도** | B1 | **0.751*** | <0.001 | 매우 높음 |
| **B2 설명 체계성** | B2 | **0.738*** | <0.001 | 높음 |
| **A1 수학 전문성** | A1 | **0.690*** | <0.001 | 높음 |
| A2 질문 구조화 | A2 | 0.602*** | <0.001 | 중간-높음 |
| C1 대화 일관성 | C1 | 0.592*** | <0.001 | 중간-높음 |
| C2 학습 지원 | C2 | 0.522*** | <0.001 | 중간 |
| A3 학습 맥락 | A3 | 0.512*** | <0.001 | 중간 |
| B3 학습 확장성 | B3 | 0.462*** | <0.001 | 중간 |

### 3.1 항목별 해석

**높은 일치도 항목 (r > 0.70)**:
- B1 학습자 맞춤도 (0.751): 학생 수준에 맞는 설명 제공 여부는 LLM과 교사가 매우 유사하게 판단
- B2 설명 체계성 (0.738): 논리적 구조와 체계성은 객관적 판단 가능

**중간 일치도 항목 (0.50 < r < 0.70)**:
- A1, A2: 수학 전문성과 질문 구조화는 비교적 명확한 기준
- C1, C2: 대화 일관성과 학습 지원은 해석 차이 가능
- A3: 학습 맥락 파악은 교사의 교육적 통찰 필요

**상대적 낮은 일치도 항목 (r < 0.50)**:
- B3 학습 확장성 (0.462): 심화 학습 유도는 교육적 의도 해석 차이가 큼

## 4. 통계적 유의성

- **모든 상관계수**: p < 0.001 (매우 유의함)
- **표본 크기**: N=100 (충분한 검정력)
- **신뢰구간**: 95% CI 기준 모든 상관계수 유의함

## 5. 종합 평가

### 5.1 타당성 확보

✅ **강한 전체 상관** (r=0.754***): LLM 평가가 교사 평가와 높은 일치도를 보임
✅ **모든 영역 유의**: 질문, 답변, 맥락 영역 모두 강한 양의 상관
✅ **항목별 일관성**: 8개 항목 모두 통계적으로 매우 유의한 상관
✅ **방향성 일치**: 모든 항목에서 양의 상관관계 유지

### 5.2 제한점

⚠️ **LLM 과대평가 경향**: 평균 +5.46점 (13.7%) 높게 평가
⚠️ **교육적 의도 항목 낮음**: B3, C2, A3 상대적으로 낮은 일치도
⚠️ **표본 크기**: N=100은 예비 연구 수준, 더 큰 표본 필요

### 5.3 결론

**LLM 평가는 교사 평가와 강한 상관관계(r=0.754***)를 보여, 대규모 평가 도구로서의 타당성을 확보하였다.**

- ✅ 전문가(교사) 평가와의 수렴 검증 완료
- ✅ 영역별, 항목별 모두 통계적으로 유의한 일치
- ⚠️ 과대평가 경향과 교육적 의도 항목에서의 해석 차이 고려 필요
- 📊 후속 연구: 더 많은 평가자, 더 큰 표본으로 재검증 필요

## 6. 근거 자료

### 6.1 데이터 파일

- LLM 평가: `statistical_evidence/01_llm_scoring/results/llm_3models_averaged_perfect.csv` (284 세션)
- 교사 평가: `statistical_evidence/02_teacher_scoring/results/teacher_averaged_scores_perfect.csv` (100 세션)
- 병합 데이터: `statistical_evidence/03_correlation_analysis/results/llm_teacher_merged_perfect.csv` (100 세션)

### 6.2 결과 파일

- 대분류 상관: `llm_teacher_correlations_perfect.json`
- 중분류 상관: `llm_teacher_mid_correlations_perfect.json`
- 요약: `correlation_summary_perfect.json`

### 6.3 분석 스크립트

- 계산 파일: `statistical_evidence/03_correlation_analysis/llm_teacher_correlation_perfect.py`

---

**보고서 생성**: 2025-11-17
**분석자**: 자동 생성 시스템


