#!/usr/bin/env python3
"""
LLM ëª¨ë¸ë³„ Ã— êµì‚¬ë³„ ìƒê´€ê´€ê³„ ì™„ì „ ë§¤íŠ¸ë¦­ìŠ¤
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ê³„ì‚°:
  - LLM: OpenAI, Anthropic, Gemini, 3ëª¨ë¸ í‰ê· 
  - êµì‚¬: 96, 97, 2ëª… í‰ê· 
  - ì „ì²´ ì¡°í•© ë§¤íŠ¸ë¦­ìŠ¤
"""

import pandas as pd
from scipy import stats
from pathlib import Path
import json

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. ë°ì´í„° ë¡œë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BASE_DIR = Path(__file__).parent.parent.parent
DATA_DIR = BASE_DIR / 'data'
OUTPUT_DIR = BASE_DIR / 'scripts' / 'verification'

print("=" * 80)
print("ğŸ“Š LLM-êµì‚¬ ìƒê´€ê´€ê³„ ì™„ì „ ë§¤íŠ¸ë¦­ìŠ¤")
print("=" * 80)

# LLM ë°ì´í„°
df_llm = pd.read_csv(DATA_DIR / 'llm_evaluations' / 'llm_284sessions_complete.csv')

# ê° ëª¨ë¸ë³„ Total ê³„ì‚°
for model in ['gemini', 'anthropic', 'openai']:
    cols = [f'{model}_A1', f'{model}_A2', f'{model}_A3', 
            f'{model}_B1', f'{model}_B2', f'{model}_B3', 
            f'{model}_C1', f'{model}_C2']
    df_llm[f'{model}_total'] = df_llm[cols].sum(axis=1)

# 3ëª¨ë¸ í‰ê· 
df_llm['avg_total'] = df_llm['avg_overall']

# êµì‚¬ ë°ì´í„°
df_teacher = pd.read_csv(DATA_DIR / 'analysis_results' / 'three_teachers_100_sessions.csv')
df_teacher_96_97 = df_teacher[df_teacher['evaluator'].isin([96, 97])]

print(f"\nâœ“ LLM ë°ì´í„°: {len(df_llm)} ì„¸ì…˜")
print(f"âœ“ êµì‚¬ ë°ì´í„°: {len(df_teacher_96_97)} í–‰ (êµì‚¬ 96, 97)")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. êµì‚¬ë³„ ë°ì´í„° ì¤€ë¹„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# êµì‚¬ 96
teacher_96 = df_teacher_96_97[df_teacher_96_97['evaluator'] == 96][['session_id', 'overall']]
teacher_96.columns = ['session_id', 'teacher_96']

# êµì‚¬ 97
teacher_97 = df_teacher_96_97[df_teacher_96_97['evaluator'] == 97][['session_id', 'overall']]
teacher_97.columns = ['session_id', 'teacher_97']

# êµì‚¬ 2ëª… í‰ê· 
teacher_avg = df_teacher_96_97.groupby('session_id')['overall'].mean().reset_index()
teacher_avg.columns = ['session_id', 'teacher_avg']

print(f"\nâœ“ êµì‚¬ 96: {len(teacher_96)} ì„¸ì…˜")
print(f"âœ“ êµì‚¬ 97: {len(teacher_97)} ì„¸ì…˜")
print(f"âœ“ êµì‚¬ í‰ê· : {len(teacher_avg)} ì„¸ì…˜")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. ì™„ì „ ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ğŸ“Š ì™„ì „ ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤")
print("=" * 80)

llm_models = [
    ('OpenAI', 'openai_total'),
    ('Anthropic', 'anthropic_total'),
    ('Gemini', 'gemini_total'),
    ('LLM 3ëª¨ë¸ í‰ê· ', 'avg_total')
]

teachers = [
    ('êµì‚¬ 96', teacher_96, 'teacher_96'),
    ('êµì‚¬ 97', teacher_97, 'teacher_97'),
    ('êµì‚¬ 2ëª… í‰ê· ', teacher_avg, 'teacher_avg')
]

results = []

for llm_name, llm_col in llm_models:
    print(f"\n{llm_name}:")
    print("-" * 80)
    
    for teacher_name, teacher_df, teacher_col in teachers:
        # ë³‘í•©
        merged = pd.merge(df_llm[['session_id', llm_col]], teacher_df, on='session_id', how='inner')
        
        if len(merged) > 0:
            # ìƒê´€ê³„ìˆ˜
            r, p = stats.pearsonr(merged[llm_col], merged[teacher_col])
            
            results.append({
                'LLM': llm_name,
                'êµì‚¬': teacher_name,
                'N': len(merged),
                'Pearson_r': round(r, 3),
                'p': '<0.001' if p < 0.001 else round(p, 3)
            })
            
            print(f"  {teacher_name:15s}: N={len(merged):3d}, r={r:.3f}, p={p:.6f}")
        else:
            print(f"  {teacher_name:15s}: ë°ì´í„° ì—†ìŒ")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. ê²°ê³¼ ì •ë¦¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

df_results = pd.DataFrame(results)

print("\n" + "=" * 80)
print("ğŸ“‹ ì „ì²´ ê²°ê³¼ í‘œ")
print("=" * 80)
print(df_results.to_string(index=False))

# í”¼ë²— í…Œì´ë¸”
pivot = df_results.pivot(index='LLM', columns='êµì‚¬', values='Pearson_r')

print("\n" + "=" * 80)
print("ğŸ“Š í”¼ë²— í…Œì´ë¸” (ìƒê´€ê³„ìˆ˜)")
print("=" * 80)
print(pivot)

# ì €ì¥
df_results.to_csv(OUTPUT_DIR / 'LLM_TEACHER_CORRELATION_MATRIX.csv', 
                  index=False, encoding='utf-8-sig')

pivot.to_csv(OUTPUT_DIR / 'LLM_TEACHER_CORRELATION_PIVOT.csv', 
             encoding='utf-8-sig')

# JSONìœ¼ë¡œë„ ì €ì¥
results_dict = {
    'full_matrix': results,
    'summary': {
        'highest_correlation': df_results.loc[df_results['Pearson_r'].idxmax()].to_dict(),
        'lowest_correlation': df_results.loc[df_results['Pearson_r'].idxmin()].to_dict(),
        'avg_3model_avg_2teacher': df_results[
            (df_results['LLM'] == 'LLM 3ëª¨ë¸ í‰ê· ') & 
            (df_results['êµì‚¬'] == 'êµì‚¬ 2ëª… í‰ê· ')
        ].iloc[0].to_dict() if len(df_results[
            (df_results['LLM'] == 'LLM 3ëª¨ë¸ í‰ê· ') & 
            (df_results['êµì‚¬'] == 'êµì‚¬ 2ëª… í‰ê· ')
        ]) > 0 else None
    }
}

with open(OUTPUT_DIR / 'LLM_TEACHER_CORRELATION_FULL.json', 'w', encoding='utf-8') as f:
    json.dump(results_dict, f, ensure_ascii=False, indent=2)

print("\n" + "=" * 80)
print("âœ… ì €ì¥ ì™„ë£Œ!")
print("=" * 80)
print(f"\níŒŒì¼:")
print(f"  - LLM_TEACHER_CORRELATION_MATRIX.csv")
print(f"  - LLM_TEACHER_CORRELATION_PIVOT.csv")
print(f"  - LLM_TEACHER_CORRELATION_FULL.json")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. í•µì‹¬ ë°œê²¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ğŸ¯ í•µì‹¬ ë°œê²¬")
print("=" * 80)

# 3ëª¨ë¸ í‰ê·  vs 2ëª… í‰ê· 
key_result = df_results[
    (df_results['LLM'] == 'LLM 3ëª¨ë¸ í‰ê· ') & 
    (df_results['êµì‚¬'] == 'êµì‚¬ 2ëª… í‰ê· ')
]

if len(key_result) > 0:
    key_r = key_result.iloc[0]['Pearson_r']
    key_n = key_result.iloc[0]['N']
    print(f"\nğŸ“Œ ë…¼ë¬¸ í•µì‹¬ ê°’:")
    print(f"   LLM 3ëª¨ë¸ í‰ê·  vs êµì‚¬ 2ëª… í‰ê· ")
    print(f"   r={key_r:.3f}, N={key_n}")

# ê°€ì¥ ë†’ì€/ë‚®ì€ ìƒê´€
highest = df_results.loc[df_results['Pearson_r'].idxmax()]
lowest = df_results.loc[df_results['Pearson_r'].idxmin()]

print(f"\nğŸ” ê°€ì¥ ë†’ì€ ìƒê´€:")
print(f"   {highest['LLM']} Ã— {highest['êµì‚¬']}")
print(f"   r={highest['Pearson_r']:.3f}, N={highest['N']}")

print(f"\nğŸ”» ê°€ì¥ ë‚®ì€ ìƒê´€:")
print(f"   {lowest['LLM']} Ã— {lowest['êµì‚¬']}")
print(f"   r={lowest['Pearson_r']:.3f}, N={lowest['N']}")

