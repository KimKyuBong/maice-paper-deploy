#!/usr/bin/env python3
"""
ëª¨ë¸ë³„ Ã— í•­ëª©ë³„ ìƒê´€ê´€ê³„ ì™„ì „ ë§¤íŠ¸ë¦­ìŠ¤
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ëª©ì : ê° LLM ëª¨ë¸ì´ ì–´ë–¤ í•­ëª©ì—ì„œ êµì‚¬ì™€ ì¼ì¹˜í•˜ëŠ”ì§€ ë¶„ì„

ë§¤íŠ¸ë¦­ìŠ¤:
  - í–‰: A1~C2 (8ê°œ í•­ëª©)
  - ì—´: OpenAI, Anthropic, Gemini, 3ëª¨ë¸ í‰ê· 
  - ê°’: êµì‚¬ 2ëª… í‰ê· ê³¼ì˜ ìƒê´€ê³„ìˆ˜
"""

import pandas as pd
from scipy import stats
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns

plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. ë°ì´í„° ë¡œë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BASE_DIR = Path(__file__).parent.parent.parent
DATA_DIR = BASE_DIR / 'data'
OUTPUT_DIR = BASE_DIR / 'scripts' / 'verification'

print("=" * 80)
print("ğŸ“Š ëª¨ë¸ë³„ Ã— í•­ëª©ë³„ ìƒê´€ê´€ê³„ ì™„ì „ ë§¤íŠ¸ë¦­ìŠ¤")
print("=" * 80)

# LLM ë°ì´í„°
df_llm = pd.read_csv(DATA_DIR / 'llm_evaluations' / 'llm_284sessions_complete.csv')

# êµì‚¬ ë°ì´í„°
df_teacher_raw = pd.read_csv(DATA_DIR / 'analysis_results' / 'three_teachers_100_sessions.csv')
df_teacher = df_teacher_raw[df_teacher_raw['evaluator'].isin([96, 97])]

# êµì‚¬ í‰ê· 
teacher_avg = df_teacher.groupby('session_id').agg({
    'q1': 'mean', 'q2': 'mean', 'q3': 'mean',
    'r1': 'mean', 'r2': 'mean', 'r3': 'mean',
    'c1': 'mean', 'c2': 'mean'
}).reset_index()

# ë³‘í•©
df_merged = pd.merge(df_llm, teacher_avg, on='session_id', how='inner')

print(f"\nâœ“ ê³µí†µ ì„¸ì…˜: {len(df_merged)}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. ëª¨ë¸ë³„ Ã— í•­ëª©ë³„ ìƒê´€ê³„ìˆ˜ ê³„ì‚°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ğŸ“Š ëª¨ë¸ë³„ Ã— í•­ëª©ë³„ ìƒê´€ê³„ìˆ˜")
print("=" * 80)

items = [
    ('A1 ìˆ˜í•™ì „ë¬¸ì„±', 'A1', 'q1'),
    ('A2 ì§ˆë¬¸êµ¬ì¡°í™”', 'A2', 'q2'),
    ('A3 í•™ìŠµë§¥ë½', 'A3', 'q3'),
    ('B1 í•™ìŠµìë§ì¶¤', 'B1', 'r1'),
    ('B2 ì„¤ëª…ì²´ê³„ì„±', 'B2', 'r2'),
    ('B3 í•™ìŠµí™•ì¥ì„±', 'B3', 'r3'),
    ('C1 ëŒ€í™”ì¼ê´€ì„±', 'C1', 'c1'),
    ('C2 í•™ìŠµì§€ì›', 'C2', 'c2')
]

models = [
    ('OpenAI', 'openai'),
    ('Anthropic', 'anthropic'),
    ('Gemini', 'gemini'),
    ('3ëª¨ë¸ í‰ê· ', 'avg')
]

# ë§¤íŠ¸ë¦­ìŠ¤ ê³„ì‚°
matrix = []

for item_name, item_code, teacher_col in items:
    row = {'í•­ëª©': item_name}
    
    print(f"\n{item_name}:")
    
    for model_name, model_prefix in models:
        llm_col = f'{model_prefix}_{item_code}'
        
        r, p = stats.pearsonr(df_merged[llm_col], df_merged[teacher_col])
        
        row[model_name] = round(r, 3)
        
        # ìœ ì˜ì„± í‘œì‹œ
        if p < 0.001:
            sig = '***'
        elif p < 0.01:
            sig = '**'
        elif p < 0.05:
            sig = '*'
        else:
            sig = ''
        
        print(f"  {model_name:12s}: r={r:.3f}{sig} (p={p:.4f})")
    
    matrix.append(row)

df_matrix = pd.DataFrame(matrix)

print("\n" + "=" * 80)
print("ğŸ“‹ ì™„ì „ ë§¤íŠ¸ë¦­ìŠ¤")
print("=" * 80)
print(df_matrix.to_string(index=False))

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. ë§ˆí¬ë‹¤ìš´ í‘œ ìƒì„±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ğŸ“ ë§ˆí¬ë‹¤ìš´ í‘œ")
print("=" * 80)

markdown = []
markdown.append("**[í‘œâ…¤-13c] ëª¨ë¸ë³„ í•­ëª©ë³„ êµì‚¬ì™€ì˜ ìƒê´€ê´€ê³„ (N=100)**")
markdown.append("")
markdown.append("| í•­ëª© | OpenAI | Anthropic | Gemini | 3ëª¨ë¸ í‰ê·  |")
markdown.append("|:----:|:------:|:---------:|:------:|:---------:|")

for _, row in df_matrix.iterrows():
    item = row['í•­ëª©']
    openai = f"{row['OpenAI']:.3f}"
    anthropic = f"{row['Anthropic']:.3f}"
    gemini = f"{row['Gemini']:.3f}"
    avg = f"{row['3ëª¨ë¸ í‰ê· ']:.3f}"
    
    markdown.append(f"| {item} | {openai}*** | {anthropic}*** | {gemini}*** | {avg}*** |")

markdown.append("")
markdown.append("ì£¼: ***p<0.001. ê° LLM ëª¨ë¸ê³¼ êµì‚¬ 2ëª…(A, B) í‰ê· ê³¼ì˜ Pearson ìƒê´€ê³„ìˆ˜. N=100.")

markdown_text = "\n".join(markdown)
print(markdown_text)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. íˆíŠ¸ë§µ ìƒì„±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

fig, ax = plt.subplots(1, 1, figsize=(10, 6))

# ë°ì´í„° ì¤€ë¹„
heatmap_data = df_matrix.set_index('í•­ëª©')[['OpenAI', 'Anthropic', 'Gemini', '3ëª¨ë¸ í‰ê· ']]

# íˆíŠ¸ë§µ
sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='YlGnBu', 
            cbar_kws={'label': 'Pearson r'}, vmin=0.2, vmax=0.8,
            linewidths=0.5, ax=ax)

ax.set_title('ëª¨ë¸ë³„ Ã— í•­ëª©ë³„ êµì‚¬ì™€ì˜ ìƒê´€ê´€ê³„', fontsize=14, fontweight='bold', pad=15)
ax.set_xlabel('LLM ëª¨ë¸', fontsize=12, fontweight='bold')
ax.set_ylabel('í‰ê°€ í•­ëª©', fontsize=12, fontweight='bold')

plt.tight_layout()
plt.savefig(OUTPUT_DIR / 'model_item_correlation_heatmap.png', dpi=300, bbox_inches='tight')
print(f"\nâœ“ ì €ì¥: model_item_correlation_heatmap.png")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. ë¶„ì„ ìš”ì•½
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ğŸ“Š ë¶„ì„ ìš”ì•½")
print("=" * 80)

# ëª¨ë¸ë³„ í‰ê· 
for model in ['OpenAI', 'Anthropic', 'Gemini', '3ëª¨ë¸ í‰ê· ']:
    model_avg = df_matrix[model].mean()
    model_max = df_matrix[model].max()
    model_min = df_matrix[model].min()
    
    max_item = df_matrix.loc[df_matrix[model].idxmax(), 'í•­ëª©']
    min_item = df_matrix.loc[df_matrix[model].idxmin(), 'í•­ëª©']
    
    print(f"\n{model}:")
    print(f"  í‰ê·  r: {model_avg:.3f}")
    print(f"  ìµœê³ : {max_item} (r={model_max:.3f})")
    print(f"  ìµœì €: {min_item} (r={model_min:.3f})")

# CSV ì €ì¥
df_matrix.to_csv(OUTPUT_DIR / 'MODEL_ITEM_CORRELATION_MATRIX.csv', index=False, encoding='utf-8-sig')

with open(OUTPUT_DIR / 'MODEL_ITEM_CORRELATION_MATRIX.md', 'w', encoding='utf-8') as f:
    f.write(markdown_text)

print("\n" + "=" * 80)
print("âœ… ì™„ë£Œ!")
print("=" * 80)
print(f"\níŒŒì¼:")
print(f"  - MODEL_ITEM_CORRELATION_MATRIX.csv")
print(f"  - MODEL_ITEM_CORRELATION_MATRIX.md")
print(f"  - model_item_correlation_heatmap.png")

