#!/usr/bin/env python3
"""
LLM 3ëª¨ë¸ í‰ê·  vs êµì‚¬ 2ëª… í‰ê·  í•­ëª©ë³„ ì ìˆ˜ ë¹„êµ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ëª©ì : LLMê³¼ êµì‚¬ì˜ ì‹¤ì œ ì ìˆ˜ë¥¼ í•­ëª©ë³„ë¡œ ë¹„êµ
"""

import pandas as pd
from scipy import stats
from pathlib import Path

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. ë°ì´í„° ë¡œë“œ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BASE_DIR = Path(__file__).parent.parent.parent
DATA_DIR = BASE_DIR / 'data'
OUTPUT_DIR = BASE_DIR / 'scripts' / 'verification'

print("=" * 80)
print("ðŸ“Š LLM vs êµì‚¬ í•­ëª©ë³„ ì ìˆ˜ ë¹„êµ")
print("=" * 80)

# LLM ë°ì´í„°
df_llm = pd.read_csv(DATA_DIR / 'llm_evaluations' / 'llm_284sessions_complete.csv')

# êµì‚¬ ë°ì´í„°
df_teacher_raw = pd.read_csv(DATA_DIR / 'analysis_results' / 'three_teachers_100_sessions.csv')
df_teacher = df_teacher_raw[df_teacher_raw['evaluator'].isin([96, 97])]

# êµì‚¬ í‰ê· 
teacher_avg = df_teacher.groupby('session_id').agg({
    'overall': 'mean',
    'q1': 'mean', 'q2': 'mean', 'q3': 'mean',
    'r1': 'mean', 'r2': 'mean', 'r3': 'mean',
    'c1': 'mean', 'c2': 'mean',
    'q_total': 'mean', 'r_total': 'mean', 'c_total': 'mean'
}).reset_index()

# ë³‘í•©
df_merged = pd.merge(df_llm, teacher_avg, on='session_id', how='inner')

print(f"\nâœ“ ê³µí†µ ì„¸ì…˜: {len(df_merged)}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. í•­ëª©ë³„ í‰ê·  ë¹„êµ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ðŸ“Š í•­ëª©ë³„ ì ìˆ˜ ë¹„êµ")
print("=" * 80)

items = [
    ('A1 ìˆ˜í•™ì „ë¬¸ì„±', 'avg_A1', 'q1', 5),
    ('A2 ì§ˆë¬¸êµ¬ì¡°í™”', 'avg_A2', 'q2', 5),
    ('A3 í•™ìŠµë§¥ë½', 'avg_A3', 'q3', 5),
    ('B1 í•™ìŠµìžë§žì¶¤', 'avg_B1', 'r1', 5),
    ('B2 ì„¤ëª…ì²´ê³„ì„±', 'avg_B2', 'r2', 5),
    ('B3 í•™ìŠµí™•ìž¥ì„±', 'avg_B3', 'r3', 5),
    ('C1 ëŒ€í™”ì¼ê´€ì„±', 'avg_C1', 'c1', 5),
    ('C2 í•™ìŠµì§€ì›', 'avg_C2', 'c2', 5),
    ('ì „ì²´', 'avg_overall', 'overall', 40)
]

results = []

for item_name, llm_col, teacher_col, max_score in items:
    llm_mean = df_merged[llm_col].mean()
    llm_std = df_merged[llm_col].std()
    
    teacher_mean = df_merged[teacher_col].mean()
    teacher_std = df_merged[teacher_col].std()
    
    diff = llm_mean - teacher_mean
    
    # t-test
    t_stat, p_val = stats.ttest_ind(df_merged[llm_col], df_merged[teacher_col])
    
    # ìƒê´€ê³„ìˆ˜
    r, _ = stats.pearsonr(df_merged[llm_col], df_merged[teacher_col])
    
    results.append({
        'í•­ëª©': item_name,
        'LLM_í‰ê· ': round(llm_mean, 2),
        'LLM_SD': round(llm_std, 2),
        'êµì‚¬_í‰ê· ': round(teacher_mean, 2),
        'êµì‚¬_SD': round(teacher_std, 2),
        'ì°¨ì´': round(diff, 2),
        't': round(t_stat, 2),
        'p': round(p_val, 3) if p_val >= 0.001 else '<0.001',
        'r': round(r, 3),
        'ë§Œì ': max_score
    })
    
    print(f"{item_name:12s}: LLM={llm_mean:.2f}, êµì‚¬={teacher_mean:.2f}, "
          f"ì°¨ì´={diff:+.2f}, r={r:.3f}")

df_results = pd.DataFrame(results)

print("\n" + "=" * 80)
print("ðŸ“‹ ì „ì²´ ê²°ê³¼")
print("=" * 80)
print(df_results.to_string(index=False))

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. ë§ˆí¬ë‹¤ìš´ í‘œ ìƒì„±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ðŸ“ ë§ˆí¬ë‹¤ìš´ í‘œ")
print("=" * 80)

markdown = []
markdown.append("**[í‘œâ…¤-X] LLM-êµì‚¬ í‰ê°€ í•­ëª©ë³„ ì ìˆ˜ ë¹„êµ (N=100)**")
markdown.append("")
markdown.append("| í•­ëª© | LLM 3ëª¨ë¸ | êµì‚¬ 2ëª… | ì°¨ì´ | r | ë¹„ê³  |")
markdown.append("|:----:|:---------:|:-------:|:----:|:-:|:----:|")

for _, row in df_results.iterrows():
    item = row['í•­ëª©']
    llm = f"{row['LLM_í‰ê· ']:.2f} ({row['LLM_SD']:.2f})"
    teacher = f"{row['êµì‚¬_í‰ê· ']:.2f} ({row['êµì‚¬_SD']:.2f})"
    diff = f"{row['ì°¨ì´']:+.2f}"
    r = f"{row['r']:.3f}"
    max_score = f"{row['ë§Œì ']}ì "
    
    if item == 'ì „ì²´':
        markdown.append(f"| **{item}** | **{llm}** | **{teacher}** | **{diff}** | **{r}*** | {max_score} |")
    else:
        markdown.append(f"| {item} | {llm} | {teacher} | {diff} | {r}*** | {max_score} |")

markdown.append("")
markdown.append("ì£¼: í‰ê· (í‘œì¤€íŽ¸ì°¨). ***p<0.001. LLMì€ Gemini, Claude, GPT-5 í‰ê· , êµì‚¬ëŠ” A, B í‰ê· .")

markdown_text = "\n".join(markdown)
print(markdown_text)

# ì €ìž¥
df_results.to_csv(OUTPUT_DIR / 'LLM_TEACHER_SCORE_COMPARISON.csv', index=False, encoding='utf-8-sig')

with open(OUTPUT_DIR / 'LLM_TEACHER_SCORE_COMPARISON.md', 'w', encoding='utf-8') as f:
    f.write(markdown_text)

print("\n" + "=" * 80)
print("âœ… ì™„ë£Œ!")
print("=" * 80)
print(f"\níŒŒì¼:")
print(f"  - LLM_TEACHER_SCORE_COMPARISON.csv")
print(f"  - LLM_TEACHER_SCORE_COMPARISON.md")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. í•µì‹¬ ë°œê²¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("\n" + "=" * 80)
print("ðŸŽ¯ í•µì‹¬ ë°œê²¬")
print("=" * 80)

# ê°€ìž¥ í° ì°¨ì´
biggest_diff = df_results.loc[df_results['ì°¨ì´'].abs().idxmax()]
print(f"\nê°€ìž¥ í° ì°¨ì´:")
print(f"  {biggest_diff['í•­ëª©']}: {biggest_diff['ì°¨ì´']:+.2f}ì ")

# ê°€ìž¥ ë†’ì€/ë‚®ì€ ìƒê´€
highest_r = df_results[df_results['í•­ëª©'] != 'ì „ì²´'].loc[df_results[df_results['í•­ëª©'] != 'ì „ì²´']['r'].idxmax()]
lowest_r = df_results[df_results['í•­ëª©'] != 'ì „ì²´'].loc[df_results[df_results['í•­ëª©'] != 'ì „ì²´']['r'].idxmin()]

print(f"\nê°€ìž¥ ë†’ì€ ìƒê´€:")
print(f"  {highest_r['í•­ëª©']}: r={highest_r['r']:.3f}")

print(f"\nê°€ìž¥ ë‚®ì€ ìƒê´€:")
print(f"  {lowest_r['í•­ëª©']}: r={lowest_r['r']:.3f}")

