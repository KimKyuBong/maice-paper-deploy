#!/usr/bin/env python3
"""
LLM í‰ê°€ ì‹ ë¢°ë„ ë¶„ì„

ë…¼ë¬¸ 5ì¥ 2ì ˆ ë‚˜í•­(1)ì—ì„œ ì œì‹œëœ ì‹ ë¢°ë„ ì§€í‘œë“¤ì„ ê²€ì¦í•©ë‹ˆë‹¤.

âš ï¸ ì¤‘ìš”: ìµœì¢… ìƒì„±ëœ CSV íŒŒì¼ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
- ì…ë ¥: llm_3models_284_PERFECT_FINAL.csv (3ê°œ ëª¨ë¸ ì±„ì  ê²°ê³¼)

ì£¼ìš” ì§€í‘œ:
1. Cronbach's Î± (ë‚´ì  ì¼ê´€ì„±)
2. ICC (Intraclass Correlation Coefficient, ê¸‰ë‚´ìƒê´€ê³„ìˆ˜)
3. Pearson ìƒê´€ê³„ìˆ˜ (ëª¨ë¸ ê°„)

ê·¼ê±°:
- ë…¼ë¬¸: "ì‹ ë¢°ë„: Cronbach's Î±=0.868, ICC=0.642, Pearson r=0.709"
- Cohen (1988), Cronbach (1951), McGraw & Wong (1996)
"""

import pandas as pd
import numpy as np
from pathlib import Path
from scipy import stats
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("LLM í‰ê°€ ì‹ ë¢°ë„ ë¶„ì„")
print("="*80)
print()
print("âš ï¸  ìµœì¢… CSV íŒŒì¼ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤: llm_3models_284_PERFECT_FINAL.csv")
print()

# ê²½ë¡œ ì„¤ì •
BASE_PATH = Path(__file__).parent.parent / "data"
OUTPUT_PATH = Path(__file__).parent / "results"
OUTPUT_PATH.mkdir(exist_ok=True)

# ============================================================================
# 1. Cronbach's Alpha ê³„ì‚°
# ============================================================================

def cronbach_alpha(data):
    """
    Cronbach's Alpha ê³„ì‚°
    
    Î± = (k / (k-1)) * (1 - (Î£var_items / var_total))
    
    where:
        k = í•­ëª© ìˆ˜
        var_items = ê° í•­ëª©ì˜ ë¶„ì‚°
        var_total = ì „ì²´ ì ìˆ˜ì˜ ë¶„ì‚°
    
    ì°¸ê³ : Cronbach, L. J. (1951). Coefficient alpha and the internal 
          structure of tests. Psychometrika, 16(3), 297-334.
    """
    # data: DataFrame (í–‰=ì„¸ì…˜, ì—´=í‰ê°€ì/ëª¨ë¸)
    n_items = data.shape[1]
    
    # ê° í•­ëª©(ëª¨ë¸)ì˜ ë¶„ì‚°
    var_items = data.var(axis=0, ddof=1).sum()
    
    # ì „ì²´ ì ìˆ˜ì˜ ë¶„ì‚° (ê° í–‰ì˜ í•©)
    total_scores = data.sum(axis=1)
    var_total = total_scores.var(ddof=1)
    
    # Cronbach's Alpha
    alpha = (n_items / (n_items - 1)) * (1 - (var_items / var_total))
    
    return alpha

# ============================================================================
# 2. ICC ê³„ì‚° (Two-way random effects, absolute agreement)
# ============================================================================

def calculate_icc(data):
    """
    ICC(2,1) ê³„ì‚°: Two-way random effects, absolute agreement
    
    ì°¸ê³ : McGraw, K. O., & Wong, S. P. (1996). Forming inferences about 
          some intraclass correlation coefficients. Psychological Methods, 
          1(1), 30-46.
    """
    # data: DataFrame (í–‰=ì„¸ì…˜, ì—´=í‰ê°€ì/ëª¨ë¸)
    n_subjects = data.shape[0]  # ì„¸ì…˜ ìˆ˜
    n_raters = data.shape[1]    # ëª¨ë¸ ìˆ˜
    
    # ì „ì²´ í‰ê· 
    grand_mean = data.values.mean()
    
    # ì„¸ì…˜ë³„ í‰ê· 
    subject_means = data.mean(axis=1).values
    
    # í‰ê°€ìë³„ í‰ê· 
    rater_means = data.mean(axis=0).values
    
    # Sum of Squares
    SS_total = ((data.values - grand_mean) ** 2).sum()
    SS_subjects = n_raters * ((subject_means - grand_mean) ** 2).sum()
    SS_raters = n_subjects * ((rater_means - grand_mean) ** 2).sum()
    SS_error = SS_total - SS_subjects - SS_raters
    
    # Mean Squares
    MS_subjects = SS_subjects / (n_subjects - 1)
    MS_raters = SS_raters / (n_raters - 1)
    MS_error = SS_error / ((n_subjects - 1) * (n_raters - 1))
    
    # ICC(2,1)
    icc = (MS_subjects - MS_error) / (MS_subjects + (n_raters - 1) * MS_error + n_raters * (MS_raters - MS_error) / n_subjects)
    
    return max(0, icc)  # ìŒìˆ˜ ë°©ì§€

# ============================================================================
# 3. ìµœì¢… CSV íŒŒì¼ ë¡œë“œ
# ============================================================================

print("1. ìµœì¢… CSV íŒŒì¼ ë¡œë“œ")
print("-" * 80)

SOURCE_FILE = BASE_PATH / "llm_evaluations" / "llm_3models_284_PERFECT_FINAL.csv"

if not SOURCE_FILE.exists():
    print(f"âŒ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {SOURCE_FILE}")
    print("ìµœì¢… ìƒì„±ëœ CSV íŒŒì¼ì´ í•„ìš”í•©ë‹ˆë‹¤: llm_3models_284_PERFECT_FINAL.csv")
    import sys
    sys.exit(1)

df = pd.read_csv(SOURCE_FILE)
print(f"âœ“ íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ì„¸ì…˜, {len(df.columns)}ê°œ ì»¬ëŸ¼")
print()

# ============================================================================
# 4. 3ê°œ ëª¨ë¸ì˜ overall ì ìˆ˜ ì¶”ì¶œ
# ============================================================================

print("2. 3ê°œ ëª¨ë¸ overall ì ìˆ˜ ì¶”ì¶œ")
print("-" * 80)

models = ['gemini', 'anthropic', 'openai']
reliability_data = pd.DataFrame({'session_id': df['session_id']})

for model in models:
    col = f"{model}_overall"
    if col in df.columns:
        reliability_data[model] = df[col].values
        print(f"âœ“ {model.upper()}: {len(df[df[col].notna()])}ê°œ ì„¸ì…˜")
    else:
        print(f"âœ— {model.upper()}: ì»¬ëŸ¼ ì—†ìŒ ({col})")
        import sys
        sys.exit(1)

# ê²°ì¸¡ì¹˜ ì œê±°
reliability_data = reliability_data.dropna()
print(f"\nâœ“ ê³µí†µ ì„¸ì…˜: {len(reliability_data)}ê°œ")
print()

# ì„¸ì…˜ IDë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
reliability_data = reliability_data.set_index('session_id')

# ëª¨ë¸ë³„ ì ìˆ˜ë§Œ ì¶”ì¶œ
reliability_scores = reliability_data[models]

print(f"ë¶„ì„ ë°ì´í„°: {len(reliability_scores)}ê°œ ì„¸ì…˜ Ã— 3ê°œ ëª¨ë¸")
print()

# ============================================================================
# 5. ì‹ ë¢°ë„ ë¶„ì„
# ============================================================================

print("3. ì‹ ë¢°ë„ ë¶„ì„")
print("-" * 80)

# 5-1. Cronbach's Alpha
print("\nğŸ“Š (1) Cronbach's Alpha (ë‚´ì  ì¼ê´€ì„±)")
print("-" * 80)

alpha = cronbach_alpha(reliability_scores)
print(f"Cronbach's Î± = {alpha:.3f}")
print()
print("í•´ì„:")
if alpha >= 0.9:
    print("  âœ“ ë§¤ìš° ë†’ìŒ (Excellent, Î± â‰¥ 0.9)")
elif alpha >= 0.8:
    print("  âœ“ ë†’ìŒ (Good, 0.8 â‰¤ Î± < 0.9)")
elif alpha >= 0.7:
    print("  âœ“ ìˆ˜ìš© ê°€ëŠ¥ (Acceptable, 0.7 â‰¤ Î± < 0.8)")
else:
    print("  âš ï¸  ë‚®ìŒ (Poor, Î± < 0.7)")

print()
print(f"ë…¼ë¬¸ ê¸°ì¬ê°’: Î± = 0.868")
print(f"ê³„ì‚° ê²°ê³¼:   Î± = {alpha:.3f}")
print(f"ì°¨ì´:       Î”Î± = {abs(alpha - 0.868):.3f}")
print()

# 5-2. ICC
print("ğŸ“Š (2) ICC (ê¸‰ë‚´ìƒê´€ê³„ìˆ˜)")
print("-" * 80)

icc = calculate_icc(reliability_scores)
print(f"ICC(2,1) = {icc:.3f}")
print()
print("í•´ì„:")
if icc >= 0.75:
    print("  âœ“ ë†’ìŒ (Excellent, ICC â‰¥ 0.75)")
elif icc >= 0.60:
    print("  âœ“ ì¤‘ê°„-ë†’ìŒ (Good, 0.60 â‰¤ ICC < 0.75)")
elif icc >= 0.40:
    print("  âš ï¸  ì¤‘ê°„ (Fair, 0.40 â‰¤ ICC < 0.60)")
else:
    print("  âš ï¸  ë‚®ìŒ (Poor, ICC < 0.40)")

print()
print(f"ë…¼ë¬¸ ê¸°ì¬ê°’: ICC = 0.642")
print(f"ê³„ì‚° ê²°ê³¼:   ICC = {icc:.3f}")
print(f"ì°¨ì´:       Î”ICC = {abs(icc - 0.642):.3f}")
print()

# 5-3. Pearson ìƒê´€ê³„ìˆ˜
print("ğŸ“Š (3) Pearson ìƒê´€ê³„ìˆ˜ (ëª¨ë¸ ê°„)")
print("-" * 80)

correlations = {}
pairs = [
    ('gemini', 'anthropic'),
    ('gemini', 'openai'),
    ('anthropic', 'openai')
]

for m1, m2 in pairs:
    r, p = stats.pearsonr(reliability_scores[m1], reliability_scores[m2])
    correlations[f"{m1}_{m2}"] = {
        'r': float(r),
        'p': float(p)
    }
    print(f"{m1.upper():8s} - {m2.upper():8s}: r = {r:.3f} (p = {p:.4f})")

avg_r = np.mean([corr['r'] for corr in correlations.values()])
print()
print(f"í‰ê·  ìƒê´€ê³„ìˆ˜: r = {avg_r:.3f}")
print()
print(f"ë…¼ë¬¸ ê¸°ì¬ê°’: r = 0.709")
print(f"ê³„ì‚° ê²°ê³¼:   r = {avg_r:.3f}")
print(f"ì°¨ì´:       Î”r = {abs(avg_r - 0.709):.3f}")
print()

# ============================================================================
# 6. ê²°ê³¼ ì €ì¥
# ============================================================================

print("4. ê²°ê³¼ ì €ì¥")
print("-" * 80)

reliability_summary = {
    'n_sessions': len(reliability_scores),
    'n_models': 3,
    'cronbach_alpha': {
        'value': float(alpha),
        'interpretation': 'Good' if alpha >= 0.8 else 'Acceptable' if alpha >= 0.7 else 'Poor',
        'paper_value': 0.868,
        'difference': float(abs(alpha - 0.868))
    },
    'icc': {
        'value': float(icc),
        'interpretation': 'Excellent' if icc >= 0.75 else 'Good' if icc >= 0.60 else 'Fair',
        'paper_value': 0.642,
        'difference': float(abs(icc - 0.642))
    },
    'pearson_average': {
        'value': float(avg_r),
        'interpretation': 'Strong' if avg_r >= 0.7 else 'Moderate',
        'paper_value': 0.709,
        'difference': float(abs(avg_r - 0.709))
    },
    'pairwise_correlations': correlations
}

output_json = OUTPUT_PATH / "llm_reliability_results.json"
import json
with open(output_json, 'w', encoding='utf-8') as f:
    json.dump(reliability_summary, f, ensure_ascii=False, indent=2)
print(f"âœ“ ì‹ ë¢°ë„ ë¶„ì„ ê²°ê³¼ ì €ì¥: {output_json}")

# ìƒê´€ê³„ìˆ˜ í–‰ë ¬ CSV
corr_matrix = reliability_scores.corr()
corr_csv = OUTPUT_PATH / "llm_correlation_matrix.csv"
corr_matrix.to_csv(corr_csv, encoding='utf-8-sig')
print(f"âœ“ ìƒê´€ê³„ìˆ˜ í–‰ë ¬ ì €ì¥: {corr_csv}")

print()
print("="*80)
print("LLM í‰ê°€ ì‹ ë¢°ë„ ë¶„ì„ ì™„ë£Œ!")
print("="*80)
print()
print("âœ… ê²€ì¦ ê²°ê³¼:")
print(f"   Cronbach's Î±: {alpha:.3f} (ë…¼ë¬¸: 0.868, ì°¨ì´: {abs(alpha - 0.868):.3f})")
print(f"   ICC(2,1):     {icc:.3f} (ë…¼ë¬¸: 0.642, ì°¨ì´: {abs(icc - 0.642):.3f})")
print(f"   Pearson r:    {avg_r:.3f} (ë…¼ë¬¸: 0.709, ì°¨ì´: {abs(avg_r - 0.709):.3f})")
print()
print("âš ï¸  ì°¸ê³ : ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìµœì¢… CSV íŒŒì¼ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
print("   ì›ë³¸ JSONL íŒŒì¼ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
